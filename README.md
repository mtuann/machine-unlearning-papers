# Machine Unlearning Papers

Updated list of Machine Unlearning papers as of **January 08, 2026**. 

## Quick Access
üîç **[Interactive Search & Browse](https://mtuann.github.io/papers/)** - Filter, search, and explore all papers with an intuitive interface

## Overview
- **Coverage**: Papers from 2016 to present
- **Sources**: arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML venues
- **Updates**: Automated collection of new publications
- **Features**: Advanced search, code availability tracking, and multi-venue coverage

## Related Topics
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** | **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** | **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** | **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)**
- **[Serverless Computing](https://mtuann.github.io/papers/)** | **[Multi-Modal Learning](https://mtuann.github.io/papers/)**

## Machine Unlearning Papers with Code
This section lists papers with available code (sorted by publication date). For the complete paper list, visit the [Research Papers Page](https://mtuann.github.io/papers/).

---

## Support
If you find this resource helpful, consider supporting its development:

- **Ko-fi** (PayPal/Card): [ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)
- **Techcombank** (Vietnam): 5877 5555 55 (Nguyen Thi Lan Phuong)

---

*This repository is regularly updated. For the latest data, visit the [Research Papers Page](https://mtuann.github.io/papers/).*


|No.|Title|Authors|Publish Date|Venue|Code|
|---|---|---|---|---|---|
|1|[Training wide residual networks for deployment using a single bit for each weight](https://openreview.net/pdf/861cb006a62eb71925571a5d4979901d047a92ea.pdf)|Mark D. McDonnell||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/training-wide-residual-networks-for/code)|
|2|[Compressed Sensing with Deep Image Prior and Learned Regularization](https://openreview.net/pdf/960068efdade58de64b1b641bcccfdba53ac168b.pdf)|Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, Alexandros G. Dimakis||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/compressed-sensing-with-deep-image-prior-and/code)|
|3|[Multitask Soft Option Learning](https://openreview.net/pdf/5e7c12118369a575ab52f9fb553689c36468b080.pdf)|Maximilian Igl, Andrew Gambardella, Jinke He, Nantas Nardelli, N. Siddharth, Wendelin B√∂hmer, Shimon Whiteson||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/multitask-soft-option-learning/code)|
|4|[Machine Unlearning in the Era of Quantum Machine Learning: An Empirical Study](https://doi.org/10.48550/arxiv.2512.19253)|Carla Crivoi, Radu Tudor Ionescu|2025-12-22|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/CrivoiCarla/HQML)](https://github.com/CrivoiCarla/HQML)|
|5|[SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities](https://doi.org/10.48550/arxiv.2512.06562)|Nguyen, Dung Thuy, Nguyen, Quang, Robinette, Preston K., Jiang, Eli, Johnson, Taylor T., Leach, Kevin|2025-12-06|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/judydnguyen/SUGAR-Generative-Unlearn)](https://github.com/judydnguyen/SUGAR-Generative-Unlearn)|
|6|[Rethinking Machine Unlearning in Image Generation Models](https://doi.org/10.48550/arXiv.2506.02761)|Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng|2025-11-19|ACM Conference on Computer and Communications Security (CCS 2025)|[![Star](https://img.shields.io/github/stars/ryliu68/IGMU)](https://github.com/ryliu68/IGMU)|
|7|[Graph Unlearning Meets Influence-aware Negative Preference Optimization](https://doi.org/10.48550/arXiv.2510.19479)|Qiang Chen, Zhongze Wu, Ang He, Xi Lin, Shuo Jiang, Shan You, Chang Xu, Yi Chen, Xiu Su|2025-11-19|Arabixiv (OSF Preprints)|[![Star](https://img.shields.io/github/stars/sh-qiangchen/INPO)](https://github.com/sh-qiangchen/INPO)|
|8|[Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models](https://doi.org/10.48550/arxiv.2511.06793)|LI Kunhao, Li, Wenhao, Wu Di, Yang Lei, Bai Jun, Jia Ju, Xue, Jason|2025-11-10|arXiv (Cornell University)|[![Star](https://img.shields.io/github/stars/PreckLi/MIP-Editor)](https://github.com/PreckLi/MIP-Editor)|
|9|[FedDPGu: Adaptive Prompt-tuning with Built-in Unlearning for Federated Learning](https://doi.org/10.21203/rs.3.rs-7488594/v1)|Lishan Yang, Wei Emma Zhang, Ali Shakeri, Amin Beheshti, Weitong Chen, Jian Yang|2025-10-30|OpenAlex|[![Star](https://img.shields.io/github/stars/gotobcn8/FedDPG)](https://github.com/gotobcn8/FedDPG)|
|10|[LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems](https://doi.org/10.48550/arXiv.2510.20327)|Feihong Yu, Yuyuan Li, Xiaohua Feng, Junpeng Fang, Tao Wang, Chaochao Chen|2025-10-25|OpenAlex|[![Star](https://img.shields.io/github/stars/anonymifish/lego-rec-multiple-attribute-unlearning)](https://github.com/anonymifish/lego-rec-multiple-attribute-unlearning)|
|11|[Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning](https://doi.org/10.48550/arXiv.2510.17021)|Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu|2025-10-19|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Backdoor)](https://github.com/OPTML-Group/Unlearn-Backdoor)|
|12|[Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack   against Image Generation Model Unlearning](https://doi.org/10.48550/arXiv.2507.07139)|Renyang Liu, Guanlin Li, Tianwei Zhang, See-Kiong Ng|2025-07-01|arXiv|[![Star](https://img.shields.io/github/stars/ryliu68/RECALL)](https://github.com/ryliu68/RECALL)|
|13|[Leveraging Distribution Matching to Make Approximate Machine Unlearning   Faster](https://doi.org/10.48550/arXiv.2507.09786)|Junaid Iqbal Khan|2025-07-01|arXiv|[![Star](https://img.shields.io/github/stars/algebraicdianuj/DC_Unlearning)](https://github.com/algebraicdianuj/DC_Unlearning)|
|14|[Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation   and Confidence Awareness](https://doi.org/10.48550/arXiv.2506.05735)|Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chi...|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/Graph-COM/Knowledge_Unlearning)](https://github.com/Graph-COM/Knowledge_Unlearning.git)|
|15|[Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from   Model Outputs](http://arxiv.org/abs/2506.14003v2)|Yiwei Chen, Soumyadeep Pal, Yimeng Zhang, Qing Qu, Sijia Liu|2025-06-01|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Trace)](https://github.com/OPTML-Group/Unlearn-Trace)|
|16|[Forget-MI: Machine Unlearning for Forgetting Multimodal Information in   Healthcare Settings](https://doi.org/10.1007/978-3-032-04947-6_20)|Shahad Hardan, Darya Taratynova, Abdelmajid Essofi, Karthik Nandakumar, Mohammad Yaqub|2025-06-01|MICCAI|[![Star](https://img.shields.io/github/stars/BioMedIA-MBZUAI/Forget-MI)](https://github.com/BioMedIA-MBZUAI/Forget-MI.git)|
|17|[Unlearning Isn't Deletion: Investigating Reversibility of Machine   Unlearning in LLMs](http://arxiv.org/abs/2505.16831v1)|Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du|2025-05-01|arXiv|[![Star](https://img.shields.io/github/stars/XiaoyuXU1/Representational_Analysis_Tools)](https://github.com/XiaoyuXU1/Representational_Analysis_Tools.git)|
|18|[Unlearning Sensitive Information in Multimodal LLMs: Benchmark and   Attack-Defense Evaluation](https://openreview.net/forum?id=YcnjgKbZQS)|Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal|2025-05-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/Vaidehi99/UnLOK-VQA)](https://github.com/Vaidehi99/UnLOK-VQA)|
|19|[Unlearning for Federated Online Learning to Rank: A Reproducibility   Study](https://doi.org/10.48550/arXiv.2505.12791)|Yiling Tao, Shuyi Wang, Jiaxi Yang, Guido Zuccon|2025-05-01|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|[![Star](https://img.shields.io/github/stars/Iris1026/Unlearning-for-FOLTR)](https://github.com/Iris1026/Unlearning-for-FOLTR.git)|
|20|[LoRA Unlearns More and Retains More (Student Abstract)](https://doi.org/10.1609/aaai.v39i28.35277)|Atharv Mittal|2025-04-11|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/vlgiitr/LoRA-Unlearn)](https://github.com/vlgiitr/LoRA-Unlearn)|
|21|[LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in   Current Benchmarks](https://doi.org/10.48550/arXiv.2504.10185)|Soumyadeep Pal, Changsheng Wang, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2025-04-01|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/MU-Coreset)](https://github.com/OPTML-Group/MU-Coreset)|
|22|[Multi-Objective Large Language Model Unlearning](https://doi.org/10.1109/icassp49660.2025.10889776)|Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao|2025-03-12|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|[![Star](https://img.shields.io/github/stars/zibinpan/MOLLM)](https://github.com/zibinpan/MOLLM)|
|23|[Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive   Learning: Adapting Alignment Calibration to MERU](https://openaccess.thecvf.com/content/CVPR2025W/TMM-OpenWorld/html/Vidal_Machine_Unlearning_in_Hyperbolic_vs._Euclidean_Multimodal_Contrastive_Learning_Adapting_CVPRW_2025_paper.html)|√Älex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund|2025-03-01|CVPR Workshops|[![Star](https://img.shields.io/github/stars/alex-pv01/HAC)](https://github.com/alex-pv01/HAC)|
|24|[MMUNLEARNER: Reformulating Multimodal Machine Unlearning in the Era of   Multimodal Large Language Models](https://doi.org/10.18653/v1/2025.findings-acl.375)|Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu|2025-02-16|Findings of the Association for Computational Linguistics: ACL 2022|[![Star](https://img.shields.io/github/stars/Z1zs/MMUnlearner)](https://github.com/Z1zs/MMUnlearner)|
|25|[Knowledge Swapping via Learning and Unlearning](https://openreview.net/forum?id=B3zlIHdnER)|Mingyu Xing, Lechao Cheng, Shengeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang|2025-02-11|arXiv|[![Star](https://img.shields.io/github/stars/xingmingyu123456/KnowledgeSwapping)](https://github.com/xingmingyu123456/KnowledgeSwapping)|
|26|[Towards LLM Unlearning Resilient to Relearning Attacks: A   Sharpness-Aware Minimization Perspective and Beyond](https://openreview.net/forum?id=zZjLv6F0Ks)|Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu|2025-02-07|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Smooth)](https://github.com/OPTML-Group/Unlearn-Smooth)|
|27|[Forgetting Any Data at Any Time: A Theoretically Certified Unlearning   Framework for Vertical Federated Learning](https://doi.org/10.48550/arXiv.2502.17081)|Linian Wang, Leye Wang|2025-02-01|arXiv|[![Star](https://img.shields.io/github/stars/wangln19/vertical-federated-unlearning)](https://github.com/wangln19/vertical-federated-unlearning)|
|28|[WaterDrum: Watermarking for Data-centric Unlearning Metric](https://doi.org/10.48550/arXiv.2505.05064)|Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, Se...|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/lululu008/WaterDrum)](https://github.com/lululu008/WaterDrum)|
|29|[ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging](https://doi.org/10.48550/arXiv.2503.21088)|Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/zjunlp/unlearn)](https://github.com/zjunlp/unlearn)|
|30|[Unlearning Personal Data from a Single Image](https://openreview.net/forum?id=VxC4PZ71Ym)|Thomas De Min, Massimiliano Mancini, St√©phane Lathuili√®re, Subhankar Roy, Elisa Ricci|2025-01-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/tdemin16/one-shui)](https://github.com/tdemin16/one-shui)|
|31|[On Large Language Model Continual Unlearning](https://openreview.net/forum?id=Essg9kb4yx)|Chongyang Gao, Lixu Wang, Kaize Ding, Chenkai Weng, Xiao Wang, Qi Zhu|2025-01-01|ICLR|[![Star](https://img.shields.io/github/stars/GCYZSL/O3-LLM-UNLEARNING)](https://github.com/GCYZSL/O3-LLM-UNLEARNING)|
|32|[Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs](https://openreview.net/forum?id=1ExfUpmIW4)|Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee|2025-01-01|ICLR|[![Star](https://img.shields.io/github/stars/csm9493/efficient-llm-unlearning)](https://github.com/csm9493/efficient-llm-unlearning)|
|33|[Targeted Unlearning with Single Layer Unlearning Gradient](https://openreview.net/forum?id=6Ofb0cGXb5)|Zikui Cai, Yaoteng Tan, M. Salman Asif|2025-01-01|ICML|[![Star](https://img.shields.io/github/stars/CSIPlab/SLUG)](https://github.com/CSIPlab/SLUG)|
|34|[SAeUron: Interpretable Concept Unlearning in Diffusion Models with   Sparse Autoencoders](https://openreview.net/forum?id=6N0GxaKdX9)|Bartosz Cywi≈Ñski, Kamil Rafa≈Ç Deja|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/cywinski/SAeUron)](https://github.com/cywinski/SAeUron)|
|35|[ReLearn: Unlearning via Learning for Large Language Models](https://doi.org/10.18653/v1/2025.acl-long.297)|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu ...|2025-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/zjunlp/unlearn)](https://github.com/zjunlp/unlearn)|
|36|[Provably Unlearnable Data Examples](https://www.ndss-symposium.org/ndss-paper/provably-unlearnable-data-examples/)|Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu, Derui Wang|2025-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/NeuralSec/certified-data-learnability)](https://github.com/NeuralSec/certified-data-learnability)|
|37|[Pre-training for Recommendation Unlearning](https://doi.org/10.48550/arXiv.2505.22649)|Guoxuan Chen, Lianghao Xia, Chao Huang|2025-01-01|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|[![Star](https://img.shields.io/github/stars/HKUDS/UnlearnRec)](https://github.com/HKUDS/UnlearnRec)|
|38|[Parallel Unlearning in Inherited Model Networks](https://doi.org/10.1109/TIFS.2025.3627869)|Xiao Liu, Mingyuan Li, Guangsheng Yu, Lixiang Li, Haipeng Peng, Ren Ping Liu|2025-01-01|IEEE Trans. Inf. Forensics Secur.|[![Star](https://img.shields.io/github/stars/MJLee00/Parallel-Unlearning-in-Inherited-Model-Networks)](https://github.com/MJLee00/Parallel-Unlearning-in-Inherited-Model-Networks)|
|39|[Vertical Federated Unlearning via Backdoor Certification](https://doi.org/10.48550/arXiv.2412.11476)|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025-01-01|IEEE Transactions on Services Computing|[![Star](https://img.shields.io/github/stars/mengde-han/VFL-unlearn)](https://github.com/mengde-han/VFL-unlearn)|
|40|[LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty](https://openaccess.thecvf.com/content/CVPR2025/html/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.html)|Christoforos N. Spartalis, Theodoros Semertzidis, Efstratios Gavves, Petros Daras|2025-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/cspartalis/LoTUS)](https://github.com/cspartalis/LoTUS)|
|41|[Catastrophic Failure of LLM Unlearning via Quantization](https://openreview.net/forum?id=lHSeDYamnz)|Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, Hui Liu, Qi He, Wenpeng Yin, Suhang Wang|2025-01-01|ICLR|[![Star](https://img.shields.io/github/stars/zzwjames/FailureLLMUnlearning)](https://github.com/zzwjames/FailureLLMUnlearning)|
|42|[A Survey on Unlearnable Data](https://doi.org/10.48550/arXiv.2503.23536)|Jiahao Li, Yiqiang Chen, Yunbing Xing, Yang Gu, Xiangyuan Lan|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/LiJiahao-Alex/Awesome-UnLearnable-Data)](https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data)|
|43|[Align-then-Unlearn: Embedding Alignment for LLM Unlearning](https://doi.org/10.48550/arXiv.2506.13181)|Philipp Spohn, Leander Girrbach, Jessica Bader, Zeynep Akata|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/ExplainableML/align-then-unlearn)](https://github.com/ExplainableML/align-then-unlearn)|
|44|[Group-robust Machine Unlearning](https://doi.org/10.48550/arXiv.2503.09330)|Thomas De Min, Subhankar Roy, St√©phane Lathuili√®re, Elisa Ricci, Massimiliano Mancini|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/tdemin16/group-robust_machine_unlearning)](https://github.com/tdemin16/group-robust_machine_unlearning)|
|45|[An Information Theoretic Approach to Machine Unlearning](https://openreview.net/forum?id=t1utIThKHD)|Jack Foster, Kyle Fogarty, Stefan Schoepf, Zack Dugue, Cengiz √ñztireli, Alexandra Brintrup|2025-01-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/jwf40/Information-Theoretic-Unlearning)](https://github.com/jwf40/Information-Theoretic-Unlearning)|
|46|[BLUR: A Bi-Level Optimization Approach for LLM Unlearning](https://doi.org/10.48550/arXiv.2506.08164)|Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu,...|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/OptimAI-Lab/BLURLLMUnlearning)](https://github.com/OptimAI-Lab/BLURLLMUnlearning)|
|47|[Backdoor Token Unlearning: Exposing and Defending Backdoors in   Pretrained Language Models](https://doi.org/10.1609/aaai.v39i23.34605)|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/XDJPH/BTU)](https://github.com/XDJPH/BTU)|
|48|[UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning](https://doi.org/10.48550/arXiv.2502.15082)|Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/Vaidehi99/UPCORE)](https://github.com/Vaidehi99/UPCORE)|
|49|[Certified Unlearning for Neural Networks](https://openreview.net/forum?id=3rWQlV3s1I)|Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/stair-lab/certified-unlearning-neural-networks-icml-2025)](https://github.com/stair-lab/certified-unlearning-neural-networks-icml-2025)|
|50|[Effective Skill Unlearning through Intervention and Abstention](https://doi.org/10.18653/v1/2025.naacl-long.322)|Yongce Li, Chung-En Sun, Tsui-Wei Weng|2025-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/Trustworthy-ML-Lab/effective_skill_unlearning)](https://github.com/Trustworthy-ML-Lab/effective_skill_unlearning)|
|51|[Fine-Grained and Efficient Self-Unlearning with Layered Iteration](https://doi.org/10.24963/ijcai.2025/850)|Hongyi Lyu, Xuyun Zhang, Hongsheng Hu, Shuo Wang, Chaoxiang He, Lianyong Qi|2025-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/Hongyi-Lyu-MQ/SULI)](https://github.com/Hongyi-Lyu-MQ/SULI)|
|52|[Efficient Unlearning with Privacy Guarantees](https://doi.org/10.48550/arXiv.2507.04771)|Josep Domingo-Ferrer, Najeeb Jebreel, David S√°nchez|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/najeebjebreel/EUPG)](https://github.com/najeebjebreel/EUPG)|
|53|[Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning](https://openreview.net/forum?id=mGOugCZlAq)|Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/tmlr-group/SatImp)](https://github.com/tmlr-group/SatImp)|
|54|[Efficient Knowledge Graph Unlearning with Zeroth-order Information](https://doi.org/10.48550/arXiv.2508.14013)|Yang Xiao, Ruimeng Ye, Bohan Liu, Xiaolong Ma, Bo Hui|2025-01-01|arXiv|[![Star](https://img.shields.io/github/stars/NKUShaw/ZOWFKGIF)](https://github.com/NKUShaw/ZOWFKGIF)|
|55|[Forget Vectors at Play: Universal Input Perturbations Driving Machine   Unlearning in Image Classification](https://doi.org/10.48550/arXiv.2412.16780)|Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|2024-12-21|arXiv|[![Star](https://img.shields.io/github/stars/Changchangsun/Forget-Vector)](https://github.com/Changchangsun/Forget-Vector)|
|56|[A Cognac Shot To Forget Bad Memories: Corrective Unlearning for Graph   Neural Networks](https://openreview.net/forum?id=epDkt44mkq)|Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru|2024-12-01|ICML|[![Star](https://img.shields.io/github/stars/cognac-gnn-unlearning/corrective-unlearning-for-gnns)](https://github.com/cognac-gnn-unlearning/corrective-unlearning-for-gnns)|
|57|[Delta-Influence: Unlearning Poisons via Influence Functions](https://doi.org/10.48550/arXiv.2411.13731)|Wenjie Li, Jiawei Li, Pengcheng Zeng, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal|2024-11-20|arXiv|[![Star](https://img.shields.io/github/stars/andyisokay/delta-influence)](https://github.com/andyisokay/delta-influence)|
|58|[Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning   Methods](https://doi.org/10.48550/arXiv.2411.12103)|Jai Doshi, Asa Cooper Stickland|2024-11-18|arXiv|[![Star](https://img.shields.io/github/stars/JaiDoshi/Knowledge-Erasure)](https://github.com/JaiDoshi/Knowledge-Erasure)|
|59|[Identify Backdoored Model in Federated Learning via Individual   Unlearning](https://doi.org/10.1109/WACV61041.2025.00773)|Jiahao Xu, Zikai Zhang, Rui Hu|2024-11-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/JiiahaoXU/MASA)](https://github.com/JiiahaoXU/MASA)|
|60|[Learning from Convolution-based Unlearnable Datasets](https://doi.org/10.48550/arXiv.2411.01742)|Dohyun Kim, Pedro Sandoval-Segura|2024-11-01|arXiv|[![Star](https://img.shields.io/github/stars/aseriesof-tubes/RSK)](https://github.com/aseriesof-tubes/RSK)|
|61|[Evaluating Deep Unlearning in Large Language Models](https://doi.org/10.48550/arXiv.2410.15153)|Ruihan Wu, Chhavi Yadav, Russ R. Salakhutdinov, Kamalika Chaudhuri|2024-10-19|arXiv|[![Star](https://img.shields.io/github/stars/wrh14/deep_unlearning)](https://github.com/wrh14/deep_unlearning)|
|62|[Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned   Concepts](https://doi.org/10.48550/arXiv.2410.12777)|Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin|2024-10-16|arXiv|[![Star](https://img.shields.io/github/stars/sail-sg/Meta-Unlearning)](https://github.com/sail-sg/Meta-Unlearning)|
|63|[Dissecting Fine-Tuning Unlearning in Large Language Models](https://doi.org/10.18653/v1/2024.emnlp-main.228)|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|2024-10-09|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/yihuaihong/Dissecting-FT-Unlearning)](https://github.com/yihuaihong/Dissecting-FT-Unlearning)|
|64|[A Probabilistic Perspective on Unlearning and Alignment for Large   Language Models](https://openreview.net/forum?id=51WraMid8K)|Yan Scholten, Stephan G√ºnnemann, Leo Schwinn|2024-10-04|arXiv|[![Star](https://img.shields.io/github/stars/yascho/probabilistic-unlearning)](https://github.com/yascho/probabilistic-unlearning)|
|65|[NegMerge: Sign-Consensual Weight Merging for Machine Unlearning](https://openreview.net/forum?id=ZbWXovStjD)|Hyo Seo Kim, Dongyoon Han, Junsuk Choe|2024-10-01|ICML|[![Star](https://img.shields.io/github/stars/naver-ai/negmerge)](https://github.com/naver-ai/negmerge)|
|66|[Simplicity Prevails: Rethinking Negative Preference Optimization for LLM   Unlearning](https://doi.org/10.48550/arXiv.2410.07163)|Chongyu Fan, Liu Jian-cheng, Licong Lin, Jinghan Jia, Ruiqi Zhang, Mei Song, Sijia Liu|2024-10-01|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Simple)](https://github.com/OPTML-Group/Unlearn-Simple)|
|67|[Alternate Preference Optimization for Unlearning Factual Knowledge in   Large Language Models](https://aclanthology.org/2025.coling-main.252/)|Anmol Reddy Mekala, Vineeth Dorna, Shreya Dubey, Abhishek Lalwani, David Koleczek, Mukund Rungta, Sadid A. Hasan, Elita ...|2024-09-20||[![Star](https://img.shields.io/github/stars/molereddy/Alternate-Preference-Optimization)](https://github.com/molereddy/Alternate-Preference-Optimization)|
|68|[Score Forgetting Distillation: A Swift, Data-Free Method for Machine   Unlearning in Diffusion Models](https://openreview.net/forum?id=gjwhDHeAsz)|Tianqi Chen, Shujian Zhang, Mingyuan Zhou|2024-09-17|arXiv|[![Star](https://img.shields.io/github/stars/tqch/score-forgetting-distillation)](https://github.com/tqch/score-forgetting-distillation)|
|69|[CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper   Influence](http://papers.nips.cc/paper_files/paper/2024/hash/b364953e402d7d92e13830383677efb5-Abstract-Datasets_and_Benchmarks_Track.html)|Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan|2024-08-26|NeurIPS|[![Star](https://img.shields.io/github/stars/xiye7lai/CURE4Rec)](https://github.com/xiye7lai/CURE4Rec)|
|70|[Scalable and Certifiable Graph Unlearning: Overcoming the Approximation   Error Barrier](https://openreview.net/forum?id=pPyJyeLriR)|Lu Yi, Zhewei Wei|2024-08-01|ICLR|[![Star](https://img.shields.io/github/stars/luyi256/ScaleGUN)](https://github.com/luyi256/ScaleGUN)|
|71|[Multimodal Unlearnable Examples: Protecting Data against Multimodal   Contrastive Learning](https://doi.org/10.48550/arXiv.2407.16307)|Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao|2024-07-23|ACM Multimedia|[![Star](https://img.shields.io/github/stars/thinwayliu/Multimodal-Unlearnable-Examples)](https://github.com/thinwayliu/Multimodal-Unlearnable-Examples)|
|72|[Safe Unlearning: A Surprisingly Effective and Generalizable Solution to   Defend Against Jailbreak Attacks](https://doi.org/10.48550/arXiv.2407.02855)|Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|2024-07-03|arXiv|[![Star](https://img.shields.io/github/stars/thu-coai/SafeUnlearning)](https://github.com/thu-coai/SafeUnlearning)|
|73|[Enable the Right to be Forgotten with Federated Client Unlearning in   Medical Imaging](https://doi.org/10.1007/978-3-031-72117-5_23)|Zhipeng Deng, Luyang Luo, Hao Chen|2024-07-02|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/dzp2095/FCU)](https://github.com/dzp2095/FCU)|
|74|[To Forget or Not? Towards Practical Knowledge Unlearning for Large   Language Models](https://doi.org/10.18653/v1/2024.findings-emnlp.82)|Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang|2024-07-01|OpenAlex|[![Star](https://img.shields.io/github/stars/zjunlp/KnowUnDo)](https://github.com/zjunlp/KnowUnDo)|
|75|[From Theft to Bomb-Making: The Ripple Effect of Unlearning in Defending   Against Jailbreak Attacks](http://arxiv.org/abs/2407.02855v3)|Zhexin Zhang, Junxiao Yang, Yida Lu, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|2024-07-01|arXiv|[![Star](https://img.shields.io/github/stars/thu-coai/SafeUnlearning)](https://github.com/thu-coai/SafeUnlearning)|
|76|[Data Attribution for Text-to-Image Models by Unlearning Synthesized   Images](http://papers.nips.cc/paper_files/paper/2024/hash/07fbde96bee50f4e09303fd4f877c2f3-Abstract-Conference.html)|Sheng-Yu Wang, Aaron Hertzmann, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang|2024-06-13|NeurIPS|[![Star](https://img.shields.io/github/stars/PeterWang512/AttributeByUnlearning)](https://github.com/PeterWang512/AttributeByUnlearning)|
|77|[Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning   Framework from Logit Difference](http://papers.nips.cc/paper_files/paper/2024/hash/171291d8fed723c6dfc76330aa827ff8-Abstract-Conference.html)|Jiabao Ji, Yujian Liu, Yang Zhang, Gaowen Liu, Ramana Rao Kompella, Sijia Liu, Shiyu Chang|2024-06-12|NeurIPS|[![Star](https://img.shields.io/github/stars/UCSB-NLP-Chang/ULD)](https://github.com/UCSB-NLP-Chang/ULD)|
|78|[Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces](https://doi.org/10.48550/arXiv.2406.11614)|Yihuai Hong, Lei Yu, Haiqin Yang, Shauli Ravfogel, Mor Geva|2024-06-01|arXiv|[![Star](https://img.shields.io/github/stars/yihuaihong/ConceptVectors)](https://github.com/yihuaihong/ConceptVectors)|
|79|[MUC: Machine Unlearning for Contrastive Learning with Black-box   Evaluation](https://openreview.net/forum?id=F9pjSDvuM9)|Yihan Wang, Yiwei Lu, Guojun Zhang, Franziska Boenisch, Adam Dziedzic, Yaoliang Yu, Xiao-Shan Gao|2024-06-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/EhanW/Alignment-Calibration)](https://github.com/EhanW/Alignment-Calibration)|
|80|[Defensive Unlearning with Adversarial Training for Robust Concept   Erasure in Diffusion Models](http://papers.nips.cc/paper_files/paper/2024/hash/40954ac18a457dd5f11145bae6454cdf-Abstract-Conference.html)|Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu|2024-05-24|NeurIPS|[![Star](https://img.shields.io/github/stars/OPTML-Group/AdvUnlearn)](https://github.com/OPTML-Group/AdvUnlearn)|
|81|[Unlearning during Learning: An Efficient Federated Machine Unlearning   Method](https://www.ijcai.org/proceedings/2024/446)|Hanlin Gu, Gongxi Zhu, Jie Zhang, Xinyuan Zhao, Yuxing Han, Lixin Fan, Qiang Yang|2024-05-24|OpenAlex|[![Star](https://img.shields.io/github/stars/Liar-Mask/FedAU)](https://github.com/Liar-Mask/FedAU)|
|82|[Erasing Concepts from Text-to-Image Diffusion Models with Few-shot   Unlearning](https://doi.org/10.48550/arXiv.2405.07288)|Masane Fuchi, Tomohiro Takagi|2024-05-12|BMVC|[![Star](https://img.shields.io/github/stars/fmp453/few-shot-erasing)](https://github.com/fmp453/few-shot-erasing)|
|83|[Purify Unlearnable Examples via Rate-Constrained Variational   Autoencoders](https://openreview.net/forum?id=0LBNdbmQCM)|Yi Yu, Yu-Fei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap‚ÄêPeng Tan, Alex C. Kot|2024-05-02|ICML|[![Star](https://img.shields.io/github/stars/yuyi-sd/D-VAE)](https://github.com/yuyi-sd/D-VAE)|
|84|[Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew   Resilience](https://doi.org/10.1007/978-3-031-70362-1_4)|Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Ab...|2024-05-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/thanhtrunghuynh93/fastFedUL)](https://github.com/thanhtrunghuynh93/fastFedUL)|
|85|[Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity](http://papers.nips.cc/paper_files/paper/2024/hash/2b09bb02b90584e2be94ff3ae09289bc-Abstract-Conference.html)|Hanlin Gu, Win Kent Ong, Chee Seng Chan, Lixin Fan|2024-05-01|NeurIPS|[![Star](https://img.shields.io/github/stars/OngWinKent/Federated-Feature-Unlearning)](https://github.com/OngWinKent/Federated-Feature-Unlearning)|
|86|[Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality   Constraints](https://doi.org/10.1609/aaai.v39i12.33367)|Yash Sinha, Murari Mandal, Mohan S. Kankanhalli|2024-05-01||[![Star](https://img.shields.io/github/stars/MachineUnlearn/MMRecUN)](https://github.com/MachineUnlearn/MMRecUN)|
|87|[SOUL: Unlocking the Power of Second-Order Optimization for LLM   Unlearning](https://doi.org/10.18653/v1/2024.emnlp-main.245)|Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2024-04-28|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/OPTML-Group/SOUL)](https://github.com/OPTML-Group/SOUL)|
|88|[Eraser: Jailbreaking Defense in Large Language Models via Unlearning   Harmful Knowledge](https://openreview.net/pdf/56792e044282ec46ecc14cfd3f68de33ed880b8e.pdf)|Weikai Lu, Ziqian Zeng, Jianwei Wang, Zhengdong Lu, Zelin Chen, Huiping Zhuang, Cen Chen|2024-04-08|OpenReview|[![Star](https://img.shields.io/github/stars/ZeroNLP/Eraser)](https://github.com/ZeroNLP/Eraser)|
|89|[Machine Unlearning for Document Classification](https://doi.org/10.1007/978-3-031-70546-5_6)|Lei Kang, Mohamed Ali Souibgui, Fei Yang, Lluis Gomez, Ernest Valveny, Dimosthenis Karatzas|2024-04-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/leitro/MachineUnlearning-DocClassification)](https://github.com/leitro/MachineUnlearning-DocClassification)|
|90|[Towards Efficient and Effective Unlearning of Large Language Models for   Recommendation](https://doi.org/10.1007/s11704-024-40044-2)|Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang, Yong Yu|2024-03-06|Frontiers of Computer Science|[![Star](https://img.shields.io/github/stars/justarter/E2URec)](https://github.com/justarter/E2URec)|
|91|[Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine   Unlearning](https://doi.org/10.1007/978-3-031-72664-4_16)|Chongyu Fan, Jiancheng Liu, Alfred Olivier Hero, Sijia Liu|2024-03-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-WorstCase)](https://github.com/OPTML-Group/Unlearn-WorstCase)|
|92|[Towards Lifecycle Unlearning Commitment Management: Measuring   Sample-level Approximate Unlearning Completeness](https://www.usenix.org/conference/usenixsecurity25/presentation/wang-cheng-long)|Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang|2024-03-01|USENIX Security Symposium|[![Star](https://img.shields.io/github/stars/Happy2Git/Unlearning_Inference_IAM)](https://github.com/Happy2Git/Unlearning_Inference_IAM)|
|93|[UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning   for Diffusion Models](https://doi.org/10.48550/arXiv.2402.11846)|Yihua Zhang, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Xiaoming Liu, Sijia Liu|2024-02-19|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/UnlearnCanvas)](https://github.com/OPTML-Group/UnlearnCanvas)|
|94|[Corrective Machine Unlearning](https://local.forskningsportal.dk/local/dki-cgi/ws/cris-link?src=ku&id=ku-3bc52420-b6c0-4ebf-a0ea-0dedef731af7&ti=Corrective%20Machine%20Unlearning)|Shashwat Goel, Ameya Prabhu, Philip H. S. Torr, Ponnurangam Kumaraguru, Amartya Sanyal|2024-01-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/drimpossible/corrective-unlearning-bench)](https://github.com/drimpossible/corrective-unlearning-bench)|
|95|[Machine Unlearning in Generative AI: A Survey](https://doi.org/10.48550/arXiv.2407.20516)|Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/franciscoliu/GenAI-MU-Reading)](https://github.com/franciscoliu/GenAI-MU-Reading)|
|96|[A Closer Look at Machine Unlearning for Large Language Models](https://openreview.net/forum?id=Q1MHvGmhyT)|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/sail-sg/closer-look-LLM-unlearning)](https://github.com/sail-sg/closer-look-LLM-unlearning)|
|97|[Dataset Condensation Driven Machine Unlearning](https://doi.org/10.48550/arXiv.2402.00195)|Junaid Iqbal Khan|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/algebraicdianuj/DC_U)](https://github.com/algebraicdianuj/DC_U)|
|98|[Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need](http://papers.nips.cc/paper_files/paper/2024/hash/b3d868b4b5b61b35a849ba6e7a1d4449-Abstract-Conference.html)|Xianlong Wang, Minghui Li, Weiping Liu, Hangtao Zhang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Hai Jin|2024-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/CGCL-codes/UnlearnablePC)](https://github.com/CGCL-codes/UnlearnablePC)|
|99|[Soft Prompting for Unlearning in Large Language Models](https://doi.org/10.18653/v1/2025.naacl-long.204)|Karuna Bhaila, Minh-Hao Van, Xintao Wu|2024-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/karuna-bhaila/llm_unlearning)](https://github.com/karuna-bhaila/llm_unlearning)|
|100|[Revisiting Who&apos;s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective](https://doi.org/10.18653/v1/2024.emnlp-main.495)|Yujian Liu, Yang Zhang, Tommi S. Jaakkola, Shiyu Chang|2024-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|[![Star](https://img.shields.io/github/stars/UCSB-NLP-Chang/causal_unlearn)](https://github.com/UCSB-NLP-Chang/causal_unlearn.git)|
|101|[Machine Unlearning via Representation Forgetting With Parameter Self-Sharing](https://doi.org/10.1109/TIFS.2023.3331239)|Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu|2024-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/wwq5-code/RFU-SS)](https://github.com/wwq5-code/RFU-SS.git)|
|102|[Machine Unlearning via Null Space Calibration](https://www.ijcai.org/proceedings/2024/40)|Huiqiang Chen, Tianqing Zhu, Xinjie Yu, Wanlei Zhou|2024-01-01|OpenAlex|[![Star](https://img.shields.io/github/stars/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration)](https://github.com/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration)|
|103|[Boosting Alignment for Post-Unlearning Text-to-Image Generative Models](http://papers.nips.cc/paper_files/paper/2024/hash/9aa51796f8bede2ea947d6b6e3087ab8-Abstract-Conference.html)|Myeongseob Ko, Henry Li, Zhun Wang, Jonathan Patsenker, Jiachen T. Wang, Qinbin Li, Ming Jin, Dawn Song, Ruoxi Jia|2024-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/reds-lab/Restricted_gradient_diversity_unlearning)](https://github.com/reds-lab/Restricted_gradient_diversity_unlearning.git)|
|104|[Machine Unlearning of Pre-trained Large Language Models](https://openreview.net/pdf/fe1970154c67c30db5b9431d2efc8b5d8ece2dee.pdf)|Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue|2024-01-01|OpenReview|[![Star](https://img.shields.io/github/stars/yaojin17/Unlearning_LLM)](https://github.com/yaojin17/Unlearning_LLM)|
|105|[Machine Unlearning for Image-to-Image Generative Models](https://openreview.net/forum?id=9hjVoPWPnh)|Guihong Li, Hsiang Hsu, Chun-Fu, Chen, Diana Marculescu|2024-01-01|ICLR|[![Star](https://img.shields.io/github/stars/jpmorganchase/l2l-generator-unlearning)](https://github.com/jpmorganchase/l2l-generator-unlearning)|
|106|[Large Language Model Unlearning via Embedding-Corrupted Prompts](http://papers.nips.cc/paper_files/paper/2024/hash/d6359156e0e30b1caa116a4306b12688-Abstract-Conference.html)|Chris Yuhao Liu, Yaxuan Wang, Jeffrey Flanigan, Yang Liu|2024-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/chrisliu298/llm-unlearn-eco)](https://github.com/chrisliu298/llm-unlearn-eco)|
|107|[LMEraser: Large Model Unlearning through Adaptive Prompt Tuning](https://proceedings.mlr.press/v258/xu25e.html)|Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia|2024-01-01|AISTATS|[![Star](https://img.shields.io/github/stars/lmeraser/lmeraser)](https://github.com/lmeraser/lmeraser)|
|108|[Generative Unlearning for Any Identity](https://doi.org/10.1109/CVPR52733.2024.00874)|Juwon Seo, Sung-Hoon Lee, Tae-Young Lee, Seungjun Moon, Gyeong-Moon Park|2024-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/KHU-AGI/GUIDE)](https://github.com/KHU-AGI/GUIDE)|
|109|[Game-Theoretic Unlearnable Example Generator](https://doi.org/10.1609/aaai.v38i19.30130)|Shuang Liu, Yihan Wang, Xiao-Shan Gao|2024-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/hong-xian/gue)](https://github.com/hong-xian/gue)|
|110|[From Hope to Safety: Unlearning Biases of Deep Models via Gradient Penalization in Latent Space](https://doi.org/10.1609/aaai.v38i19.30096)|Maximilian Dreyer, Frederik Pahde, Christopher J. Anders, Wojciech Samek, Sebastian Lapuschkin|2024-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/frederikpahde/rrclarc)](https://github.com/frederikpahde/rrclarc)|
|111|[Efficient Federated Unlearning under Plausible Deniability](https://doi.org/10.1007/s10994-024-06685-x)|Ayush K. Varshney, Vicen√ß Torra|2024-01-01|Machine Learning|[![Star](https://img.shields.io/github/stars/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability)](https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability)|
|112|[Dissecting Language Models: Machine Unlearning via Selective Pruning](https://doi.org/10.48550/arXiv.2403.01267)|Nicholas Pochinkov, Nandi Schoots|2024-01-01|arXiv|[![Star](https://img.shields.io/github/stars/nickypro/selective-pruning)](https://github.com/nickypro/selective-pruning)|
|113|[Breaking the Trilemma of Privacy, Utility, and Efficiency via Controllable Machine Unlearning](https://doi.org/10.48550/arXiv.2310.18574)|Zheyuan Liu, Guangyao Dou, Wang-Chien Chen, Chunhui Zhang, Yijun Tian, Ziwei Zhu|2024-01-01|Proceedings of the ACM Web Conference 2022|[![Star](https://img.shields.io/github/stars/guangyaodou/ConMU)](https://github.com/guangyaodou/ConMU)|
|114|[FedCSA: Boosting the Convergence Speed of Federated Unlearning under Data Heterogeneity](https://doi.org/10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00083)|Zhen Wang, Daniyal M. Alghazzawi, Li Cheng, Gaoyang Liu, Chen Wang, Zeng Cheng, Yang Yang|2023-12-21|ISPA/BDCloud/SocialCom/SustainCom|[![Star](https://img.shields.io/github/stars/ZhenWang9/FedCSA)](https://github.com/ZhenWang9/FedCSA)|
|115|[Deep Unlearning: Fast and Efficient Gradient-free Approach to Class   Forgetting](https://openreview.net/forum?id=BmI5p6wBi0)|Sangamesh Kodge, Gobinda Saha, Kaushik Roy|2023-12-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/sangamesh-kodge/class_forgetting)](https://github.com/sangamesh-kodge/class_forgetting)|
|116|[Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning   Interference with Gradient Projection](https://doi.org/10.1109/WACV57701.2024.00475)|Tuan Hoang, Santu Rana, Sunil Gupta, Svetha Venkatesh|2023-12-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|[![Star](https://img.shields.io/github/stars/hnanhtuan/projected_gradient_unlearning)](https://github.com/hnanhtuan/projected_gradient_unlearning)|
|117|[Towards Machine Unlearning Benchmarks: Forgetting the Personal   Identities in Facial Recognition Systems](https://doi.org/10.48550/arXiv.2311.02240)|Dasol Choi, Dongbin Na|2023-11-01|arXiv|[![Star](https://img.shields.io/github/stars/ndb796/MachineUnlearning)](https://github.com/ndb796/MachineUnlearning)|
|118|[Stable Unlearnable Example: Enhancing the Robustness of Unlearnable   Examples via Stable Error-Minimizing Noise](https://doi.org/10.48550/arXiv.2311.13091)|Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun|2023-11-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/liuyixin-louis/Stable-Unlearnable-Example)](https://github.com/liuyixin-louis/Stable-Unlearnable-Example)|
|119|[To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still   Easy To Generate Unsafe Images ... For Now](https://doi.org/10.1007/978-3-031-72998-0_22)|Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu|2023-10-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/OPTML-Group/Diffusion-MU-Attack)](https://github.com/OPTML-Group/Diffusion-MU-Attack)|
|120|[SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency   in Both Image Classification and Generation](https://openreview.net/forum?id=gn0mIhQGNM)|Chongyu Fan, Jiancheng Liu, Yihua Zhang, Eric Wong, Dennis Wei, Sijia Liu|2023-10-01|arXiv|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Saliency)](https://github.com/OPTML-Group/Unlearn-Saliency)|
|121|[Distill to Delete: Unlearning in Graph Networks with Knowledge   Distillation](https://doi.org/10.48550/arXiv.2309.16173)|Yash Sinha, Murari Mandal, Mohan S. Kankanhalli|2023-09-01|PubMed|[![Star](https://img.shields.io/github/stars/MachineUnlearn/D2DGN)](https://github.com/MachineUnlearn/D2DGN)|
|122|[Fair Machine Unlearning: Data Removal while Mitigating Disparities](https://proceedings.mlr.press/v238/oesterling24a.html)|Alex Oesterling, Jiaqi Ma, Fl√°vio P. Calmon, Himabindu Lakkaraju|2023-07-01|AISTATS|[![Star](https://img.shields.io/github/stars/AI4LIFE-GROUP/fair-unlearning)](https://github.com/AI4LIFE-GROUP/fair-unlearning)|
|123|[Fast Yet Effective Machine Unlearning](https://doi.org/10.1109/tnnls.2023.3266233)|Ayush K. Tarun, Vikram S. Chundawat, Murari Mandal, Mohan S. Kankanhalli|2023-05-01|IEEE Transactions on Neural Networks and Learning Systems|[![Star](https://img.shields.io/github/stars/vikram2000b/Fast-Machine-Unlearning)](https://github.com/vikram2000b/Fast-Machine-Unlearning)|
|124|[Unlearnable Examples Give a False Sense of Security: Piercing through   Unexploitable Data with Learnable Examples](https://doi.org/10.48550/arXiv.2305.09241)|Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong|2023-05-01|ACM Multimedia|[![Star](https://img.shields.io/github/stars/jiangw-0/LE_JCDP)](https://github.com/jiangw-0/LE_JCDP)|
|125|[CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning](https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf)|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023-04-16|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|
|126|[Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural   Networks](https://openreview.net/pdf/e61ee961464c8ff0055125464944b1b3ca4bb37a.pdf)|Vijaya Raghavan T. Ramkumar, Elahe Arani, Bahram Zonooz|2023-03-01|Trans. Mach. Learn. Res.|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learn-unlearn-and-relearn-an-online-learning/code)|
|127|[Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable   Example Attacks](https://doi.org/10.48550/arXiv.2303.15127)|Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu|2023-03-01|arXiv|[![Star](https://img.shields.io/github/stars/lafeat/ueraser)](https://github.com/lafeat/ueraser)|
|128|[Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding ](https://openreview.net/pdf/b3f85b26464b6cd916b9a66adb82d3d295c951c4.pdf)|Abdullah Hamdi, Silvio Giancola, Bernard Ghanem|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/voint-cloud-multi-view-point-cloud/code)|
|129|[Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks](https://openreview.net/pdf/0e2acc3ed9aaaff91e94533aa1eb2cec3a27915b.pdf)|Noam Wies, Yoav Levine, Amnon Shashua|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/sub-task-decomposition-enables-learning-in/code)|
|130|[One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks](https://openreview.net/pdf/b69561625d5ce4388db999c205fdb5a8b988725e.pdf)|Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang|2023-02-01|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/one-pixel-shortcut-on-the-learning-preference/code)|
|131|[Zero-Shot Machine Unlearning](https://doi.org/10.1109/tifs.2023.3265506)|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|2023-01-01|IEEE Transactions on Information Forensics and Security|[![Star](https://img.shields.io/github/stars/ayu987/zero-shot-unlearning)](https://github.com/ayu987/zero-shot-unlearning)|
|132|[Task-Aware Machine Unlearning and Its Application in Load Forecasting](https://doi.org/10.1109/tpwrs.2024.3376828)|Wangkun Xu, Fei Teng|2023-01-01|IEEE Transactions on Power Systems|[![Star](https://img.shields.io/github/stars/xuwkk/task_aware_machine_unlearning)](https://github.com/xuwkk/task_aware_machine_unlearning)|
|133|[What Can We Learn from Unlearnable Datasets?](http://papers.nips.cc/paper_files/paper/2023/hash/ee5bb72130c332c3d4bf8d231e617506-Abstract-Conference.html)|Pedro Sandoval Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein|2023-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/psandovalsegura/learn-from-unlearnable)](https://github.com/psandovalsegura/learn-from-unlearnable)|
|134|[Unlearning Bias in Language Models by Partitioning Gradients](https://doi.org/10.18653/v1/2023.findings-acl.375)|Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, Heng Ji|2023-01-01|Findings of the Association for Computational Linguistics: ACL 2022|[![Star](https://img.shields.io/github/stars/CharlesYu2000/PCGU-UnlearningBias)](https://github.com/CharlesYu2000/PCGU-UnlearningBias)|
|135|[Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples](https://doi.org/10.1109/CVPR52729.2023.00388)|Jiaming Zhang, Xingjun Ma, Qi Yi, Jitao Sang, Yu-Gang Jiang, Yaowei Wang, Changsheng Xu|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/jiamingzhang94/Unlearnable-Clusters)](https://github.com/jiamingzhang94/Unlearnable-Clusters)|
|136|[Inductive Graph Unlearning](https://www.usenix.org/conference/usenixsecurity23/presentation/wang-cheng-long)|Cheng-Long Wang, Mengdi Huai, Di Wang|2023-01-01|USENIX Security Symposium|[![Star](https://img.shields.io/github/stars/Happy2Git/GUIDE)](https://github.com/Happy2Git/GUIDE)|
|137|[Recommendation Unlearning via Influence Function](https://doi.org/10.48550/arXiv.2307.02147)|Yang Zhang, Zhiyu Hu, Yimeng Bai, Fuli Feng, Jiancan Wu, Qifan Wang, Xiangnan He|2023-01-01|ACM Transactions on Recommender Systems|[![Star](https://img.shields.io/github/stars/baiyimeng/IFRU)](https://github.com/baiyimeng/IFRU)|
|138|[Model Sparsification Can Simplify Machine Unlearning](http://papers.nips.cc/paper_files/paper/2023/hash/a204aa68ab4e970e1ceccfb5b5cdc5e4-Abstract-Conference.html)|Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu, Yang Liu, Pranay Sharma, Sijia Liu|2023-01-01|NeurIPS|[![Star](https://img.shields.io/github/stars/OPTML-Group/Unlearn-Sparse)](https://github.com/OPTML-Group/Unlearn-Sparse)|
|139|[A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions](https://doi.org/10.48550/arXiv.2310.19218)|Jiaxi Yang, Yang Zhao|2023-01-01|arXiv|[![Star](https://img.shields.io/github/stars/abbottyanginchina/Awesome-Federated-Unlearning)](https://github.com/abbottyanginchina/Awesome-Federated-Unlearning)|
|140|[Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning   in Generative Adversarial Networks](https://openreview.net/forum?id=jAHEBivObO)|Piyush Tiwary, Atri Guha, Subhodip Panda, Prathosh A. P.|2023-01-01|Trans. Mach. Learn. Res.|[![Star](https://img.shields.io/github/stars/atriguha/Adapt_Unlearn)](https://github.com/atriguha/Adapt_Unlearn)|
|141|[GIF: A General Graph Unlearning Strategy via Influence Function](https://doi.org/10.48550/arXiv.2304.02835)|Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He|2023-01-01|Proceedings of the ACM Web Conference 2022|[![Star](https://img.shields.io/github/stars/wujcan/GIF-torch)](https://github.com/wujcan/GIF-torch)|
|142|[GNNDelete: A General Strategy for Unlearning in Graph Neural Networks](https://openreview.net/pdf/d344e51366b6eeb1347bf96857a1cdeb5ca03e64.pdf)|Jiali Cheng, George Dasoulas, Huan He, Chirag Agarwal, Marinka Zitnik|2023-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/gnndelete-a-general-strategy-for-unlearning/code)|
|143|[ERM-KTP: Knowledge-Level Machine Unlearning via Knowledge Transfer](https://doi.org/10.1109/CVPR52729.2023.01929)|Shen Lin, Xiaoyu Zhang, Chenyang Chen, Xiaofeng Chen, Willy Susilo|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|[![Star](https://img.shields.io/github/stars/RUIYUN-ML/ERM-KTP)](https://github.com/RUIYUN-ML/ERM-KTP)|
|144|[PatchGT: Transformer over Non-trainable Clusters for Learning Graph Representations](https://openreview.net/pdf/7a95f2c19eec64ed2379944a8398af365f166ed3.pdf)|Han Gao, Xu Han, Jiaoyang Huang, Jian-Xun Wang, Liping Liu|2022-11-24|LoG 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/patchgt-transformer-over-non-trainable/code)|
|145|[Autoregressive Perturbations for Data Poisoning](https://openreview.net/pdf/f465f9046724189ffd748375c5f6a4ac4d722e10.pdf)|Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W. Jacobs|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/autoregressive-perturbations-for-data/code)|
|146|[The Privacy Onion Effect: Memorization is Relative](https://openreview.net/pdf/9693b6b162a476e99f5438ece8d66f14a520d97b.pdf)|Nicholas Carlini, Matthew Jagielski, Chiyuan Zhang, Nicolas Papernot, Andreas Terzis, Florian Tramer|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/the-privacy-onion-effect-memorization-is/code)|
|147|[Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork](https://openreview.net/pdf/a0b040b733099d83fd30969cd35fa8cc35c367b2.pdf)|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/trap-and-replace-defending-backdoor-attacks/code)|
|148|[Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models](https://openreview.net/pdf/cbffa1a0bf2612f146adbc70397e00fc131d2db4.pdf)|Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/exploring-the-limits-of-domain-adaptive/code)|
|149|[Characterizing Datapoints via Second-Split Forgetting](https://openreview.net/pdf/4e3bb598ca199212473a7389946dde4baf3d97b1.pdf)|Pratyush Maini, Saurabh Garg, Zachary Chase Lipton, J Zico Kolter|2022-07-20|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/characterizing-datapoints-via-second-split/code)|
|150|[Deep Unlearning via Randomized Conditionally Independent Hessians](https://doi.org/10.1109/cvpr52688.2022.01017)|Ronak Mehta, Sourav Pal, Vikas Pratap Singh, Sathya N. Ravi|2022-06-01||[![Star](https://img.shields.io/github/stars/vsingh-group/LCODEC-deep-unlearning)](https://github.com/vsingh-group/LCODEC-deep-unlearning)|
|151|[Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an   Incompetent Teacher](https://doi.org/10.48550/arXiv.2205.08096)|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|2022-05-01|Proceedings of the AAAI Conference on Artificial Intelligence|[![Star](https://img.shields.io/github/stars/vikram2000b/bad-teaching-unlearning)](https://github.com/vikram2000b/bad-teaching-unlearning)|
|152|[Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning](https://openreview.net/pdf/cb11d28b469a29f68dc6043214ae3f4f579b360a.pdf)|Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao|2022-03-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/robust-unlearnable-examples-protecting-data/code)|
|153|[Knowledge Removal in Sampling-based Bayesian Inference](https://openreview.net/pdf/a42ad90a502167268f1ba4c67f57150bf59ccbc9.pdf)|Shaopeng Fu, Fengxiang He, Dacheng Tao|2022-01-28|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/knowledge-removal-in-sampling-based-bayesian/code)|
|154|[Knowledge Unlearning for Mitigating Privacy Risks in Language Models](https://openreview.net/pdf/b13e3c3cdc06b81ed93687d74823ddd0aef79674.pdf)|Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo|2022-01-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/knowledge-unlearning-for-mitigating-privacy/code)|
|155|[Recommendation Unlearning](https://openreview.nethttps://arxiv.org/pdf/2201.06820.pdf)|Chong Chen, Fei Sun, Min Zhang, Bolin Ding|2022-01-01|Proceedings of the ACM Web Conference 2022|[![Star](https://img.shields.io/github/stars/chenchongthu/Recommendation-Unlearning)](https://github.com/chenchongthu/Recommendation-Unlearning)|
|156|[QUARK: Controllable Text Generation with Reinforced Unlearning](http://papers.nips.cc/paper_files/paper/2022/hash/b125999bde7e80910cbdbd323087df8f-Abstract-Conference.html)|Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, Yejin Choi|2022-01-01|NeurIPS 2022 (Oral Selection)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/quark-controllable-text-generation-with/code)|
|157|[Machine Unlearning of Federated Clusters](https://openreview.net/pdf/51ee65b11a32de7ad446a5917d748f9da5399714.pdf)|Chao Pan, Jin Sima, Saurav Prakash, Vishal Singh Rana, Olgica Milenkoviƒá|2022-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/machine-unlearning-of-federated-clusters/code)|
|158|[FedHarmony: Unlearning Scanner Bias with Distributed Data](https://doi.org/10.1007/978-3-031-16452-1_66)|Nicola K. Dinsdale, Mark Jenkinson, Ana I. L. Namburete|2022-01-01|Lecture notes in computer science|[![Star](https://img.shields.io/github/stars/nkdinsdale/FedHarmony)](https://github.com/nkdinsdale/FedHarmony)|
|159|[Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks](http://papers.nips.cc/paper_files/paper/2023/hash/8b4add8b0aa8749d80a34ca5d941c355-Abstract-Conference.html)|Jimmy Z. Di, Jack F. Douglas, Jayadev Acharya, Gautam Kamath, Ayush Sekhari|2022-01-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/hidden-poison-machine-unlearning-enables/code)|
|160|[Deep Regression Unlearning](https://proceedings.mlr.press/v202/tarun23a.html)|Ayush Kumar Tarun, Vikram Singh Chundawat, Murari Mandal, Mohan S. Kankanhalli|2022-01-01|arXiv|[![Star](https://img.shields.io/github/stars/ayu987/deep-regression-unlearning)](https://github.com/ayu987/deep-regression-unlearning)|
|161|[Continual Learning and Private Unlearning](https://proceedings.mlr.press/v199/liu22a.html)|Bo Liu, Qiang Liu, Peter Stone|2022-01-01|CoLLAs|[![Star](https://img.shields.io/github/stars/Cranial-XIX/Continual-Learning-Private-Unlearning)](https://github.com/Cranial-XIX/Continual-Learning-Private-Unlearning)|
|162|[Atlas: Universal Function Approximator For Memory Retention](https://openreview.net/pdf/95b89482f610b970f80506d51d6924d79cd125e6.pdf)|Heinrich van Deventer, Anna Sergeevna Bosman|2022-01-01|NeurIPS 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/atlas-universal-function-approximator-for/code)|
|163|[Adversarial Unlearning: Reducing Confidence Along Adversarial Directions](http://papers.nips.cc/paper_files/paper/2022/hash/75f1a165c7561e028c41d42fa6286a76-Abstract-Conference.html)|Amrith Setlur, Benjamin Eysenbach, Virginia Smith, Sergey Levine|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-reducing-confidence/code)|
|164|[A Survey of Machine Unlearning](https://doi.org/10.48550/arXiv.2209.02299)|Thanh Tam Nguyen, Thanh Trung Huynh, Zhao Ren, Phi Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin, Quoc Viet Hung Nguyen|2022-01-01|ACM Transactions on Intelligent Systems and Technology|[![Star](https://img.shields.io/github/stars/tamlhp/awesome-machine-unlearning)](https://github.com/tamlhp/awesome-machine-unlearning)|
|165|[Certified Graph Unlearning](https://openreview.net/pdf/255ad2fc5a24c56a6f91f08eabdfdd9ba94a3bf2.pdf)|Eli Chien, Chao Pan, Olgica Milenkovic|2022-01-01|NeurIPS 2022 GLFrontiers Workshop|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/certified-graph-unlearning/code)|
|166|[Adaptive Machine Unlearning](https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html)|Varun Gupta, Christopher Jung, Seth Neel, Aaron Roth, Saeed Sharifi -Malvajerdi, Christopher Waites|2021-11-09|Neural Information Processing Systems|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adaptive-machine-unlearning/code)|
|167|[Unlearnable Examples: Making Personal Data Unexploitable](https://openreview.net/pdf/eb123b0f1c20d0c5d47b33fa7feca81748e02666.pdf)|Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang|2021-01-13|ICLR 2021 Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unlearnable-examples-making-personal-data/code)|
|168|[Adversarial Unlearning of Backdoors via Implicit Hypergradient](https://openreview.net/pdf/6aeb6e81c9d0eadbb4cfbefb6caac0f155d561ea.pdf)|Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia|2021-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-of-backdoors-via/code)|
|169|[Towards Probabilistic Verification of Machine Unlearning](http://arxiv.org/abs/2003.04247v2)|David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal|2020-01-01|arXiv|[![Star](https://img.shields.io/github/stars/inspire-group/unlearning-verification)](https://github.com/inspire-group/unlearning-verification)|
|170|[When Machine Unlearning Jeopardizes Privacy](https://doi.org/10.1145/3460120.3484756)|Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang|2020-01-01|Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security|[![Star](https://img.shields.io/github/stars/MinChen00/UnlearningLeaks)](https://github.com/MinChen00/UnlearningLeaks)|
|171|[Learnability for the Information Bottleneck](https://openreview.net/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf)|Tailin Wu, Ian Fischer, Isaac Chuang, Max Tegmark|2019-04-17|LLD 2019|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learnability-for-the-information-bottleneck/code)|

![Star History Chart](https://api.star-history.com/svg?repos=mtuann/machine-unlearning-papers&type=Date)

