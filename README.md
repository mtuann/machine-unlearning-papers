# Table of Contents
1. [Machine Unlearning Papers](#machine-unlearning-papers)
2. [Other Research Topics](#other-research-topics)
3. [Machine Unlearning Papers with Code](#machine-unlearning-papers-with-code)
4. [Data Sources](#data-sources)
5. [Contributing](#contributing)
6. [Support](#support)

## Machine Unlearning Papers
This GitHub repository contains an updated list of Machine Unlearning papers as of **October 06, 2025**. 

### Overview
- **Total Papers**: Updated regularly with latest publications
- **Coverage**: Papers from 2016 to present
- **Sources**: Collected from arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, IEEE, ACM, Springer, ScienceDirect, Nature, and other top AI/ML conferences and journals
- **Interactive Search**: For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/)

### Key Features
- üìä **Comprehensive Coverage**: Papers from major AI/ML venues
- üîç **Advanced Search**: Filter by title, author, venue, year
- üìÖ **Regular Updates**: Automated collection of new papers
- üíª **Code Availability**: Identifies papers with available code
- üìà **Trending Research**: Focus on cutting-edge developments

---

## Other Research Topics
Explore additional research papers on the following topics:

### Machine Learning & AI
- **[Large Language Models](https://github.com/mtuann/llm-updated-papers)** - LLM research and applications
- **[Federated Learning](https://github.com/mtuann/federated-learning-updated-papers)** - Distributed machine learning
- **[Backdoor Learning](https://github.com/mtuann/backdoor-ai-resources)** - Adversarial machine learning
- **[Machine Unlearning](https://github.com/mtuann/machine-unlearning-papers)** - Data removal and privacy

### Computing & Systems
- **[Serverless Computing](https://mtuann.shinyapps.io/research-papers/)** - Cloud computing architectures
- **[Multi-Modal Learning](https://mtuann.shinyapps.io/research-papers/)** - Multi-modal AI systems

### Interactive Platforms
- **[Research Papers App](https://mtuann.shinyapps.io/research-papers/)** - Search and explore all papers
- **[Paper Collections](https://github.com/mtuann/research-papers)** - Main repository with all datasets

---

## Data Sources
The papers are collected from the following sources:

### Academic Databases
- **arXiv** (1991-present) - Preprints and published papers
- **OpenReview** - Conference submissions and peer reviews
- **ACM Digital Library** - Computer science publications
- **Springer** - Academic journals and conferences
- **ScienceDirect** - Elsevier publications
- **Nature** - High-impact research papers
- **DBLP** - Computer science bibliography
- **Google Scholar** - Academic search engine
- **CrossRef** - DOI registration agency
- **OpenAlex** - Open scholarly data

### Major Conferences & Journals
- **Machine Learning**: NeurIPS, ICML, ICLR, JMLR, TMLR
- **Natural Language Processing**: ACL, EMNLP, NAACL, COLING
- **Computer Vision**: CVPR, ICCV, ECCV, PAMI, IJCV
- **Artificial Intelligence**: AAAI, IJCAI, AAMAS
- **Data Mining**: KDD, ICDM, SDM, TKDD
- **Security & Privacy**: CCS, USENIX Security, NDSS
- **And many more...**

---

## Machine Unlearning Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publication date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

<!-- 
### Summary Statistics
- **Total Papers in Dataset**: 2,413
- **Papers with Available Code**: 161
- **Code Availability Rate**: 6.7%
- **Last Updated**: October 06, 2025

### Paper Statistics
- **Total Papers**: 2413
- **Papers with Code**: 2413
- **Latest Update**: 2413
- **Coverage Period**: 2016 - Present -->

---

## Contributing
We welcome contributions to improve this paper collection:

### How to Contribute
1. **Add Missing Papers**: Submit papers that should be included
2. **Improve Metadata**: Help enhance paper information
3. **Report Issues**: Identify bugs or missing features
4. **Suggest Improvements**: Propose new features or enhancements

### Contact Information
- **Email**: [tuannm0312@gmail.com](mailto:tuannm0312@gmail.com)
- **GitHub Issues**: [Create an issue](https://github.com/mtuann/research-papers/issues)
- **Discussions**: [Join the discussion](https://github.com/mtuann/research-papers/discussions)

---

## Support
If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:

### Payment Methods
- **Techcombank (Vietnam)**: 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card**: [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

### Why Support?
Your support helps maintain and improve:
- ü§ñ Automated paper collection pipeline
- üåê Interactive web application
- üìä Regular data updates
- üîß System maintenance and improvements
- üìö New research area coverage

---

**Note**: This repository is regularly updated with new papers. For the most current data, check the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/) or the individual topic repositories linked above.


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|Training wide residual networks for deployment using a single bit for each weight|Mark D. McDonnell||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/training-wide-residual-networks-for/code)|https://openreview.net/pdf/861cb006a62eb71925571a5d4979901d047a92ea.pdf|
|2|Multitask Soft Option Learning|Maximilian Igl, Andrew Gambardella, Jinke He, Nantas Nardelli, N. Siddharth, Wendelin B√∂hmer, Shimon Whiteson||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/multitask-soft-option-learning/code)|https://openreview.net/pdf/5e7c12118369a575ab52f9fb553689c36468b080.pdf|
|3|Compressed Sensing with Deep Image Prior and Learned Regularization|Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, Alexandros G. Dimakis||OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/compressed-sensing-with-deep-image-prior-and/code)|https://openreview.net/pdf/960068efdade58de64b1b641bcccfdba53ac168b.pdf|
|4|Leveraging Distribution Matching to Make Approximate Machine Unlearning   Faster|Junaid Iqbal Khan|2025-07-01|arXiv|https://github.com/algebraicdianuj/DC_Unlearning.|https://doi.org/10.48550/arXiv.2507.09786|
|5|Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack   against Image Generation Model Unlearning|Renyang Liu, Guanlin Li, Tianwei Zhang, See-Kiong Ng|2025-07-01|arXiv|https://github.com/ryliu68/RECALL|https://doi.org/10.48550/arXiv.2507.07139|
|6|Forget-MI: Machine Unlearning for Forgetting Multimodal Information in   Healthcare Settings|Shahad Hardan, Darya Taratynova, Abdelmajid Essofi, Karthik Nandakumar, Mohammad Yaqub|2025-06-01|MICCAI|https://github.com/BioMedIA-MBZUAI/Forget-MI.git|https://doi.org/10.1007/978-3-032-04947-6_20|
|7|Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation   and Confidence Awareness|Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chi...|2025-06-01|arXiv|https://github.com/Graph-COM/Knowledge_Unlearning.git.|https://doi.org/10.48550/arXiv.2506.05735|
|8|Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from   Model Outputs|Yiwei Chen, Soumyadeep Pal, Yimeng Zhang, Qing Qu, Sijia Liu|2025-06-01|arXiv|https://github.com/OPTML-Group/Unlearn-Trace.|http://arxiv.org/abs/2506.14003v2|
|9|Unlearning Sensitive Information in Multimodal LLMs: Benchmark and   Attack-Defense Evaluation|Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal|2025-05-01|Trans. Mach. Learn. Res.|https://github.com/Vaidehi99/UnLOK-VQA|https://openreview.net/forum?id=YcnjgKbZQS|
|10|Unlearning Isn't Deletion: Investigating Reversibility of Machine   Unlearning in LLMs|Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du|2025-05-01|arXiv|https://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.|http://arxiv.org/abs/2505.16831v1|
|11|Unlearning for Federated Online Learning to Rank: A Reproducibility   Study|Yiling Tao, Shuyi Wang, Jiaxi Yang, Guido Zuccon|2025-05-01|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/Iris1026/Unlearning-for-FOLTR.git.|https://doi.org/10.48550/arXiv.2505.12791|
|12|LoRA Unlearns More and Retains More (Student Abstract)|Atharv Mittal|2025-04-11|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/vlgiitr/LoRA-Unlearn.|https://doi.org/10.1609/aaai.v39i28.35277|
|13|LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in   Current Benchmarks|Soumyadeep Pal, Changsheng Wang, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2025-04-01|arXiv|https://github.com/OPTML-Group/MU-Coreset.|https://doi.org/10.48550/arXiv.2504.10185|
|14|Multi-Objective Large Language Model Unlearning|Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao|2025-03-12|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/zibinpan/MOLLM.|https://doi.org/10.1109/icassp49660.2025.10889776|
|15|Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive   Learning: Adapting Alignment Calibration to MERU|√Älex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund|2025-03-01|CVPR Workshops|https://github.com/alex-pv01/HAC|https://openaccess.thecvf.com/content/CVPR2025W/TMM-OpenWorld/html/Vidal_Machine_Unlearning_in_Hyperbolic_vs._Euclidean_Multimodal_Contrastive_Learning_Adapting_CVPRW_2025_paper.html|
|16|MMUNLEARNER: Reformulating Multimodal Machine Unlearning in the Era of   Multimodal Large Language Models|Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu|2025-02-16|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/Z1zs/MMUnlearner|https://doi.org/10.18653/v1/2025.findings-acl.375|
|17|Knowledge Swapping via Learning and Unlearning|Mingyu Xing, Lechao Cheng, Shengeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang|2025-02-11|arXiv|https://github.com/xingmingyu123456/KnowledgeSwapping|https://doi.org/10.48550/arXiv.2502.08075|
|18|Towards LLM Unlearning Resilient to Relearning Attacks: A   Sharpness-Aware Minimization Perspective and Beyond|Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu|2025-02-07|arXiv|https://github.com/OPTML-Group/Unlearn-Smooth.|https://doi.org/10.48550/arXiv.2502.05374|
|19|Forgetting Any Data at Any Time: A Theoretically Certified Unlearning   Framework for Vertical Federated Learning|Linian Wang, Leye Wang|2025-02-01|arXiv|https://github.com/wangln19/vertical-federated-unlearning.|https://doi.org/10.48550/arXiv.2502.17081|
|20|Pre-training for Recommendation Unlearning|Guoxuan Chen, Lianghao Xia, Chao Huang|2025-01-01|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/HKUDS/UnlearnRec.|https://doi.org/10.48550/arXiv.2505.22649|
|21|ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging|Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang|2025-01-01|arXiv|https://github.com/zjunlp/unlearn|https://doi.org/10.48550/arXiv.2503.21088|
|22|WaterDrum: Watermarking for Data-centric Unlearning Metric|Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, Se...|2025-01-01|arXiv|https://github.com/lululu008/WaterDrum|https://doi.org/10.48550/arXiv.2505.05064|
|23|Vertical Federated Unlearning via Backdoor Certification|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025-01-01|IEEE Transactions on Services Computing|https://github.com/mengde-han/VFL-unlearn.|https://doi.org/10.48550/arXiv.2412.11476|
|24|Unlearning Personal Data from a Single Image|Thomas De Min, Massimiliano Mancini, St√©phane Lathuili√®re, Subhankar Roy, Elisa Ricci|2025-01-01|Trans. Mach. Learn. Res.|https://github.com/tdemin16/one-shui.|https://openreview.net/forum?id=VxC4PZ71Ym|
|25|UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning|Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal|2025-01-01|arXiv|https://github.com/Vaidehi99/UPCORE|https://doi.org/10.48550/arXiv.2502.15082|
|26|Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs|Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee|2025-01-01|ICLR|https://github.com/csm9493/efficient-llm-unlearning.|https://openreview.net/forum?id=1ExfUpmIW4|
|27|SAeUron: Interpretable Concept Unlearning in Diffusion Models with   Sparse Autoencoders|Bartosz Cywi≈Ñski, Kamil Rafa≈Ç Deja|2025-01-01|arXiv|https://github.com/cywinski/SAeUron.|https://doi.org/10.48550/arXiv.2501.18052|
|28|Rethinking Machine Unlearning in Image Generation Models|Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng|2025-01-01|ACM Conference on Computer and Communications Security (CCS 2025)|https://github.com/ryliu68/IGMU.|https://doi.org/10.48550/arXiv.2506.02761|
|29|ReLearn: Unlearning via Learning for Large Language Models|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu ...|2025-01-01|OpenAlex|https://github.com/zjunlp/unlearn.|https://doi.org/10.18653/v1/2025.acl-long.297|
|30|A Survey on Unlearnable Data|Jiahao Li, Yiqiang Chen, Yunbing Xing, Yang Gu, Xiangyuan Lan|2025-01-01|arXiv|https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data|https://doi.org/10.48550/arXiv.2503.23536|
|31|Provably Unlearnable Data Examples|Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu, Derui Wang|2025-01-01|OpenAlex|https://github.com/NeuralSec/certified-data-learnability|https://www.ndss-symposium.org/ndss-paper/provably-unlearnable-data-examples/|
|32|On Large Language Model Continual Unlearning|Chongyang Gao, Lixu Wang, Kaize Ding, Chenkai Weng, Xiao Wang, Qi Zhu|2025-01-01|ICLR|https://github.com/GCYZSL/O3-LLM-UNLEARNING.|https://openreview.net/forum?id=Essg9kb4yx|
|33|Group-robust Machine Unlearning|Thomas De Min, Subhankar Roy, St√©phane Lathuili√®re, Elisa Ricci, Massimiliano Mancini|2025-01-01|arXiv|https://github.com/tdemin16/group-robust_machine_unlearning.|https://doi.org/10.48550/arXiv.2503.09330|
|34|Fine-Grained and Efficient Self-Unlearning with Layered Iteration|Hongyi Lyu, Xuyun Zhang, Hongsheng Hu, Shuo Wang, Chaoxiang He, Lianyong Qi|2025-01-01|OpenAlex|https://github.com/Hongyi-Lyu-MQ/SULI.|https://doi.org/10.24963/ijcai.2025/850|
|35|Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning|Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han|2025-01-01|arXiv|https://github.com/tmlr-group/SatImp.|https://doi.org/10.48550/arXiv.2505.11953|
|36|Efficient Unlearning with Privacy Guarantees|Josep Domingo-Ferrer, Najeeb Jebreel, David S√°nchez|2025-01-01|arXiv|https://github.com/najeebjebreel/EUPG.|https://doi.org/10.48550/arXiv.2507.04771|
|37|Effective Skill Unlearning through Intervention and Abstention|Yongce Li, Chung-En Sun, Tsui-Wei Weng|2025-01-01|OpenAlex|https://github.com/Trustworthy-ML-Lab/effective_skill_unlearning|https://doi.org/10.18653/v1/2025.naacl-long.322|
|38|Certified Unlearning for Neural Networks|Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo|2025-01-01|arXiv|https://github.com/stair-lab/certified-unlearning-neural-networks-icml-2025|https://doi.org/10.48550/arXiv.2506.06985|
|39|Catastrophic Failure of LLM Unlearning via Quantization|Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, Hui Liu, Qi He, Wenpeng Yin, Suhang Wang|2025-01-01|ICLR|https://github.com/zzwjames/FailureLLMUnlearning|https://openreview.net/forum?id=lHSeDYamnz|
|40|Backdoor Token Unlearning: Exposing and Defending Backdoors in   Pretrained Language Models|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/XDJPH/BTU.|https://doi.org/10.1609/aaai.v39i23.34605|
|41|BLUR: A Bi-Level Optimization Approach for LLM Unlearning|Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu,...|2025-01-01|arXiv|https://github.com/OptimAI-Lab/BLURLLMUnlearning.|https://doi.org/10.48550/arXiv.2506.08164|
|42|An Information Theoretic Approach to Machine Unlearning|Jack Foster, Kyle Fogarty, Stefan Schoepf, Zack Dugue, Cengiz √ñztireli, Alexandra Brintrup|2025-01-01|Trans. Mach. Learn. Res.|https://github.com/jwf40/Information-Theoretic-Unlearning|https://openreview.net/forum?id=t1utIThKHD|
|43|Align-then-Unlearn: Embedding Alignment for LLM Unlearning|Philipp Spohn, Leander Girrbach, Jessica Bader, Zeynep Akata|2025-01-01|arXiv|https://github.com/ExplainableML/align-then-unlearn.|https://doi.org/10.48550/arXiv.2506.13181|
|44|LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty|Christoforos N. Spartalis, Theodoros Semertzidis, Efstratios Gavves, Petros Daras|2025-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/cspartalis/LoTUS.|https://openaccess.thecvf.com/content/CVPR2025/html/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.html|
|45|Forget Vectors at Play: Universal Input Perturbations Driving Machine   Unlearning in Image Classification|Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|2024-12-21|arXiv|https://github.com/Changchangsun/Forget-Vector.|https://doi.org/10.48550/arXiv.2412.16780|
|46|A Cognac Shot To Forget Bad Memories: Corrective Unlearning for Graph   Neural Networks|Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru|2024-12-01|arXiv|https://github.com/cognac-gnn-unlearning/corrective-unlearning-for-gnns|http://arxiv.org/abs/2412.00789v4|
|47|Delta-Influence: Unlearning Poisons via Influence Functions|Wenjie Li, Jiawei Li, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal|2024-11-20|arXiv|https://github.com/andyisokay/delta-influence|https://doi.org/10.48550/arXiv.2411.13731|
|48|Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning   Methods|Jai Doshi, Asa Cooper Stickland|2024-11-18|arXiv|https://github.com/JaiDoshi/Knowledge-Erasure.|https://doi.org/10.48550/arXiv.2411.12103|
|49|Learning from Convolution-based Unlearnable Datasets|Dohyun Kim, Pedro Sandoval-Segura|2024-11-01|arXiv|https://github.com/aseriesof-tubes/RSK|https://doi.org/10.48550/arXiv.2411.01742|
|50|Identify Backdoored Model in Federated Learning via Individual   Unlearning|Jiahao Xu, Zikai Zhang, Rui Hu|2024-11-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/JiiahaoXU/MASA|https://doi.org/10.1109/WACV61041.2025.00773|
|51|Evaluating Deep Unlearning in Large Language Models|Ruihan Wu, Chhavi Yadav, Russ R. Salakhutdinov, Kamalika Chaudhuri|2024-10-19|arXiv|https://github.com/wrh14/deep_unlearning.|https://doi.org/10.48550/arXiv.2410.15153|
|52|Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned   Concepts|Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin|2024-10-16|arXiv|https://github.com/sail-sg/Meta-Unlearning.|https://doi.org/10.48550/arXiv.2410.12777|
|53|Dissecting Fine-Tuning Unlearning in Large Language Models|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|2024-10-09|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yihuaihong/Dissecting-FT-Unlearning.|https://doi.org/10.18653/v1/2024.emnlp-main.228|
|54|A Probabilistic Perspective on Unlearning and Alignment for Large   Language Models|Yan Scholten, Stephan G√ºnnemann, Leo Schwinn|2024-10-04|arXiv|https://github.com/yascho/probabilistic-unlearning|https://openreview.net/forum?id=51WraMid8K|
|55|Simplicity Prevails: Rethinking Negative Preference Optimization for LLM   Unlearning|Chongyu Fan, Liu Jian-cheng, Licong Lin, Jinghan Jia, Ruiqi Zhang, Mei Song, Sijia Liu|2024-10-01|arXiv|https://github.com/OPTML-Group/Unlearn-Simple.|https://doi.org/10.48550/arXiv.2410.07163|
|56|NegMerge: Sign-Consensual Weight Merging for Machine Unlearning|Hyo Seo Kim, Dongyoon Han, Junsuk Choe|2024-10-01|arXiv|https://github.com/naver-ai/negmerge.|http://arxiv.org/abs/2410.05583v2|
|57|Alternate Preference Optimization for Unlearning Factual Knowledge in   Large Language Models|Anmol Reddy Mekala, Vineeth Dorna, Shreya Dubey, Abhishek Lalwani, David Koleczek, Mukund Rungta, Sadid A. Hasan, Elita ...|2024-09-20||https://github.com/molereddy/Alternate-Preference-Optimization.|https://aclanthology.org/2025.coling-main.252/|
|58|Score Forgetting Distillation: A Swift, Data-Free Method for Machine   Unlearning in Diffusion Models|Tianqi Chen, Shujian Zhang, Mingyuan Zhou|2024-09-17|arXiv|https://github.com/tqch/score-forgetting-distillation.|https://openreview.net/forum?id=gjwhDHeAsz|
|59|CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper   Influence|Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan|2024-08-26|NeurIPS|https://github.com/xiye7lai/CURE4Rec.|http://papers.nips.cc/paper_files/paper/2024/hash/b364953e402d7d92e13830383677efb5-Abstract-Datasets_and_Benchmarks_Track.html|
|60|Scalable and Certifiable Graph Unlearning: Overcoming the Approximation   Error Barrier|Lu Yi, Zhewei Wei|2024-08-01|ICLR|https://github.com/luyi256/ScaleGUN.|https://openreview.net/forum?id=pPyJyeLriR|
|61|Multimodal Unlearnable Examples: Protecting Data against Multimodal   Contrastive Learning|Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao|2024-07-23|ACM Multimedia|https://github.com/thinwayliu/Multimodal-Unlearnable-Examples|https://doi.org/10.48550/arXiv.2407.16307|
|62|Safe Unlearning: A Surprisingly Effective and Generalizable Solution to   Defend Against Jailbreak Attacks|Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|2024-07-03|arXiv|https://github.com/thu-coai/SafeUnlearning|https://doi.org/10.48550/arXiv.2407.02855|
|63|Enable the Right to be Forgotten with Federated Client Unlearning in   Medical Imaging|Zhipeng Deng, Luyang Luo, Hao Chen|2024-07-02|Lecture notes in computer science|https://github.com/dzp2095/FCU.|https://doi.org/10.1007/978-3-031-72117-5_23|
|64|From Theft to Bomb-Making: The Ripple Effect of Unlearning in Defending   Against Jailbreak Attacks|Zhexin Zhang, Junxiao Yang, Yida Lu, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|2024-07-01|arXiv|https://github.com/thu-coai/SafeUnlearning.|http://arxiv.org/abs/2407.02855v3|
|65|Targeted Unlearning with Single Layer Unlearning Gradient|Zikui Cai, Yaoteng Tan, M. Salman Asif|2024-07-01|arXiv|https://github.com/CSIPlab/SLUG.|http://arxiv.org/abs/2407.11867v3|
|66|To Forget or Not? Towards Practical Knowledge Unlearning for Large   Language Models|Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang|2024-07-01|OpenAlex|https://github.com/zjunlp/KnowUnDo.|https://doi.org/10.18653/v1/2024.findings-emnlp.82|
|67|Data Attribution for Text-to-Image Models by Unlearning Synthesized   Images|Sheng-Yu Wang, Aaron Hertzmann, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang|2024-06-13|NeurIPS|https://github.com/PeterWang512/AttributeByUnlearning|http://papers.nips.cc/paper_files/paper/2024/hash/07fbde96bee50f4e09303fd4f877c2f3-Abstract-Conference.html|
|68|Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning   Framework from Logit Difference|Jiabao Ji, Yujian Liu, Yang Zhang, Gaowen Liu, Ramana Rao Kompella, Sijia Liu, Shiyu Chang|2024-06-12|NeurIPS|https://github.com/UCSB-NLP-Chang/ULD.|http://papers.nips.cc/paper_files/paper/2024/hash/171291d8fed723c6dfc76330aa827ff8-Abstract-Conference.html|
|69|Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces|Yihuai Hong, Lei Yu, Haiqin Yang, Shauli Ravfogel, Mor Geva|2024-06-01|arXiv|https://github.com/yihuaihong/ConceptVectors.|https://doi.org/10.48550/arXiv.2406.11614|
|70|MUC: Machine Unlearning for Contrastive Learning with Black-box   Evaluation|Yihan Wang, Yiwei Lu, Guojun Zhang, Franziska Boenisch, Adam Dziedzic, Yaoliang Yu, Xiao-Shan Gao|2024-06-01|Trans. Mach. Learn. Res.|https://github.com/EhanW/Alignment-Calibration.|https://openreview.net/forum?id=F9pjSDvuM9|
|71|Unlearning during Learning: An Efficient Federated Machine Unlearning   Method|Hanlin Gu, Gongxi Zhu, Jie Zhang, Xinyuan Zhao, Yuxing Han, Lixin Fan, Qiang Yang|2024-05-24|OpenAlex|https://github.com/Liar-Mask/FedAU.|https://www.ijcai.org/proceedings/2024/446|
|72|Defensive Unlearning with Adversarial Training for Robust Concept   Erasure in Diffusion Models|Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu|2024-05-24|NeurIPS|https://github.com/OPTML-Group/AdvUnlearn|http://papers.nips.cc/paper_files/paper/2024/hash/40954ac18a457dd5f11145bae6454cdf-Abstract-Conference.html|
|73|Erasing Concepts from Text-to-Image Diffusion Models with Few-shot   Unlearning|Masane Fuchi, Tomohiro Takagi|2024-05-12|BMVC|https://github.com/fmp453/few-shot-erasing|https://doi.org/10.48550/arXiv.2405.07288|
|74|Purify Unlearnable Examples via Rate-Constrained Variational   Autoencoders|Yi Yu, Yu-Fei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap‚ÄêPeng Tan, Alex C. Kot|2024-05-02|ICML|https://github.com/yuyi-sd/D-VAE.|https://openreview.net/forum?id=0LBNdbmQCM|
|75|Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew   Resilience|Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Ab...|2024-05-01|Lecture notes in computer science|https://github.com/thanhtrunghuynh93/fastFedUL|https://doi.org/10.1007/978-3-031-70362-1_4|
|76|Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity|Hanlin Gu, Win Kent Ong, Chee Seng Chan, Lixin Fan|2024-05-01|NeurIPS|https://github.com/OngWinKent/Federated-Feature-Unlearning|http://papers.nips.cc/paper_files/paper/2024/hash/2b09bb02b90584e2be94ff3ae09289bc-Abstract-Conference.html|
|77|Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality   Constraints|Yash Sinha, Murari Mandal, Mohan S. Kankanhalli|2024-05-01||https://github.com/MachineUnlearn/MMRecUN|https://doi.org/10.1609/aaai.v39i12.33367|
|78|SOUL: Unlocking the Power of Second-Order Optimization for LLM   Unlearning|Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2024-04-28|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/OPTML-Group/SOUL.|https://doi.org/10.18653/v1/2024.emnlp-main.245|
|79|Eraser: Jailbreaking Defense in Large Language Models via Unlearning   Harmful Knowledge|Weikai Lu, Ziqian Zeng, Jianwei Wang, Zhengdong Lu, Zelin Chen, Huiping Zhuang, Cen Chen|2024-04-08|OpenReview|https://github.com/ZeroNLP/Eraser.|https://openreview.net/pdf/56792e044282ec46ecc14cfd3f68de33ed880b8e.pdf|
|80|Machine Unlearning for Document Classification|Lei Kang, Mohamed Ali Souibgui, Fei Yang, Lluis Gomez, Ernest Valveny, Dimosthenis Karatzas|2024-04-01|Lecture notes in computer science|https://github.com/leitro/MachineUnlearning-DocClassification|https://doi.org/10.1007/978-3-031-70546-5_6|
|81|Towards Efficient and Effective Unlearning of Large Language Models for   Recommendation|Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang, Yong Yu|2024-03-06|Frontiers of Computer Science|https://github.com/justarter/E2URec|https://doi.org/10.1007/s11704-024-40044-2|
|82|Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine   Unlearning|Chongyu Fan, Jiancheng Liu, Alfred Olivier Hero, Sijia Liu|2024-03-01|Lecture notes in computer science|https://github.com/OPTML-Group/Unlearn-WorstCase.|https://doi.org/10.1007/978-3-031-72664-4_16|
|83|Towards Lifecycle Unlearning Commitment Management: Measuring   Sample-level Approximate Unlearning Completeness|Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang|2024-03-01|arXiv|https://github.com/Happy2Git/Unlearning_Inference_IAM.|https://doi.org/10.48550/arXiv.2506.06112|
|84|UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning   for Diffusion Models|Yihua Zhang, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Xiaoming Liu, Sijia Liu|2024-02-19|arXiv|https://github.com/OPTML-Group/UnlearnCanvas.|https://doi.org/10.48550/arXiv.2402.11846|
|85|Corrective Machine Unlearning|Shashwat Goel, Ameya Prabhu, Philip H. S. Torr, Ponnurangam Kumaraguru, Amartya Sanyal|2024-01-01|Trans. Mach. Learn. Res.|https://github.com/drimpossible/corrective-unlearning-bench.|https://local.forskningsportal.dk/local/dki-cgi/ws/cris-link?src=ku&id=ku-3bc52420-b6c0-4ebf-a0ea-0dedef731af7&ti=Corrective%20Machine%20Unlearning|
|86|Machine Unlearning of Pre-trained Large Language Models|Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue|2024-01-01|OpenReview|https://github.com/yaojin17/Unlearning_LLM|https://openreview.net/pdf/fe1970154c67c30db5b9431d2efc8b5d8ece2dee.pdf|
|87|A Closer Look at Machine Unlearning for Large Language Models|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|2024-01-01|arXiv|https://github.com/sail-sg/closer-look-LLM-unlearning.|https://openreview.net/forum?id=Q1MHvGmhyT|
|88|Boosting Alignment for Post-Unlearning Text-to-Image Generative Models|Myeongseob Ko, Henry Li, Zhun Wang, Jonathan Patsenker, Jiachen T. Wang, Qinbin Li, Ming Jin, Dawn Song, Ruoxi Jia|2024-01-01|NeurIPS|https://github.com/reds-lab/Restricted_gradient_diversity_unlearning.git.|http://papers.nips.cc/paper_files/paper/2024/hash/9aa51796f8bede2ea947d6b6e3087ab8-Abstract-Conference.html|
|89|Dataset Condensation Driven Machine Unlearning|Junaid Iqbal Khan|2024-01-01|arXiv|https://github.com/algebraicdianuj/DC_U|https://doi.org/10.48550/arXiv.2402.00195|
|90|Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need|Xianlong Wang, Minghui Li, Weiping Liu, Hangtao Zhang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Hai Jin|2024-01-01|NeurIPS|https://github.com/CGCL-codes/UnlearnablePC|http://papers.nips.cc/paper_files/paper/2024/hash/b3d868b4b5b61b35a849ba6e7a1d4449-Abstract-Conference.html|
|91|Soft Prompting for Unlearning in Large Language Models|Karuna Bhaila, Minh-Hao Van, Xintao Wu|2024-01-01|OpenAlex|https://github.com/karuna-bhaila/llm_unlearning|https://doi.org/10.18653/v1/2025.naacl-long.204|
|92|Revisiting Who&apos;s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective|Yujian Liu, Yang Zhang, Tommi S. Jaakkola, Shiyu Chang|2024-01-01|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/UCSB-NLP-Chang/causal_unlearn.git.|https://doi.org/10.18653/v1/2024.emnlp-main.495|
|93|Machine Unlearning via Representation Forgetting With Parameter Self-Sharing|Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu|2024-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/wwq5-code/RFU-SS.git.|https://doi.org/10.1109/TIFS.2023.3331239|
|94|Machine Unlearning via Null Space Calibration|Huiqiang Chen, Tianqing Zhu, Xinjie Yu, Wanlei Zhou|2024-01-01|OpenAlex|https://github.com/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration|https://www.ijcai.org/proceedings/2024/40|
|95|Breaking the Trilemma of Privacy, Utility, and Efficiency via Controllable Machine Unlearning|Zheyuan Liu, Guangyao Dou, Wang-Chien Chen, Chunhui Zhang, Yijun Tian, Ziwei Zhu|2024-01-01|Proceedings of the ACM Web Conference 2022|https://github.com/guangyaodou/ConMU.|https://doi.org/10.48550/arXiv.2310.18574|
|96|Machine Unlearning in Generative AI: A Survey|Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang|2024-01-01|arXiv|https://github.com/franciscoliu/GenAI-MU-Reading.|https://doi.org/10.48550/arXiv.2407.20516|
|97|Game-Theoretic Unlearnable Example Generator|Shuang Liu, Yihan Wang, Xiao-Shan Gao|2024-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/hong-xian/gue.|https://doi.org/10.1609/aaai.v38i19.30130|
|98|Machine Unlearning for Image-to-Image Generative Models|Guihong Li, Hsiang Hsu, Chun-Fu, Chen, Diana Marculescu|2024-01-01|ICLR|https://github.com/jpmorganchase/l2l-generator-unlearning.|https://openreview.net/forum?id=9hjVoPWPnh|
|99|From Hope to Safety: Unlearning Biases of Deep Models via Gradient Penalization in Latent Space|Maximilian Dreyer, Frederik Pahde, Christopher J. Anders, Wojciech Samek, Sebastian Lapuschkin|2024-01-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/frederikpahde/rrclarc.|https://doi.org/10.1609/aaai.v38i19.30096|
|100|Dissecting Language Models: Machine Unlearning via Selective Pruning|Nicholas Pochinkov, Nandi Schoots|2024-01-01|arXiv|https://github.com/nickypro/selective-pruning|https://doi.org/10.48550/arXiv.2403.01267|
|101|Efficient Federated Unlearning under Plausible Deniability|Ayush K. Varshney, Vicen√ß Torra|2024-01-01|Machine Learning|https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability|https://doi.org/10.1007/s10994-024-06685-x|
|102|Generative Unlearning for Any Identity|Juwon Seo, Sung-Hoon Lee, Tae-Young Lee, Seungjun Moon, Gyeong-Moon Park|2024-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/KHU-AGI/GUIDE.|https://doi.org/10.1109/CVPR52733.2024.00874|
|103|LMEraser: Large Model Unlearning through Adaptive Prompt Tuning|Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia|2024-01-01|AISTATS|https://github.com/lmeraser/lmeraser|https://proceedings.mlr.press/v258/xu25e.html|
|104|Large Language Model Unlearning via Embedding-Corrupted Prompts|Chris Yuhao Liu, Yaxuan Wang, Jeffrey Flanigan, Yang Liu|2024-01-01|NeurIPS|https://github.com/chrisliu298/llm-unlearn-eco|http://papers.nips.cc/paper_files/paper/2024/hash/d6359156e0e30b1caa116a4306b12688-Abstract-Conference.html|
|105|FedCSA: Boosting the Convergence Speed of Federated Unlearning under Data Heterogeneity|Zhen Wang, Daniyal M. Alghazzawi, Li Cheng, Gaoyang Liu, Chen Wang, Zeng Cheng, Yang Yang|2023-12-21|ISPA/BDCloud/SocialCom/SustainCom|https://github.com/ZhenWang9/FedCSA.|https://doi.org/10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00083|
|106|Deep Unlearning: Fast and Efficient Gradient-free Approach to Class   Forgetting|Sangamesh Kodge, Gobinda Saha, Kaushik Roy|2023-12-01|Trans. Mach. Learn. Res.|https://github.com/sangamesh-kodge/class_forgetting.|https://openreview.net/forum?id=BmI5p6wBi0|
|107|Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning   Interference with Gradient Projection|Tuan Hoang, Santu Rana, Sunil Gupta, Svetha Venkatesh|2023-12-01|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/hnanhtuan/projected_gradient_unlearning.|https://doi.org/10.1109/WACV57701.2024.00475|
|108|Stable Unlearnable Example: Enhancing the Robustness of Unlearnable   Examples via Stable Error-Minimizing Noise|Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun|2023-11-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/liuyixin-louis/Stable-Unlearnable-Example.|https://doi.org/10.48550/arXiv.2311.13091|
|109|Towards Machine Unlearning Benchmarks: Forgetting the Personal   Identities in Facial Recognition Systems|Dasol Choi, Dongbin Na|2023-11-01|arXiv|https://github.com/ndb796/MachineUnlearning.|https://doi.org/10.48550/arXiv.2311.02240|
|110|SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency   in Both Image Classification and Generation|Chongyu Fan, Jiancheng Liu, Yihua Zhang, Eric Wong, Dennis Wei, Sijia Liu|2023-10-01|arXiv|https://github.com/OPTML-Group/Unlearn-Saliency.|https://openreview.net/forum?id=gn0mIhQGNM|
|111|To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still   Easy To Generate Unsafe Images ... For Now|Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu|2023-10-01|Lecture notes in computer science|https://github.com/OPTML-Group/Diffusion-MU-Attack.|https://doi.org/10.1007/978-3-031-72998-0_22|
|112|Fair Machine Unlearning: Data Removal while Mitigating Disparities|Alex Oesterling, Jiaqi Ma, Fl√°vio P. Calmon, Himabindu Lakkaraju|2023-07-01|AISTATS|https://github.com/AI4LIFE-GROUP/fair-unlearning|https://proceedings.mlr.press/v238/oesterling24a.html|
|113|Fast Yet Effective Machine Unlearning|Ayush K. Tarun, Vikram S. Chundawat, Murari Mandal, Mohan S. Kankanhalli|2023-05-01|IEEE Transactions on Neural Networks and Learning Systems|https://github.com/vikram2000b/Fast-Machine-Unlearning|https://doi.org/10.1109/tnnls.2023.3266233|
|114|Unlearnable Examples Give a False Sense of Security: Piercing through   Unexploitable Data with Learnable Examples|Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong|2023-05-01|ACM Multimedia|https://github.com/jiangw-0/LE_JCDP.|https://doi.org/10.48550/arXiv.2305.09241|
|115|CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023-04-16|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf|
|116|Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable   Example Attacks|Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu|2023-03-01|arXiv|https://github.com/lafeat/ueraser.|https://doi.org/10.48550/arXiv.2303.15127|
|117|Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural   Networks|Vijaya Raghavan T. Ramkumar, Elahe Arani, Bahram Zonooz|2023-03-01|Trans. Mach. Learn. Res.|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learn-unlearn-and-relearn-an-online-learning/code)|https://openreview.net/pdf/e61ee961464c8ff0055125464944b1b3ca4bb37a.pdf|
|118|One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks|Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang|2023-02-01|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/one-pixel-shortcut-on-the-learning-preference/code)|https://openreview.net/pdf/b69561625d5ce4388db999c205fdb5a8b988725e.pdf|
|119|Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks|Noam Wies, Yoav Levine, Amnon Shashua|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/sub-task-decomposition-enables-learning-in/code)|https://openreview.net/pdf/0e2acc3ed9aaaff91e94533aa1eb2cec3a27915b.pdf|
|120|Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding |Abdullah Hamdi, Silvio Giancola, Bernard Ghanem|2023-02-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/voint-cloud-multi-view-point-cloud/code)|https://openreview.net/pdf/b3f85b26464b6cd916b9a66adb82d3d295c951c4.pdf|
|121|Zero-Shot Machine Unlearning|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|2023-01-01|IEEE Transactions on Information Forensics and Security|https://github.com/ayu987/zero-shot-unlearning|https://doi.org/10.1109/tifs.2023.3265506|
|122|Unlearning Bias in Language Models by Partitioning Gradients|Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, Heng Ji|2023-01-01|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/CharlesYu2000/PCGU-UnlearningBias.|https://doi.org/10.18653/v1/2023.findings-acl.375|
|123|Task-Aware Machine Unlearning and Its Application in Load Forecasting|Wangkun Xu, Fei Teng|2023-01-01|IEEE Transactions on Power Systems|https://github.com/xuwkk/task_aware_machine_unlearning.|https://doi.org/10.1109/tpwrs.2024.3376828|
|124|Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples|Jiaming Zhang, Xingjun Ma, Qi Yi, Jitao Sang, Yu-Gang Jiang, Yaowei Wang, Changsheng Xu|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/jiamingzhang94/Unlearnable-Clusters.|https://doi.org/10.1109/CVPR52729.2023.00388|
|125|What Can We Learn from Unlearnable Datasets?|Pedro Sandoval Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein|2023-01-01|NeurIPS|https://github.com/psandovalsegura/learn-from-unlearnable|http://papers.nips.cc/paper_files/paper/2023/hash/ee5bb72130c332c3d4bf8d231e617506-Abstract-Conference.html|
|126|Recommendation Unlearning via Influence Function|Yang Zhang, Zhiyu Hu, Yimeng Bai, Fuli Feng, Jiancan Wu, Qifan Wang, Xiangnan He|2023-01-01|ACM Transactions on Recommender Systems|https://github.com/baiyimeng/IFRU.|https://doi.org/10.48550/arXiv.2307.02147|
|127|Model Sparsification Can Simplify Machine Unlearning|Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu, Yang Liu, Pranay Sharma, Sijia Liu|2023-01-01|NeurIPS|https://github.com/OPTML-Group/Unlearn-Sparse.|http://papers.nips.cc/paper_files/paper/2023/hash/a204aa68ab4e970e1ceccfb5b5cdc5e4-Abstract-Conference.html|
|128|A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions|Jiaxi Yang, Yang Zhao|2023-01-01|arXiv|https://github.com/abbottyanginchina/Awesome-Federated-Unlearning.|https://doi.org/10.48550/arXiv.2310.19218|
|129|Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning   in Generative Adversarial Networks|Piyush Tiwary, Atri Guha, Subhodip Panda, Prathosh A. P.|2023-01-01|Trans. Mach. Learn. Res.|https://github.com/atriguha/Adapt_Unlearn.|https://openreview.net/forum?id=jAHEBivObO|
|130|Inductive Graph Unlearning|Cheng-Long Wang, Mengdi Huai, Di Wang|2023-01-01|USENIX Security Symposium|https://github.com/Happy2Git/GUIDE.|https://www.usenix.org/conference/usenixsecurity23/presentation/wang-cheng-long|
|131|GIF: A General Graph Unlearning Strategy via Influence Function|Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He|2023-01-01|Proceedings of the ACM Web Conference 2022|https://github.com/wujcan/GIF-torch|https://doi.org/10.48550/arXiv.2304.02835|
|132|ERM-KTP: Knowledge-Level Machine Unlearning via Knowledge Transfer|Shen Lin, Xiaoyu Zhang, Chenyang Chen, Xiaofeng Chen, Willy Susilo|2023-01-01|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/RUIYUN-ML/ERM-KTP|https://doi.org/10.1109/CVPR52729.2023.01929|
|133|GNNDelete: A General Strategy for Unlearning in Graph Neural Networks|Jiali Cheng, George Dasoulas, Huan He, Chirag Agarwal, Marinka Zitnik|2023-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/gnndelete-a-general-strategy-for-unlearning/code)|https://openreview.net/pdf/d344e51366b6eeb1347bf96857a1cdeb5ca03e64.pdf|
|134|PatchGT: Transformer over Non-trainable Clusters for Learning Graph Representations|Han Gao, Xu Han, Jiaoyang Huang, Jian-Xun Wang, Liping Liu|2022-11-24|LoG 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/patchgt-transformer-over-non-trainable/code)|https://openreview.net/pdf/7a95f2c19eec64ed2379944a8398af365f166ed3.pdf|
|135|Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models|Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/exploring-the-limits-of-domain-adaptive/code)|https://openreview.net/pdf/cbffa1a0bf2612f146adbc70397e00fc131d2db4.pdf|
|136|The Privacy Onion Effect: Memorization is Relative|Nicholas Carlini, Matthew Jagielski, Chiyuan Zhang, Nicolas Papernot, Andreas Terzis, Florian Tramer|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/the-privacy-onion-effect-memorization-is/code)|https://openreview.net/pdf/9693b6b162a476e99f5438ece8d66f14a520d97b.pdf|
|137|Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/trap-and-replace-defending-backdoor-attacks/code)|https://openreview.net/pdf/a0b040b733099d83fd30969cd35fa8cc35c367b2.pdf|
|138|Autoregressive Perturbations for Data Poisoning|Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W. Jacobs|2022-10-31|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/autoregressive-perturbations-for-data/code)|https://openreview.net/pdf/f465f9046724189ffd748375c5f6a4ac4d722e10.pdf|
|139|Characterizing Datapoints via Second-Split Forgetting|Pratyush Maini, Saurabh Garg, Zachary Chase Lipton, J Zico Kolter|2022-07-20|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/characterizing-datapoints-via-second-split/code)|https://openreview.net/pdf/4e3bb598ca199212473a7389946dde4baf3d97b1.pdf|
|140|Deep Unlearning via Randomized Conditionally Independent Hessians|Ronak Mehta, Sourav Pal, Vikas Pratap Singh, Sathya N. Ravi|2022-06-01||https://github.com/vsingh-group/LCODEC-deep-unlearning|https://doi.org/10.1109/cvpr52688.2022.01017|
|141|Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an   Incompetent Teacher|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|2022-05-01|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/vikram2000b/bad-teaching-unlearning|https://doi.org/10.48550/arXiv.2205.08096|
|142|Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning|Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao|2022-03-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/robust-unlearnable-examples-protecting-data/code)|https://openreview.net/pdf/cb11d28b469a29f68dc6043214ae3f4f579b360a.pdf|
|143|Knowledge Removal in Sampling-based Bayesian Inference|Shaopeng Fu, Fengxiang He, Dacheng Tao|2022-01-28|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/knowledge-removal-in-sampling-based-bayesian/code)|https://openreview.net/pdf/a42ad90a502167268f1ba4c67f57150bf59ccbc9.pdf|
|144|Recommendation Unlearning|Chong Chen, Fei Sun, Min Zhang, Bolin Ding|2022-01-01|Proceedings of the ACM Web Conference 2022|https://github.com/chenchongthu/Recommendation-Unlearning|https://openreview.nethttps://arxiv.org/pdf/2201.06820.pdf|
|145|QUARK: Controllable Text Generation with Reinforced Unlearning|Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, Yejin Choi|2022-01-01|NeurIPS 2022 (Oral Selection)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/quark-controllable-text-generation-with/code)|http://papers.nips.cc/paper_files/paper/2022/hash/b125999bde7e80910cbdbd323087df8f-Abstract-Conference.html|
|146|Knowledge Unlearning for Mitigating Privacy Risks in Language Models|Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo|2022-01-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/knowledge-unlearning-for-mitigating-privacy/code)|https://openreview.net/pdf/b13e3c3cdc06b81ed93687d74823ddd0aef79674.pdf|
|147|Machine Unlearning of Federated Clusters|Chao Pan, Jin Sima, Saurav Prakash, Vishal Singh Rana, Olgica Milenkoviƒá|2022-01-01|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/machine-unlearning-of-federated-clusters/code)|https://openreview.net/pdf/51ee65b11a32de7ad446a5917d748f9da5399714.pdf|
|148|Deep Regression Unlearning|Ayush Kumar Tarun, Vikram Singh Chundawat, Murari Mandal, Mohan S. Kankanhalli|2022-01-01|arXiv|https://github.com/ayu987/deep-regression-unlearning|https://proceedings.mlr.press/v202/tarun23a.html|
|149|Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks|Jimmy Z. Di, Jack F. Douglas, Jayadev Acharya, Gautam Kamath, Ayush Sekhari|2022-01-01|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/hidden-poison-machine-unlearning-enables/code)|http://papers.nips.cc/paper_files/paper/2023/hash/8b4add8b0aa8749d80a34ca5d941c355-Abstract-Conference.html|
|150|FedHarmony: Unlearning Scanner Bias with Distributed Data|Nicola K. Dinsdale, Mark Jenkinson, Ana I. L. Namburete|2022-01-01|Lecture notes in computer science|https://github.com/nkdinsdale/FedHarmony.|https://doi.org/10.1007/978-3-031-16452-1_66|
|151|Continual Learning and Private Unlearning|Bo Liu, Qiang Liu, Peter Stone|2022-01-01|CoLLAs|https://github.com/Cranial-XIX/Continual-Learning-Private-Unlearning.|https://proceedings.mlr.press/v199/liu22a.html|
|152|Atlas: Universal Function Approximator For Memory Retention|Heinrich van Deventer, Anna Sergeevna Bosman|2022-01-01|NeurIPS 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/atlas-universal-function-approximator-for/code)|https://openreview.net/pdf/95b89482f610b970f80506d51d6924d79cd125e6.pdf|
|153|Adversarial Unlearning: Reducing Confidence Along Adversarial Directions|Amrith Setlur, Benjamin Eysenbach, Virginia Smith, Sergey Levine|2022-01-01|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-reducing-confidence/code)|http://papers.nips.cc/paper_files/paper/2022/hash/75f1a165c7561e028c41d42fa6286a76-Abstract-Conference.html|
|154|A Survey of Machine Unlearning|Thanh Tam Nguyen, Thanh Trung Huynh, Zhao Ren, Phi Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin, Quoc Viet Hung Nguyen|2022-01-01|ACM Transactions on Intelligent Systems and Technology|https://github.com/tamlhp/awesome-machine-unlearning.|https://doi.org/10.48550/arXiv.2209.02299|
|155|Certified Graph Unlearning|Eli Chien, Chao Pan, Olgica Milenkovic|2022-01-01|NeurIPS 2022 GLFrontiers Workshop|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/certified-graph-unlearning/code)|https://openreview.net/pdf/255ad2fc5a24c56a6f91f08eabdfdd9ba94a3bf2.pdf|
|156|Adaptive Machine Unlearning|Varun Gupta, Christopher Jung, Seth Neel, Aaron Roth, Saeed Sharifi -Malvajerdi, Christopher Waites|2021-11-09|Neural Information Processing Systems|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adaptive-machine-unlearning/code)|https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html|
|157|Unlearnable Examples: Making Personal Data Unexploitable|Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang|2021-01-13|ICLR 2021 Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unlearnable-examples-making-personal-data/code)|https://openreview.net/pdf/eb123b0f1c20d0c5d47b33fa7feca81748e02666.pdf|
|158|Adversarial Unlearning of Backdoors via Implicit Hypergradient|Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia|2021-01-01|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-of-backdoors-via/code)|https://openreview.net/pdf/6aeb6e81c9d0eadbb4cfbefb6caac0f155d561ea.pdf|
|159|Towards Probabilistic Verification of Machine Unlearning|David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal|2020-01-01|arXiv|https://github.com/inspire-group/unlearning-verification|http://arxiv.org/abs/2003.04247v2|
|160|When Machine Unlearning Jeopardizes Privacy|Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang|2020-01-01|Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security|https://github.com/MinChen00/UnlearningLeaks.|https://doi.org/10.1145/3460120.3484756|
|161|Learnability for the Information Bottleneck|Tailin Wu, Ian Fischer, Isaac Chuang, Max Tegmark|2019-04-17|LLD 2019|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learnability-for-the-information-bottleneck/code)|https://openreview.net/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf|
