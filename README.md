# Table of Contents
1. [Machine Unlearning Papers](#machine-unlearning-papers)
2. [Other topics](#other-topics)
3. [Machine Unlearning Papers with Code](#machine-unlearning-papers-with-code)


## Machine Unlearning Papers
This GitHub repository contains an updated list of Federated Learning papers as of **July 27, 2025**. 

- The resources are collected from various sources, including arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, NIPS, IEEE, ACM, Springer, ScienceDirect, Wiley, Nature, Science, and other top AI/ML conferences and journals.
- For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

---
# Other Topics
Explore additional research papers on the following topics:
- For **Large Language Models** papers, please visit the [**LLM Repository**](https://github.com/mtuann/llm-updated-papers).
- For **Backdoor Learning** papers, please visit the [**Backdoor Learning Repository**](https://github.com/mtuann/backdoor-ai-resources).
- For **Federated Learning** papers, please visit the [**Federated Learning Repository**](https://github.com/mtuann/federated-learning-updated-papers).
- For **Machine Unlearning** papers, please visit the [**Machine Unlearning Repository**](https://github.com/mtuann/machine-unlearning-papers).

---

For contributions, inquiries, or suggestions, feel free to reach out via [email](mailto:tuannm0312@gmail.com).

---

If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:
- **Techcombank (Vietnam):** 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card:** [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

---

## Machine Unlearning Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publish date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

---


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|Training wide residual networks for deployment using a single bit for each weight|Mark D. McDonnell|<li><span style="color:#FF5733;">None</span></li>|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/training-wide-residual-networks-for/code)|https://openreview.net/pdf/861cb006a62eb71925571a5d4979901d047a92ea.pdf|
|2|Multitask Soft Option Learning|Maximilian Igl, Andrew Gambardella, Jinke He, Nantas Nardelli, N. Siddharth, Wendelin Böhmer, Shimon Whiteson|<li><span style="color:#FF5733;">None</span></li>|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/multitask-soft-option-learning/code)|https://openreview.net/pdf/5e7c12118369a575ab52f9fb553689c36468b080.pdf|
|3|Compressed Sensing with Deep Image Prior and Learned Regularization|Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, Alexandros G. Dimakis|<li><span style="color:#FF5733;">None</span></li>|OpenReview|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/compressed-sensing-with-deep-image-prior-and/code)|https://openreview.net/pdf/960068efdade58de64b1b641bcccfdba53ac168b.pdf|
|4|Image Can Bring Your Memory Back: A Novel Multi-Modal Guided Attack
  against Image Generation Model Unlearning|Renyang Liu, Guanlin Li, Tianwei Zhang, See-Kiong Ng|<li><span style="color:#FF5733;">2025-07-01</span></li>|arXiv|https://github.com/ryliu68/RECALL|http://arxiv.org/abs/2507.07139v1|
|5|Efficient Unlearning with Privacy Guarantees|Josep Domingo-Ferrer, Najeeb Jebreel, David Sánchez|<li><span style="color:#FF5733;">2025-07-01</span></li>|arXiv|https://github.com/najeebjebreel/EUPG.|http://arxiv.org/abs/2507.04771v1|
|6|Leveraging Distribution Matching to Make Approximate Machine Unlearning
  Faster|Junaid Iqbal Khan|<li><span style="color:#FF5733;">2025-07-01</span></li>|arXiv|https://github.com/algebraicdianuj/DC_Unlearning.|http://arxiv.org/abs/2507.09786v1|
|7|Forget-MI: Machine Unlearning for Forgetting Multimodal Information in
  Healthcare Settings|Shahad Hardan, Darya Taratynova, Abdelmajid Essofi, Karthik Nandakumar, Mohammad Yaqub|<li><span style="color:#FF5733;">2025-06-01</span></li>|arXiv|https://github.com/BioMedIA-MBZUAI/Forget-MI.git|https://doi.org/10.48550/arXiv.2506.23145|
|8|Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation
  and Confidence Awareness|Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chi...|<li><span style="color:#FF5733;">2025-06-01</span></li>|arXiv|https://github.com/Graph-COM/Knowledge_Unlearning.git.|https://doi.org/10.48550/arXiv.2506.05735|
|9|Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from
  Model Outputs|Yiwei Chen, Soumyadeep Pal, Yimeng Zhang, Qing Qu, Sijia Liu|<li><span style="color:#FF5733;">2025-06-01</span></li>|arXiv|https://github.com/OPTML-Group/Unlearn-Trace.|http://arxiv.org/abs/2506.14003v2|
|10|Unlearning Sensitive Information in Multimodal LLMs: Benchmark and
  Attack-Defense Evaluation|Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal|<li><span style="color:#FF5733;">2025-05-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/Vaidehi99/UnLOK-VQA|https://openreview.net/forum?id=YcnjgKbZQS|
|11|Unlearning for Federated Online Learning to Rank: A Reproducibility
  Study|Yiling Tao, Shuyi Wang, Jiaxi Yang, Guido Zuccon|<li><span style="color:#FF5733;">2025-05-01</span></li>|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/Iris1026/Unlearning-for-FOLTR.git.|https://doi.org/10.48550/arXiv.2505.12791|
|12|Unlearning Isn't Deletion: Investigating Reversibility of Machine
  Unlearning in LLMs|Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du|<li><span style="color:#FF5733;">2025-05-01</span></li>|arXiv|https://github.com/XiaoyuXU1/Representational_Analysis_Tools.git.|http://arxiv.org/abs/2505.16831v1|
|13|LoRA Unlearns More and Retains More (Student Abstract)|Atharv Mittal|<li><span style="color:#FF5733;">2025-04-11</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/vlgiitr/LoRA-Unlearn.|https://doi.org/10.1609/aaai.v39i28.35277|
|14|LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in
  Current Benchmarks|Soumyadeep Pal, Changsheng Wang, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|<li><span style="color:#FF5733;">2025-04-01</span></li>|arXiv|https://github.com/OPTML-Group/MU-Coreset.|https://doi.org/10.48550/arXiv.2504.10185|
|15|Multi-Objective Large Language Model Unlearning|Zibin Pan, Shuwen Zhang, Yuesheng Zheng, Chi Li, Yuheng Cheng, Junhua Zhao|<li><span style="color:#FF5733;">2025-03-12</span></li>|ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)|https://github.com/zibinpan/MOLLM.|https://doi.org/10.1109/icassp49660.2025.10889776|
|16|Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive
  Learning: Adapting Alignment Calibration to MERU|Àlex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund|<li><span style="color:#FF5733;">2025-03-01</span></li>|CVPR Workshops|https://github.com/alex-pv01/HAC|https://openaccess.thecvf.com/content/CVPR2025W/TMM-OpenWorld/html/Vidal_Machine_Unlearning_in_Hyperbolic_vs._Euclidean_Multimodal_Contrastive_Learning_Adapting_CVPRW_2025_paper.html|
|17|MMUNLEARNER: Reformulating Multimodal Machine Unlearning in the Era of
  Multimodal Large Language Models|Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu|<li><span style="color:#FF5733;">2025-02-16</span></li>|arXiv|https://github.com/Z1zs/MMUnlearner|https://aclanthology.org/2025.findings-acl.375/|
|18|Knowledge Swapping via Learning and Unlearning|Mingyu Xing, Lechao Cheng, Shengeng Tang, Yaxiong Wang, Zhun Zhong, Meng Wang|<li><span style="color:#FF5733;">2025-02-11</span></li>|arXiv|https://github.com/xingmingyu123456/KnowledgeSwapping|https://doi.org/10.48550/arXiv.2502.08075|
|19|Towards LLM Unlearning Resilient to Relearning Attacks: A
  Sharpness-Aware Minimization Perspective and Beyond|Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu|<li><span style="color:#FF5733;">2025-02-07</span></li>|arXiv|https://github.com/OPTML-Group/Unlearn-Smooth.|https://doi.org/10.48550/arXiv.2502.05374|
|20|Forgetting Any Data at Any Time: A Theoretically Certified Unlearning
  Framework for Vertical Federated Learning|Linian Wang, Leye Wang|<li><span style="color:#FF5733;">2025-02-01</span></li>|arXiv|https://github.com/wangln19/vertical-federated-unlearning.|https://doi.org/10.48550/arXiv.2502.17081|
|21|Provably Unlearnable Data Examples|Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu, Derui Wang|<li><span style="color:#FF5733;">2025-01-01</span></li>|OpenAlex|https://github.com/NeuralSec/certified-data-learnability|https://www.ndss-symposium.org/ndss-paper/provably-unlearnable-data-examples/|
|22|WaterDrum: Watermarking for Data-centric Unlearning Metric|Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, Se...|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/lululu008/WaterDrum|https://doi.org/10.48550/arXiv.2505.05064|
|23|Vertical Federated Unlearning via Backdoor Certification|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|<li><span style="color:#FF5733;">2025-01-01</span></li>|IEEE Transactions on Services Computing|https://github.com/mengde-han/VFL-unlearn.|https://doi.org/10.48550/arXiv.2412.11476|
|24|Unlearning Personal Data from a Single Image|Thomas De Min, Massimiliano Mancini, Stéphane Lathuilière, Subhankar Roy, Elisa Ricci|<li><span style="color:#FF5733;">2025-01-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/tdemin16/one-shui.|https://openreview.net/forum?id=VxC4PZ71Ym|
|25|UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning|Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/Vaidehi99/UPCORE|https://doi.org/10.48550/arXiv.2502.15082|
|26|Towards Robust and Parameter-Efficient Knowledge Unlearning for LLMs|Sungmin Cha, Sungjun Cho, Dasol Hwang, Moontae Lee|<li><span style="color:#FF5733;">2025-01-01</span></li>|ICLR|https://github.com/csm9493/efficient-llm-unlearning.|https://openreview.net/forum?id=1ExfUpmIW4|
|27|SAeUron: Interpretable Concept Unlearning in Diffusion Models with
  Sparse Autoencoders|Bartosz Cywiński, Kamil Rafał Deja|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/cywinski/SAeUron.|https://doi.org/10.48550/arXiv.2501.18052|
|28|Rethinking Machine Unlearning in Image Generation Models|Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng|<li><span style="color:#FF5733;">2025-01-01</span></li>|ACM Conference on Computer and Communications Security (CCS 2025)|https://github.com/ryliu68/IGMU.|https://doi.org/10.48550/arXiv.2506.02761|
|29|ReLearn: Unlearning via Learning for Large Language Models|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu ...|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/zjunlp/unlearn.|https://aclanthology.org/2025.acl-long.297/|
|30|ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging|Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/zjunlp/unlearn|https://doi.org/10.48550/arXiv.2503.21088|
|31|Pre-training for Recommendation Unlearning|Guoxuan Chen, Lianghao Xia, Chao Huang|<li><span style="color:#FF5733;">2025-01-01</span></li>|Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval|https://github.com/HKUDS/UnlearnRec.|https://doi.org/10.48550/arXiv.2505.22649|
|32|On Large Language Model Continual Unlearning|Chongyang Gao, Lixu Wang, Kaize Ding, Chenkai Weng, Xiao Wang, Qi Zhu|<li><span style="color:#FF5733;">2025-01-01</span></li>|ICLR|https://github.com/GCYZSL/O3-LLM-UNLEARNING.|https://openreview.net/forum?id=Essg9kb4yx|
|33|BLUR: A Bi-Level Optimization Approach for LLM Unlearning|Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu,...|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/OptimAI-Lab/BLURLLMUnlearning.|https://doi.org/10.48550/arXiv.2506.08164|
|34|A Survey on Unlearnable Data|Jiahao Li, Yiqiang Chen, Yunbing Xing, Yang Gu, Xiangyuan Lan|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data|https://doi.org/10.48550/arXiv.2503.23536|
|35|Align-then-Unlearn: Embedding Alignment for LLM Unlearning|Philipp Spohn, Leander Girrbach, Jessica Bader, Zeynep Akata|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/ExplainableML/align-then-unlearn.|https://doi.org/10.48550/arXiv.2506.13181|
|36|Group-robust Machine Unlearning|Thomas De Min, Subhankar Roy, Stéphane Lathuilière, Elisa Ricci, Massimiliano Mancini|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/tdemin16/group-robust_machine_unlearning.|https://doi.org/10.48550/arXiv.2503.09330|
|37|An Information Theoretic Approach to Machine Unlearning|Jack Foster, Kyle Fogarty, Stefan Schoepf, Zack Dugue, Cengiz Öztireli, Alexandra Brintrup|<li><span style="color:#FF5733;">2025-01-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/jwf40/Information-Theoretic-Unlearning|https://openreview.net/forum?id=t1utIThKHD|
|38|LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty|Christoforos N. Spartalis, Theodoros Semertzidis, Efstratios Gavves, Petros Daras|<li><span style="color:#FF5733;">2025-01-01</span></li>|CVPR|https://github.com/cspartalis/LoTUS.|https://openaccess.thecvf.com/content/CVPR2025/html/Spartalis_LoTUS_Large-Scale_Machine_Unlearning_with_a_Taste_of_Uncertainty_CVPR_2025_paper.html|
|39|Backdoor Token Unlearning: Exposing and Defending Backdoors in
  Pretrained Language Models|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|<li><span style="color:#FF5733;">2025-01-01</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/XDJPH/BTU.|https://doi.org/10.1609/aaai.v39i23.34605|
|40|Catastrophic Failure of LLM Unlearning via Quantization|Zhiwei Zhang, Fali Wang, Xiaomin Li, Zongyu Wu, Xianfeng Tang, Hui Liu, Qi He, Wenpeng Yin, Suhang Wang|<li><span style="color:#FF5733;">2025-01-01</span></li>|ICLR|https://github.com/zzwjames/FailureLLMUnlearning|https://openreview.net/forum?id=lHSeDYamnz|
|41|Certified Unlearning for Neural Networks|Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/stair-lab/certified-unlearning-neural-networks-icml-2025|https://doi.org/10.48550/arXiv.2506.06985|
|42|Effective Skill Unlearning through Intervention and Abstention|Yongce Li, Chung-En Sun, Tsui-Wei Weng|<li><span style="color:#FF5733;">2025-01-01</span></li>|OpenAlex|https://github.com/Trustworthy-ML-Lab/effective_skill_unlearning|https://doi.org/10.18653/v1/2025.naacl-long.322|
|43|Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning|Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han|<li><span style="color:#FF5733;">2025-01-01</span></li>|arXiv|https://github.com/tmlr-group/SatImp.|https://doi.org/10.48550/arXiv.2505.11953|
|44|Forget Vectors at Play: Universal Input Perturbations Driving Machine
  Unlearning in Image Classification|Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|<li><span style="color:#FF5733;">2024-12-21</span></li>|arXiv|https://github.com/Changchangsun/Forget-Vector.|https://doi.org/10.48550/arXiv.2412.16780|
|45|A Cognac Shot To Forget Bad Memories: Corrective Unlearning for Graph
  Neural Networks|Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru|<li><span style="color:#FF5733;">2024-12-01</span></li>|arXiv|https://github.com/cognac-gnn-unlearning/corrective-unlearning-for-gnns|http://arxiv.org/abs/2412.00789v4|
|46|Delta-Influence: Unlearning Poisons via Influence Functions|Wenjie Li, Jiawei Li, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal|<li><span style="color:#FF5733;">2024-11-20</span></li>|arXiv|https://github.com/andyisokay/delta-influence|https://doi.org/10.48550/arXiv.2411.13731|
|47|Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning
  Methods|Jai Doshi, Asa Cooper Stickland|<li><span style="color:#FF5733;">2024-11-18</span></li>|arXiv|https://github.com/JaiDoshi/Knowledge-Erasure.|https://doi.org/10.48550/arXiv.2411.12103|
|48|Identify Backdoored Model in Federated Learning via Individual
  Unlearning|Jiahao Xu, Zikai Zhang, Rui Hu|<li><span style="color:#FF5733;">2024-11-01</span></li>|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/JiiahaoXU/MASA|https://doi.org/10.1109/WACV61041.2025.00773|
|49|Learning from Convolution-based Unlearnable Datasets|Dohyun Kim, Pedro Sandoval-Segura|<li><span style="color:#FF5733;">2024-11-01</span></li>|arXiv|https://github.com/aseriesof-tubes/RSK|https://doi.org/10.48550/arXiv.2411.01742|
|50|Evaluating Deep Unlearning in Large Language Models|Ruihan Wu, Chhavi Yadav, Russ R. Salakhutdinov, Kamalika Chaudhuri|<li><span style="color:#FF5733;">2024-10-19</span></li>|arXiv|https://github.com/wrh14/deep_unlearning.|https://doi.org/10.48550/arXiv.2410.15153|
|51|Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned
  Concepts|Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin|<li><span style="color:#FF5733;">2024-10-16</span></li>|arXiv|https://github.com/sail-sg/Meta-Unlearning.|https://doi.org/10.48550/arXiv.2410.12777|
|52|Dissecting Fine-Tuning Unlearning in Large Language Models|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|<li><span style="color:#FF5733;">2024-10-09</span></li>|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/yihuaihong/Dissecting-FT-Unlearning.|https://doi.org/10.18653/v1/2024.emnlp-main.228|
|53|A Probabilistic Perspective on Unlearning and Alignment for Large
  Language Models|Yan Scholten, Stephan Günnemann, Leo Schwinn|<li><span style="color:#FF5733;">2024-10-04</span></li>|arXiv|https://github.com/yascho/probabilistic-unlearning|https://openreview.net/forum?id=51WraMid8K|
|54|NegMerge: Sign-Consensual Weight Merging for Machine Unlearning|Hyo Seo Kim, Dongyoon Han, Junsuk Choe|<li><span style="color:#FF5733;">2024-10-01</span></li>|arXiv|https://github.com/naver-ai/negmerge.|http://arxiv.org/abs/2410.05583v2|
|55|Simplicity Prevails: Rethinking Negative Preference Optimization for LLM
  Unlearning|Chongyu Fan, Liu Jian-cheng, Licong Lin, Jinghan Jia, Ruiqi Zhang, Mei Song, Sijia Liu|<li><span style="color:#FF5733;">2024-10-01</span></li>|arXiv|https://github.com/OPTML-Group/Unlearn-Simple.|https://doi.org/10.48550/arXiv.2410.07163|
|56|Alternate Preference Optimization for Unlearning Factual Knowledge in
  Large Language Models|Anmol Reddy Mekala, Vineeth Dorna, Shreya Dubey, Abhishek Lalwani, David Koleczek, Mukund Rungta, Sadid A. Hasan, Elita ...|<li><span style="color:#FF5733;">2024-09-20</span></li>||https://github.com/molereddy/Alternate-Preference-Optimization.|https://aclanthology.org/2025.coling-main.252/|
|57|Score Forgetting Distillation: A Swift, Data-Free Method for Machine
  Unlearning in Diffusion Models|Tianqi Chen, Shujian Zhang, Mingyuan Zhou|<li><span style="color:#FF5733;">2024-09-17</span></li>|arXiv|https://github.com/tqch/score-forgetting-distillation.|https://openreview.net/forum?id=gjwhDHeAsz|
|58|CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper
  Influence|Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan|<li><span style="color:#FF5733;">2024-08-26</span></li>|NeurIPS|https://github.com/xiye7lai/CURE4Rec.|http://papers.nips.cc/paper_files/paper/2024/hash/b364953e402d7d92e13830383677efb5-Abstract-Datasets_and_Benchmarks_Track.html|
|59|Scalable and Certifiable Graph Unlearning: Overcoming the Approximation
  Error Barrier|Lu Yi, Zhewei Wei|<li><span style="color:#FF5733;">2024-08-01</span></li>|ICLR|https://github.com/luyi256/ScaleGUN.|https://openreview.net/forum?id=pPyJyeLriR|
|60|Multimodal Unlearnable Examples: Protecting Data against Multimodal
  Contrastive Learning|Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao|<li><span style="color:#FF5733;">2024-07-23</span></li>|ACM Multimedia|https://github.com/thinwayliu/Multimodal-Unlearnable-Examples|https://doi.org/10.48550/arXiv.2407.16307|
|61|Safe Unlearning: A Surprisingly Effective and Generalizable Solution to
  Defend Against Jailbreak Attacks|Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|<li><span style="color:#FF5733;">2024-07-03</span></li>|arXiv|https://github.com/thu-coai/SafeUnlearning|https://doi.org/10.48550/arXiv.2407.02855|
|62|Enable the Right to be Forgotten with Federated Client Unlearning in
  Medical Imaging|Zhipeng Deng, Luyang Luo, Hao Chen|<li><span style="color:#FF5733;">2024-07-02</span></li>|Lecture notes in computer science|https://github.com/dzp2095/FCU.|https://doi.org/10.1007/978-3-031-72117-5_23|
|63|To Forget or Not? Towards Practical Knowledge Unlearning for Large
  Language Models|Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang|<li><span style="color:#FF5733;">2024-07-01</span></li>|OpenAlex|https://github.com/zjunlp/KnowUnDo.|https://doi.org/10.18653/v1/2024.findings-emnlp.82|
|64|Targeted Unlearning with Single Layer Unlearning Gradient|Zikui Cai, Yaoteng Tan, M. Salman Asif|<li><span style="color:#FF5733;">2024-07-01</span></li>|arXiv|https://github.com/CSIPlab/SLUG.|http://arxiv.org/abs/2407.11867v3|
|65|From Theft to Bomb-Making: The Ripple Effect of Unlearning in Defending
  Against Jailbreak Attacks|Zhexin Zhang, Junxiao Yang, Yida Lu, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|<li><span style="color:#FF5733;">2024-07-01</span></li>|arXiv|https://github.com/thu-coai/SafeUnlearning.|http://arxiv.org/abs/2407.02855v3|
|66|Data Attribution for Text-to-Image Models by Unlearning Synthesized
  Images|Sheng-Yu Wang, Aaron Hertzmann, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang|<li><span style="color:#FF5733;">2024-06-13</span></li>|NeurIPS|https://github.com/PeterWang512/AttributeByUnlearning|http://papers.nips.cc/paper_files/paper/2024/hash/07fbde96bee50f4e09303fd4f877c2f3-Abstract-Conference.html|
|67|Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning
  Framework from Logit Difference|Jiabao Ji, Yujian Liu, Yang Zhang, Gaowen Liu, Ramana Rao Kompella, Sijia Liu, Shiyu Chang|<li><span style="color:#FF5733;">2024-06-12</span></li>|NeurIPS|https://github.com/UCSB-NLP-Chang/ULD.|http://papers.nips.cc/paper_files/paper/2024/hash/171291d8fed723c6dfc76330aa827ff8-Abstract-Conference.html|
|68|Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces|Yihuai Hong, Lei Yu, Haiqin Yang, Shauli Ravfogel, Mor Geva|<li><span style="color:#FF5733;">2024-06-01</span></li>|arXiv|https://github.com/yihuaihong/ConceptVectors.|https://doi.org/10.48550/arXiv.2406.11614|
|69|Defensive Unlearning with Adversarial Training for Robust Concept
  Erasure in Diffusion Models|Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu|<li><span style="color:#FF5733;">2024-05-24</span></li>|NeurIPS|https://github.com/OPTML-Group/AdvUnlearn|http://papers.nips.cc/paper_files/paper/2024/hash/40954ac18a457dd5f11145bae6454cdf-Abstract-Conference.html|
|70|Unlearning during Learning: An Efficient Federated Machine Unlearning
  Method|Hanlin Gu, Gongxi Zhu, Jie Zhang, Xinyuan Zhao, Yuxing Han, Lixin Fan, Qiang Yang|<li><span style="color:#FF5733;">2024-05-24</span></li>|OpenAlex|https://github.com/Liar-Mask/FedAU.|https://www.ijcai.org/proceedings/2024/446|
|71|Erasing Concepts from Text-to-Image Diffusion Models with Few-shot
  Unlearning|Masane Fuchi, Tomohiro Takagi|<li><span style="color:#FF5733;">2024-05-12</span></li>|BMVC|https://github.com/fmp453/few-shot-erasing|https://doi.org/10.48550/arXiv.2405.07288|
|72|Purify Unlearnable Examples via Rate-Constrained Variational
  Autoencoders|Yi Yu, Yu-Fei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap‐Peng Tan, Alex C. Kot|<li><span style="color:#FF5733;">2024-05-02</span></li>|ICML|https://github.com/yuyi-sd/D-VAE.|https://openreview.net/forum?id=0LBNdbmQCM|
|73|Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity|Hanlin Gu, Win Kent Ong, Chee Seng Chan, Lixin Fan|<li><span style="color:#FF5733;">2024-05-01</span></li>|NeurIPS|https://github.com/OngWinKent/Federated-Feature-Unlearning|http://papers.nips.cc/paper_files/paper/2024/hash/2b09bb02b90584e2be94ff3ae09289bc-Abstract-Conference.html|
|74|Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew
  Resilience|Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Ab...|<li><span style="color:#FF5733;">2024-05-01</span></li>|Lecture notes in computer science|https://github.com/thanhtrunghuynh93/fastFedUL|https://doi.org/10.1007/978-3-031-70362-1_4|
|75|Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality
  Constraints|Yash Sinha, Murari Mandal, Mohan S. Kankanhalli|<li><span style="color:#FF5733;">2024-05-01</span></li>||https://github.com/MachineUnlearn/MMRecUN|https://doi.org/10.1609/aaai.v39i12.33367|
|76|SOUL: Unlocking the Power of Second-Order Optimization for LLM
  Unlearning|Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|<li><span style="color:#FF5733;">2024-04-28</span></li>|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/OPTML-Group/SOUL.|https://doi.org/10.18653/v1/2024.emnlp-main.245|
|77|Eraser: Jailbreaking Defense in Large Language Models via Unlearning
  Harmful Knowledge|Weikai Lu, Ziqian Zeng, Jianwei Wang, Zhengdong Lu, Zelin Chen, Huiping Zhuang, Cen Chen|<li><span style="color:#FF5733;">2024-04-08</span></li>|OpenReview|https://github.com/ZeroNLP/Eraser.|https://openreview.net/pdf/56792e044282ec46ecc14cfd3f68de33ed880b8e.pdf|
|78|Machine Unlearning for Document Classification|Lei Kang, Mohamed Ali Souibgui, Fei Yang, Lluis Gomez, Ernest Valveny, Dimosthenis Karatzas|<li><span style="color:#FF5733;">2024-04-01</span></li>|Lecture notes in computer science|https://github.com/leitro/MachineUnlearning-DocClassification|https://doi.org/10.1007/978-3-031-70546-5_6|
|79|Towards Efficient and Effective Unlearning of Large Language Models for
  Recommendation|Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang, Yong Yu|<li><span style="color:#FF5733;">2024-03-06</span></li>|Frontiers of Computer Science|https://github.com/justarter/E2URec|https://doi.org/10.1007/s11704-024-40044-2|
|80|Towards Lifecycle Unlearning Commitment Management: Measuring
  Sample-level Approximate Unlearning Completeness|Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang|<li><span style="color:#FF5733;">2024-03-01</span></li>|arXiv|https://github.com/Happy2Git/Unlearning_Inference_IAM.|https://doi.org/10.48550/arXiv.2506.06112|
|81|Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine
  Unlearning|Chongyu Fan, Jiancheng Liu, Alfred Olivier Hero, Sijia Liu|<li><span style="color:#FF5733;">2024-03-01</span></li>|Lecture notes in computer science|https://github.com/OPTML-Group/Unlearn-WorstCase.|https://doi.org/10.1007/978-3-031-72664-4_16|
|82|UnlearnCanvas: A Stylized Image Dataset to Benchmark Machine Unlearning
  for Diffusion Models|Yihua Zhang, Yimeng Zhang, Yuguang Yao, Jinghan Jia, Jiancheng Liu, Xiaoming Liu, Sijia Liu|<li><span style="color:#FF5733;">2024-02-19</span></li>|arXiv|https://github.com/OPTML-Group/UnlearnCanvas.|https://doi.org/10.48550/arXiv.2402.11846|
|83|Machine Unlearning for Image-to-Image Generative Models|Guihong Li, Hsiang Hsu, Chun-Fu, Chen, Diana Marculescu|<li><span style="color:#FF5733;">2024-01-01</span></li>|ICLR|https://github.com/jpmorganchase/l2l-generator-unlearning.|https://openreview.net/forum?id=9hjVoPWPnh|
|84|Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need|Xianlong Wang, Minghui Li, Weiping Liu, Hangtao Zhang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Hai Jin|<li><span style="color:#FF5733;">2024-01-01</span></li>|NeurIPS|https://github.com/CGCL-codes/UnlearnablePC|http://papers.nips.cc/paper_files/paper/2024/hash/b3d868b4b5b61b35a849ba6e7a1d4449-Abstract-Conference.html|
|85|Soft Prompting for Unlearning in Large Language Models|Karuna Bhaila, Minh-Hao Van, Xintao Wu|<li><span style="color:#FF5733;">2024-01-01</span></li>|OpenAlex|https://github.com/karuna-bhaila/llm_unlearning|https://doi.org/10.18653/v1/2025.naacl-long.204|
|86|Revisiting Who&apos;s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective|Yujian Liu, Yang Zhang, Tommi S. Jaakkola, Shiyu Chang|<li><span style="color:#FF5733;">2024-01-01</span></li>|Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing|https://github.com/UCSB-NLP-Chang/causal_unlearn.git.|https://doi.org/10.18653/v1/2024.emnlp-main.495|
|87|Machine Unlearning via Representation Forgetting With Parameter Self-Sharing|Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu|<li><span style="color:#FF5733;">2024-01-01</span></li>|IEEE Transactions on Information Forensics and Security|https://github.com/wwq5-code/RFU-SS.git.|https://doi.org/10.1109/TIFS.2023.3331239|
|88|Machine Unlearning via Null Space Calibration|Huiqiang Chen, Tianqing Zhu, Xinjie Yu, Wanlei Zhou|<li><span style="color:#FF5733;">2024-01-01</span></li>|OpenAlex|https://github.com/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration|https://www.ijcai.org/proceedings/2024/40|
|89|Machine Unlearning of Pre-trained Large Language Models|Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue|<li><span style="color:#FF5733;">2024-01-01</span></li>|OpenReview|https://github.com/yaojin17/Unlearning_LLM|https://openreview.net/pdf/fe1970154c67c30db5b9431d2efc8b5d8ece2dee.pdf|
|90|Machine Unlearning in Generative AI: A Survey|Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang|<li><span style="color:#FF5733;">2024-01-01</span></li>|arXiv|https://github.com/franciscoliu/GenAI-MU-Reading.|https://doi.org/10.48550/arXiv.2407.20516|
|91|Corrective Machine Unlearning|Shashwat Goel, Ameya Prabhu, Philip H. S. Torr, Ponnurangam Kumaraguru, Amartya Sanyal|<li><span style="color:#FF5733;">2024-01-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/drimpossible/corrective-unlearning-bench.|https://local.forskningsportal.dk/local/dki-cgi/ws/cris-link?src=ku&id=ku-3bc52420-b6c0-4ebf-a0ea-0dedef731af7&ti=Corrective%20Machine%20Unlearning|
|92|Large Language Model Unlearning via Embedding-Corrupted Prompts|Chris Yuhao Liu, Yaxuan Wang, Jeffrey Flanigan, Yang Liu|<li><span style="color:#FF5733;">2024-01-01</span></li>|NeurIPS|https://github.com/chrisliu298/llm-unlearn-eco|http://papers.nips.cc/paper_files/paper/2024/hash/d6359156e0e30b1caa116a4306b12688-Abstract-Conference.html|
|93|Dissecting Language Models: Machine Unlearning via Selective Pruning|Nicholas Pochinkov, Nandi Schoots|<li><span style="color:#FF5733;">2024-01-01</span></li>|arXiv|https://github.com/nickypro/selective-pruning|https://doi.org/10.48550/arXiv.2403.01267|
|94|Boosting Alignment for Post-Unlearning Text-to-Image Generative Models|Myeongseob Ko, Henry Li, Zhun Wang, Jonathan Patsenker, Jiachen T. Wang, Qinbin Li, Ming Jin, Dawn Song, Ruoxi Jia|<li><span style="color:#FF5733;">2024-01-01</span></li>|NeurIPS|https://github.com/reds-lab/Restricted_gradient_diversity_unlearning.git.|http://papers.nips.cc/paper_files/paper/2024/hash/9aa51796f8bede2ea947d6b6e3087ab8-Abstract-Conference.html|
|95|Breaking the Trilemma of Privacy, Utility, and Efficiency via Controllable Machine Unlearning|Zheyuan Liu, Guangyao Dou, Wang-Chien Chen, Chunhui Zhang, Yijun Tian, Ziwei Zhu|<li><span style="color:#FF5733;">2024-01-01</span></li>|Proceedings of the ACM Web Conference 2022|https://github.com/guangyaodou/ConMU.|https://doi.org/10.48550/arXiv.2310.18574|
|96|LMEraser: Large Model Unlearning through Adaptive Prompt Tuning|Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia|<li><span style="color:#FF5733;">2024-01-01</span></li>|arXiv|https://github.com/lmeraser/lmeraser|https://doi.org/10.48550/arXiv.2404.11056|
|97|Dataset Condensation Driven Machine Unlearning|Junaid Iqbal Khan|<li><span style="color:#FF5733;">2024-01-01</span></li>|arXiv|https://github.com/algebraicdianuj/DC_U|https://doi.org/10.48550/arXiv.2402.00195|
|98|A Closer Look at Machine Unlearning for Large Language Models|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|<li><span style="color:#FF5733;">2024-01-01</span></li>|arXiv|https://github.com/sail-sg/closer-look-LLM-unlearning.|https://openreview.net/forum?id=Q1MHvGmhyT|
|99|Efficient Federated Unlearning under Plausible Deniability|Ayush K. Varshney, Vicenç Torra|<li><span style="color:#FF5733;">2024-01-01</span></li>|Machine Learning|https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability|https://doi.org/10.1007/s10994-024-06685-x|
|100|Generative Unlearning for Any Identity|Juwon Seo, Sung-Hoon Lee, Tae-Young Lee, Seungjun Moon, Gyeong-Moon Park|<li><span style="color:#FF5733;">2024-01-01</span></li>|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/KHU-AGI/GUIDE.|https://doi.org/10.1109/CVPR52733.2024.00874|
|101|From Hope to Safety: Unlearning Biases of Deep Models via Gradient Penalization in Latent Space|Maximilian Dreyer, Frederik Pahde, Christopher J. Anders, Wojciech Samek, Sebastian Lapuschkin|<li><span style="color:#FF5733;">2024-01-01</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/frederikpahde/rrclarc.|https://doi.org/10.1609/aaai.v38i19.30096|
|102|Game-Theoretic Unlearnable Example Generator|Shuang Liu, Yihan Wang, Xiao-Shan Gao|<li><span style="color:#FF5733;">2024-01-01</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/hong-xian/gue.|https://doi.org/10.1609/aaai.v38i19.30130|
|103|FedCSA: Boosting the Convergence Speed of Federated Unlearning under Data Heterogeneity|Zhen Wang, Daniyal M. Alghazzawi, Li Cheng, Gaoyang Liu, Chen Wang, Zeng Cheng, Yang Yang|<li><span style="color:#FF5733;">2023-12-21</span></li>|ISPA/BDCloud/SocialCom/SustainCom|https://github.com/ZhenWang9/FedCSA.|https://doi.org/10.1109/ispa-bdcloud-socialcom-sustaincom59178.2023.00083|
|104|Deep Unlearning: Fast and Efficient Gradient-free Approach to Class
  Forgetting|Sangamesh Kodge, Gobinda Saha, Kaushik Roy|<li><span style="color:#FF5733;">2023-12-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/sangamesh-kodge/class_forgetting.|https://openreview.net/forum?id=BmI5p6wBi0|
|105|Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning
  Interference with Gradient Projection|Tuan Hoang, Santu Rana, Sunil Gupta, Svetha Venkatesh|<li><span style="color:#FF5733;">2023-12-01</span></li>|2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/hnanhtuan/projected_gradient_unlearning.|https://doi.org/10.1109/WACV57701.2024.00475|
|106|Stable Unlearnable Example: Enhancing the Robustness of Unlearnable
  Examples via Stable Error-Minimizing Noise|Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun|<li><span style="color:#FF5733;">2023-11-01</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/liuyixin-louis/Stable-Unlearnable-Example.|https://doi.org/10.48550/arXiv.2311.13091|
|107|Towards Machine Unlearning Benchmarks: Forgetting the Personal
  Identities in Facial Recognition Systems|Dasol Choi, Dongbin Na|<li><span style="color:#FF5733;">2023-11-01</span></li>|arXiv|https://github.com/ndb796/MachineUnlearning.|https://doi.org/10.48550/arXiv.2311.02240|
|108|SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency
  in Both Image Classification and Generation|Chongyu Fan, Jiancheng Liu, Yihua Zhang, Eric Wong, Dennis Wei, Sijia Liu|<li><span style="color:#FF5733;">2023-10-01</span></li>|arXiv|https://github.com/OPTML-Group/Unlearn-Saliency.|https://openreview.net/forum?id=gn0mIhQGNM|
|109|To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still
  Easy To Generate Unsafe Images ... For Now|Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu|<li><span style="color:#FF5733;">2023-10-01</span></li>|Lecture notes in computer science|https://github.com/OPTML-Group/Diffusion-MU-Attack.|https://doi.org/10.1007/978-3-031-72998-0_22|
|110|Fair Machine Unlearning: Data Removal while Mitigating Disparities|Alex Oesterling, Jiaqi Ma, Flávio P. Calmon, Himabindu Lakkaraju|<li><span style="color:#FF5733;">2023-07-01</span></li>|AISTATS|https://github.com/AI4LIFE-GROUP/fair-unlearning|https://proceedings.mlr.press/v238/oesterling24a.html|
|111|Fast Yet Effective Machine Unlearning|Ayush K. Tarun, Vikram S. Chundawat, Murari Mandal, Mohan S. Kankanhalli|<li><span style="color:#FF5733;">2023-05-01</span></li>|IEEE Transactions on Neural Networks and Learning Systems|https://github.com/vikram2000b/Fast-Machine-Unlearning|https://doi.org/10.1109/tnnls.2023.3266233|
|112|Unlearnable Examples Give a False Sense of Security: Piercing through
  Unexploitable Data with Learnable Examples|Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong|<li><span style="color:#FF5733;">2023-05-01</span></li>|ACM Multimedia|https://github.com/jiangw-0/LE_JCDP.|https://doi.org/10.48550/arXiv.2305.09241|
|113|CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|<li><span style="color:#FF5733;">2023-04-17</span></li>|RTML Workshop 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/cleanclip-mitigating-data-poisoning-attacks/code)|https://openreview.net/pdf/6a86afb6f0e0ce8a38d619097336004f6f0b6a73.pdf|
|114|Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural
  Networks|Vijaya Raghavan T. Ramkumar, Elahe Arani, Bahram Zonooz|<li><span style="color:#FF5733;">2023-03-01</span></li>|Trans. Mach. Learn. Res.|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learn-unlearn-and-relearn-an-online-learning/code)|https://openreview.net/pdf/e61ee961464c8ff0055125464944b1b3ca4bb37a.pdf|
|115|Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable
  Example Attacks|Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu|<li><span style="color:#FF5733;">2023-03-01</span></li>|arXiv|https://github.com/lafeat/ueraser.|https://doi.org/10.48550/arXiv.2303.15127|
|116|Voint Cloud: Multi-View Point Cloud Representation for 3D Understanding |Abdullah Hamdi, Silvio Giancola, Bernard Ghanem|<li><span style="color:#FF5733;">2023-02-02</span></li>|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/voint-cloud-multi-view-point-cloud/code)|https://openreview.net/pdf/b3f85b26464b6cd916b9a66adb82d3d295c951c4.pdf|
|117|Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks|Noam Wies, Yoav Levine, Amnon Shashua|<li><span style="color:#FF5733;">2023-02-02</span></li>|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/sub-task-decomposition-enables-learning-in/code)|https://openreview.net/pdf/0e2acc3ed9aaaff91e94533aa1eb2cec3a27915b.pdf|
|118|One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks|Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang|<li><span style="color:#FF5733;">2023-02-02</span></li>|ICLR 2023 notable top 25%|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/one-pixel-shortcut-on-the-learning-preference/code)|https://openreview.net/pdf/b69561625d5ce4388db999c205fdb5a8b988725e.pdf|
|119|Zero-Shot Machine Unlearning|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|<li><span style="color:#FF5733;">2023-01-01</span></li>|IEEE Transactions on Information Forensics and Security|https://github.com/ayu987/zero-shot-unlearning|https://doi.org/10.1109/tifs.2023.3265506|
|120|What Can We Learn from Unlearnable Datasets?|Pedro Sandoval Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein|<li><span style="color:#FF5733;">2023-01-01</span></li>|NeurIPS|https://github.com/psandovalsegura/learn-from-unlearnable|http://papers.nips.cc/paper_files/paper/2023/hash/ee5bb72130c332c3d4bf8d231e617506-Abstract-Conference.html|
|121|Task-Aware Machine Unlearning and Its Application in Load Forecasting|Wangkun Xu, Fei Teng|<li><span style="color:#FF5733;">2023-01-01</span></li>|IEEE Transactions on Power Systems|https://github.com/xuwkk/task_aware_machine_unlearning.|https://doi.org/10.1109/tpwrs.2024.3376828|
|122|Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples|Jiaming Zhang, Xingjun Ma, Qi Yi, Jitao Sang, Yu-Gang Jiang, Yaowei Wang, Changsheng Xu|<li><span style="color:#FF5733;">2023-01-01</span></li>|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/jiamingzhang94/Unlearnable-Clusters.|https://doi.org/10.1109/CVPR52729.2023.00388|
|123|Unlearning Bias in Language Models by Partitioning Gradients|Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, Heng Ji|<li><span style="color:#FF5733;">2023-01-01</span></li>|Findings of the Association for Computational Linguistics: ACL 2022|https://github.com/CharlesYu2000/PCGU-UnlearningBias.|https://doi.org/10.18653/v1/2023.findings-acl.375|
|124|Recommendation Unlearning via Influence Function|Yang Zhang, Zhiyu Hu, Yimeng Bai, Fuli Feng, Jiancan Wu, Qifan Wang, Xiangnan He|<li><span style="color:#FF5733;">2023-01-01</span></li>|ACM Transactions on Recommender Systems|https://github.com/baiyimeng/IFRU.|https://doi.org/10.48550/arXiv.2307.02147|
|125|Model Sparsification Can Simplify Machine Unlearning|Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu, Yang Liu, Pranay Sharma, Sijia Liu|<li><span style="color:#FF5733;">2023-01-01</span></li>|NeurIPS|https://github.com/OPTML-Group/Unlearn-Sparse.|http://papers.nips.cc/paper_files/paper/2023/hash/a204aa68ab4e970e1ceccfb5b5cdc5e4-Abstract-Conference.html|
|126|Inductive Graph Unlearning|Cheng-Long Wang, Mengdi Huai, Di Wang|<li><span style="color:#FF5733;">2023-01-01</span></li>|USENIX Security Symposium|https://github.com/Happy2Git/GUIDE.|https://www.usenix.org/conference/usenixsecurity23/presentation/wang-cheng-long|
|127|GNNDelete: A General Strategy for Unlearning in Graph Neural Networks|Jiali Cheng, George Dasoulas, Huan He, Chirag Agarwal, Marinka Zitnik|<li><span style="color:#FF5733;">2023-01-01</span></li>|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/gnndelete-a-general-strategy-for-unlearning/code)|https://openreview.net/pdf/d344e51366b6eeb1347bf96857a1cdeb5ca03e64.pdf|
|128|GIF: A General Graph Unlearning Strategy via Influence Function|Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He|<li><span style="color:#FF5733;">2023-01-01</span></li>|Proceedings of the ACM Web Conference 2022|https://github.com/wujcan/GIF-torch|https://doi.org/10.48550/arXiv.2304.02835|
|129|ERM-KTP: Knowledge-Level Machine Unlearning via Knowledge Transfer|Shen Lin, Xiaoyu Zhang, Chenyang Chen, Xiaofeng Chen, Willy Susilo|<li><span style="color:#FF5733;">2023-01-01</span></li>|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/RUIYUN-ML/ERM-KTP|https://doi.org/10.1109/CVPR52729.2023.01929|
|130|A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions|Jiaxi Yang, Yang Zhao|<li><span style="color:#FF5733;">2023-01-01</span></li>|arXiv|https://github.com/abbottyanginchina/Awesome-Federated-Unlearning.|https://doi.org/10.48550/arXiv.2310.19218|
|131|Adapt then Unlearn: Exploring Parameter Space Semantics for Unlearning
  in Generative Adversarial Networks|Piyush Tiwary, Atri Guha, Subhodip Panda, Prathosh A. P.|<li><span style="color:#FF5733;">2023-01-01</span></li>|Trans. Mach. Learn. Res.|https://github.com/atriguha/Adapt_Unlearn.|https://openreview.net/forum?id=jAHEBivObO|
|132|PatchGT: Transformer over Non-trainable Clusters for Learning Graph Representations|Han Gao, Xu Han, Jiaoyang Huang, Jian-Xun Wang, Liping Liu|<li><span style="color:#FF5733;">2022-11-24</span></li>|LoG 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/patchgt-transformer-over-non-trainable/code)|https://openreview.net/pdf/7a95f2c19eec64ed2379944a8398af365f166ed3.pdf|
|133|Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|<li><span style="color:#FF5733;">2022-11-01</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/trap-and-replace-defending-backdoor-attacks/code)|https://openreview.net/pdf/a0b040b733099d83fd30969cd35fa8cc35c367b2.pdf|
|134|Autoregressive Perturbations for Data Poisoning|Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W. Jacobs|<li><span style="color:#FF5733;">2022-11-01</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/autoregressive-perturbations-for-data/code)|https://openreview.net/pdf/f465f9046724189ffd748375c5f6a4ac4d722e10.pdf|
|135|Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models|Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro|<li><span style="color:#FF5733;">2022-11-01</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/exploring-the-limits-of-domain-adaptive/code)|https://openreview.net/pdf/cbffa1a0bf2612f146adbc70397e00fc131d2db4.pdf|
|136|The Privacy Onion Effect: Memorization is Relative|Nicholas Carlini, Matthew Jagielski, Chiyuan Zhang, Nicolas Papernot, Andreas Terzis, Florian Tramer|<li><span style="color:#FF5733;">2022-11-01</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/the-privacy-onion-effect-memorization-is/code)|https://openreview.net/pdf/9693b6b162a476e99f5438ece8d66f14a520d97b.pdf|
|137|Characterizing Datapoints via Second-Split Forgetting|Pratyush Maini, Saurabh Garg, Zachary Chase Lipton, J Zico Kolter|<li><span style="color:#FF5733;">2022-07-21</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/characterizing-datapoints-via-second-split/code)|https://openreview.net/pdf/4e3bb598ca199212473a7389946dde4baf3d97b1.pdf|
|138|Deep Unlearning via Randomized Conditionally Independent Hessians|Ronak Mehta, Sourav Pal, Vikas Pratap Singh, Sathya N. Ravi|<li><span style="color:#FF5733;">2022-06-01</span></li>||https://github.com/vsingh-group/LCODEC-deep-unlearning|https://doi.org/10.1109/cvpr52688.2022.01017|
|139|Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks using an
  Incompetent Teacher|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|<li><span style="color:#FF5733;">2022-05-01</span></li>|Proceedings of the AAAI Conference on Artificial Intelligence|https://github.com/vikram2000b/bad-teaching-unlearning|https://doi.org/10.48550/arXiv.2205.08096|
|140|Robust Unlearnable Examples: Protecting Data Privacy Against Adversarial Learning|Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao|<li><span style="color:#FF5733;">2022-03-01</span></li>|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/robust-unlearnable-examples-protecting-data/code)|https://openreview.net/pdf/cb11d28b469a29f68dc6043214ae3f4f579b360a.pdf|
|141|Knowledge Removal in Sampling-based Bayesian Inference|Shaopeng Fu, Fengxiang He, Dacheng Tao|<li><span style="color:#FF5733;">2022-01-29</span></li>|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/knowledge-removal-in-sampling-based-bayesian/code)|https://openreview.net/pdf/a42ad90a502167268f1ba4c67f57150bf59ccbc9.pdf|
|142|Recommendation Unlearning|Chong Chen, Fei Sun, Min Zhang, Bolin Ding|<li><span style="color:#FF5733;">2022-01-01</span></li>|Proceedings of the ACM Web Conference 2022|https://github.com/chenchongthu/Recommendation-Unlearning|https://openreview.nethttps://arxiv.org/pdf/2201.06820.pdf|
|143|QUARK: Controllable Text Generation with Reinforced Unlearning|Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, Yejin Choi|<li><span style="color:#FF5733;">2022-01-01</span></li>|NeurIPS 2022 (Oral Selection)|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/quark-controllable-text-generation-with/code)|http://papers.nips.cc/paper_files/paper/2022/hash/b125999bde7e80910cbdbd323087df8f-Abstract-Conference.html|
|144|Machine Unlearning of Federated Clusters|Chao Pan, Jin Sima, Saurav Prakash, Vishal Singh Rana, Olgica Milenković|<li><span style="color:#FF5733;">2022-01-01</span></li>|ICLR 2023 poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/machine-unlearning-of-federated-clusters/code)|https://openreview.net/pdf/51ee65b11a32de7ad446a5917d748f9da5399714.pdf|
|145|Knowledge Unlearning for Mitigating Privacy Risks in Language Models|Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo|<li><span style="color:#FF5733;">2022-01-01</span></li>|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/knowledge-unlearning-for-mitigating-privacy/code)|https://openreview.net/pdf/b13e3c3cdc06b81ed93687d74823ddd0aef79674.pdf|
|146|Hidden Poison: Machine Unlearning Enables Camouflaged Poisoning Attacks|Jimmy Z. Di, Jack F. Douglas, Jayadev Acharya, Gautam Kamath, Ayush Sekhari|<li><span style="color:#FF5733;">2022-01-01</span></li>|Submitted to ICLR 2023|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/hidden-poison-machine-unlearning-enables/code)|http://papers.nips.cc/paper_files/paper/2023/hash/8b4add8b0aa8749d80a34ca5d941c355-Abstract-Conference.html|
|147|FedHarmony: Unlearning Scanner Bias with Distributed Data|Nicola K. Dinsdale, Mark Jenkinson, Ana I. L. Namburete|<li><span style="color:#FF5733;">2022-01-01</span></li>|Lecture notes in computer science|https://github.com/nkdinsdale/FedHarmony.|https://doi.org/10.1007/978-3-031-16452-1_66|
|148|Deep Regression Unlearning|Ayush Kumar Tarun, Vikram Singh Chundawat, Murari Mandal, Mohan S. Kankanhalli|<li><span style="color:#FF5733;">2022-01-01</span></li>|arXiv|https://github.com/ayu987/deep-regression-unlearning|https://proceedings.mlr.press/v202/tarun23a.html|
|149|Continual Learning and Private Unlearning|Bo Liu, Qiang Liu, Peter Stone|<li><span style="color:#FF5733;">2022-01-01</span></li>|CoLLAs|https://github.com/Cranial-XIX/Continual-Learning-Private-Unlearning.|https://proceedings.mlr.press/v199/liu22a.html|
|150|Atlas: Universal Function Approximator For Memory Retention|Heinrich van Deventer, Anna Sergeevna Bosman|<li><span style="color:#FF5733;">2022-01-01</span></li>|NeurIPS 2022 Submitted|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/atlas-universal-function-approximator-for/code)|https://openreview.net/pdf/95b89482f610b970f80506d51d6924d79cd125e6.pdf|
|151|Adversarial Unlearning: Reducing Confidence Along Adversarial Directions|Amrith Setlur, Benjamin Eysenbach, Virginia Smith, Sergey Levine|<li><span style="color:#FF5733;">2022-01-01</span></li>|NeurIPS 2022 Accept|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-reducing-confidence/code)|http://papers.nips.cc/paper_files/paper/2022/hash/75f1a165c7561e028c41d42fa6286a76-Abstract-Conference.html|
|152|A Survey of Machine Unlearning|Thanh Tam Nguyen, Thanh Trung Huynh, Zhao Ren, Phi Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin, Quoc Viet Hung Nguyen|<li><span style="color:#FF5733;">2022-01-01</span></li>|ACM Transactions on Intelligent Systems and Technology|https://github.com/tamlhp/awesome-machine-unlearning.|https://doi.org/10.48550/arXiv.2209.02299|
|153|Certified Graph Unlearning|Eli Chien, Chao Pan, Olgica Milenkovic|<li><span style="color:#FF5733;">2022-01-01</span></li>|NeurIPS 2022 GLFrontiers Workshop|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/certified-graph-unlearning/code)|https://openreview.net/pdf/255ad2fc5a24c56a6f91f08eabdfdd9ba94a3bf2.pdf|
|154|Adaptive Machine Unlearning|Varun Gupta, Christopher Jung, Seth Neel, Aaron Roth, Saeed Sharifi -Malvajerdi, Christopher Waites|<li><span style="color:#FF5733;">2021-11-10</span></li>|Neural Information Processing Systems|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adaptive-machine-unlearning/code)|https://proceedings.neurips.cc/paper/2021/hash/87f7ee4fdb57bdfd52179947211b7ebb-Abstract.html|
|155|Unlearnable Examples: Making Personal Data Unexploitable|Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang|<li><span style="color:#FF5733;">2021-01-13</span></li>|ICLR 2021 Spotlight|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/unlearnable-examples-making-personal-data/code)|https://openreview.net/pdf/eb123b0f1c20d0c5d47b33fa7feca81748e02666.pdf|
|156|Adversarial Unlearning of Backdoors via Implicit Hypergradient|Yi Zeng, Si Chen, Won Park, Z. Morley Mao, Ming Jin, Ruoxi Jia|<li><span style="color:#FF5733;">2021-01-01</span></li>|ICLR 2022 Poster|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/adversarial-unlearning-of-backdoors-via/code)|https://openreview.net/pdf/6aeb6e81c9d0eadbb4cfbefb6caac0f155d561ea.pdf|
|157|Towards Probabilistic Verification of Machine Unlearning|David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal|<li><span style="color:#FF5733;">2020-01-01</span></li>|arXiv|https://github.com/inspire-group/unlearning-verification|http://arxiv.org/abs/2003.04247v2|
|158|When Machine Unlearning Jeopardizes Privacy|Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang|<li><span style="color:#FF5733;">2020-01-01</span></li>|Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security|https://github.com/MinChen00/UnlearningLeaks.|https://doi.org/10.1145/3460120.3484756|
|159|Learnability for the Information Bottleneck|Tailin Wu, Ian Fischer, Isaac Chuang, Max Tegmark|<li><span style="color:#FF5733;">2019-04-17</span></li>|LLD 2019|[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/learnability-for-the-information-bottleneck/code)|https://openreview.net/pdf/1290e4dc7b5d511b8b213f53c54006475d031bfc.pdf|
