# Table of Contents
1. [Machine Unlearning Papers](#machine-unlearning-papers)
2. [Other topics](#other-topics)
3. [Machine Unlearning Papers with Code](#machine-unlearning-papers-with-code)


## Machine Unlearning Papers
This GitHub repository contains an updated list of Federated Learning papers as of **July 11, 2025**. 

- The resources are collected from various sources, including arXiv, NeurIPS, ICML, ICLR, ACL, EMNLP, AAAI, IJCAI, KDD, CVPR, ICCV, ECCV, NIPS, IEEE, ACM, Springer, ScienceDirect, Wiley, Nature, Science, and other top AI/ML conferences and journals.
- For a better reading experience, visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

---
# Other Topics
Explore additional research papers on the following topics:
- For **Large Language Models** papers, please visit the [**LLM Repository**](https://github.com/mtuann/llm-updated-papers).
- For **Backdoor Learning** papers, please visit the [**Backdoor Learning Repository**](https://github.com/mtuann/backdoor-ai-resources).
- For **Federated Learning** papers, please visit the [**Federated Learning Repository**](https://github.com/mtuann/federated-learning-updated-papers).
- For **Machine Unlearning** papers, please visit the [**Machine Unlearning Repository**](https://github.com/mtuann/machine-unlearning-papers).

---

For contributions, inquiries, or suggestions, feel free to reach out via [email](mailto:tuannm0312@gmail.com).

---

If you find this application helpful and would like to support its development, you can buy me a coffee using one of the following methods:
- **Techcombank (Vietnam):** 5877 5555 55 (Nguyen Thi Lan Phuong)
- **PayPal or Credit/Debit Card:** [https://ko-fi.com/miutheladycat](https://ko-fi.com/miutheladycat)

---

## Machine Unlearning Papers with Code
Due to GitHub repository limitations, this section includes only those papers that provide accompanying code, sorted by publish date. For access to the full list of papers, please visit the [Shinyapps website](https://mtuann.shinyapps.io/research-papers/).

---


|No.|Title|Authors|Publish Date|Venue|Code|URL|
|---|---|---|---|---|---|---|
|1|Efficient Unlearning with Privacy Guarantees|Josep Domingo-Ferrer, Najeeb Jebreel, David Sánchez|2025-07-07|arXiv|https://github.com/najeebjebreel/EUPG|http://arxiv.org/abs/2507.04771v1|
|2|Forget-MI: Machine Unlearning for Forgetting Multimodal Information in Healthcare Settings|Shahad Hardan, Darya Taratynova, Abdelmajid Essofi, Karthik Nandakumar, Mohammad Yaqub|2025-06-29|arXiv|https://github.com/BioMedIA-MBZUAI/Forget-MI|http://arxiv.org/abs/2506.23145v1|
|3|Align-then-Unlearn: Embedding Alignment for LLM Unlearning|Philipp Spohn, Leander Girrbach, Jessica Bader, Zeynep Akata|2025-06-16|arXiv|https://github.com/ExplainableML/align-then-unlearn|https://doi.org/10.48550/arXiv.2506.13181|
|4|Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from Model Outputs|Yiwei Chen, Soumyadeep Pal, Yimeng Zhang, Qing Qu, Sijia Liu|2025-06-16|arXiv|https://github.com/OPTML-Group/Unlearn-Trace|http://arxiv.org/abs/2506.14003v1|
|5|BLUR: A Bi-Level Optimization Approach for LLM Unlearning|Hadi Reisizadeh, Jinghan Jia, Zhiqi Bu, Bhanukiran Vinzamuri, Anil Ramakrishna, Kai-Wei Chang, Volkan Cevher, Sijia Liu, Mingyi Hong|2025-06-09|arXiv|https://github.com/OptimAI-Lab/BLURLLMUnlearning|https://doi.org/10.48550/arXiv.2506.08164|
|6|Certified Unlearning for Neural Networks|Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo|2025-06-08|arXiv|https://github.com/stair-lab/certified-unlearning-neural-networks-icml-2025|https://doi.org/10.48550/arXiv.2506.06985|
|7|Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness|Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chien, Kamalika Chaudhuri, Olgica Milenkovic, Pan Li|2025-06-06|arXiv|https://github.com/Graph-COM/Knowledge_Unlearning|https://doi.org/10.48550/arXiv.2506.05735|
|8|Towards Lifecycle Unlearning Commitment Management: Measuring Sample-level Unlearning Completeness|Cheng-Long Wang, Qi Li, Zihang Xiang, Yinzhi Cao, Di Wang|2025-06-06|arXiv|https://github.com/Happy2Git/Unlearning_Inference_IAM|https://doi.org/10.48550/arXiv.2506.06112|
|9|Rethinking Machine Unlearning in Image Generation Models|Renyang Liu, Wenjie Feng, Tianwei Zhang, Wei Zhou, Xueqi Cheng, See-Kiong Ng|2025-06-03|arXiv|https://github.com/ryliu68/IGMU|https://doi.org/10.48550/arXiv.2506.02761|
|10|Pre-training for Recommendation Unlearning|Guoxuan Chen, Lianghao Xia, Chao Huang|2025-05-28|arXiv|https://github.com/HKUDS/UnlearnRec|https://doi.org/10.48550/arXiv.2505.22649|
|11|Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs|Xiaoyu Xu, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du|2025-05-22|arXiv|https://github.com/XiaoyuXU1/Representational_Analysis_Tools|http://arxiv.org/abs/2505.16831v1|
|12|DUSK: Do Not Unlearn Shared Knowledge|Wonje Jeung, Sangyeon Yoon, Hyesoo Hong, Soeun Kim, Seungju Han, Youngjae Yu, Albert No|2025-05-21|arXiv|https://ai-isl.github.io/dusk|https://doi.org/10.48550/arXiv.2505.15209|
|13|Unlearning for Federated Online Learning to Rank: A Reproducibility Study|Yiling Tao, Shuyi Wang, Jiaxi Yang, Guido Zuccon|2025-05-19|arXiv|https://github.com/Iris1026/Unlearning-for-FOLTR|https://doi.org/10.48550/arXiv.2505.12791|
|14|Exploring Criteria of Loss Reweighting to Enhance LLM Unlearning|Puning Yang, Qizhou Wang, Zhuo Huang, Tongliang Liu, Chengqi Zhang, Bo Han|2025-05-17|arXiv|https://github.com/Puning97/SatImp-for-LLM-Unlearning|https://doi.org/10.48550/arXiv.2505.11953|
|15|WaterDrum: Watermarking for Data-centric Unlearning Metric|Xinyang Lu, Xinyuan Niu, Gregory Kang Ruey Lau, Bui Thi Cam Nhung, Rachael Hwee Ling Sim, Fanyu Wen, Chuan-Sheng Foo, See-Kiong Ng, Bryan Kian Hsiang Low|2025-05-08|arXiv|https://github.com/lululu008/WaterDrum|https://doi.org/10.48550/arXiv.2505.05064|
|16|Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation|Vaidehi Patil, Yi-Lin Sung, Peter Hase, Jie Peng, Tianlong Chen, Mohit Bansal|2025-05-01|arXiv|https://github.com/Vaidehi99/UnLOK-VQA|https://doi.org/10.48550/arXiv.2505.01456|
|17|LLM Unlearning Reveals a Stronger-Than-Expected Coreset Effect in Current Benchmarks|Soumyadeep Pal, Changsheng Wang, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2025-04-15|arXiv|https://github.com/OPTML-Group/MU-Coreset|https://doi.org/10.48550/arXiv.2504.10185|
|18|A Survey on Unlearnable Data|Jiahao Li, Yiqiang Chen, Yunbing Xing, Yang Gu, Xiangyuan Lan|2025-03-31|arXiv|https://github.com/LiJiahao-Alex/Awesome-UnLearnable-Data|https://doi.org/10.48550/arXiv.2503.23536|
|19|ZJUKLAB at SemEval-2025 Task 4: Unlearning via Model Merging|Haoming Xu, Shuxun Wang, Yanqiu Zhao, Yi Zhong, Ziyan Jiang, Ningyuan Zhao, Shumin Deng, Huajun Chen, Ningyu Zhang|2025-03-29|arXiv|https://github.com/zjunlp/unlearn/tree/main/semeval25|https://doi.org/10.48550/arXiv.2503.21088|
|20|Effective Skill Unlearning through Intervention and Abstention|Yongce Li, Chung-En Sun, Tsui-Wei Weng|2025-03-29|arXiv|https://github.com/Trustworthy-ML-Lab/effective_skill_unlearning|https://doi.org/10.48550/arXiv.2503.21730|
|21|LoTUS: Large-Scale Machine Unlearning with a Taste of Uncertainty|Christoforos N. Spartalis, Theodoros Semertzidis, Efstratios Gavves, Petros Daras|2025-03-26|arXiv|https://github.com/cspartalis/LoTUS|https://doi.org/10.48550/arXiv.2503.18314|
|22|Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU|Àlex Pujol Vidal, Sergio Escalera, Kamal Nasrollahi, Thomas B. Moeslund|2025-03-20|arXiv|https://github.com/alex-pv01/HAC|https://doi.org/10.48550/arXiv.2503.15166|
|23|Group-robust Machine Unlearning|Thomas De Min, Subhankar Roy, Stéphane Lathuilière, Elisa Ricci, Massimiliano Mancini|2025-03-14|arXiv|https://github.com/tdemin16/group-robust_machine_unlearning|https://doi.org/10.48550/arXiv.2503.09330|
|24|Forgetting Any Data at Any Time: A Theoretically Certified Unlearning Framework for Vertical Federated Learning|Linian Wang, Leye Wang|2025-02-26|arXiv|https://github.com/wangln19/vertical-federated-unlearning|https://doi.org/10.48550/arXiv.2502.17081|
|25|UPCORE: Utility-Preserving Coreset Selection for Balanced Unlearning|Vaidehi Patil, Elias Stengel-Eskin, Mohit Bansal|2025-02-21|arXiv|https://github.com/Vaidehi99/UPCORE|https://doi.org/10.48550/arXiv.2502.15082|
|26|MMUnlearner: Reformulating Multimodal Machine Unlearning in the Era of Multimodal Large Language Models|Jiahao Huo, Yibo Yan, Xu Zheng, Yuanhuiyi Lyu, Xin Zou, Zhihua Wei, Xuming Hu|2025-02-17|arXiv|https://github.com/Z1zs/MMUnlearner|https://doi.org/10.48550/arXiv.2502.11051|
|27|ReLearn: Unlearning via Learning for Large Language Models|Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang|2025-02-17|arXiv|https://github.com/zjunlp/unlearn|https://doi.org/10.48550/arXiv.2502.11190|
|28|Towards LLM Unlearning Resilient to Relearning Attacks: A Sharpness-Aware Minimization Perspective and Beyond|Chongyu Fan, Jinghan Jia, Yihua Zhang, Anil Ramakrishna, Mingyi Hong, Sijia Liu|2025-02-08|arXiv|https://github.com/OPTML-Group/Unlearn-Smooth|https://doi.org/10.48550/arXiv.2502.05374|
|29|LMEraser: Large Model Unlearning through Adaptive Prompt Tuning|Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia|2025-02-08|arXiv|https://github.com/lmeraser/lmeraser|https://doi.org/10.48550/arXiv.2404.11056|
|30|Tool Unlearning for Tool-Augmented LLMs|Jiali Cheng, Hadi Amiri|2025-02-05|arXiv|https://clu-uml.github.io/MU-Bench-Project-Page/|https://doi.org/10.48550/arXiv.2502.01083|
|31|SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders|Bartosz Cywinski, Kamil Deja|2025-01-30|arXiv|https://github.com/cywinski/SAeUron|https://doi.org/10.48550/arXiv.2501.18052|
|32|Backdoor Token Unlearning: Exposing and Defending Backdoors in Pretrained Language Models|Peihai Jiang, Xixiang Lyu, Yige Li, Jing Ma|2025-01-06|arXiv|https://github.com/XDJPH/BTU|https://doi.org/10.48550/arXiv.2501.03272|
|33|Efficient Federated Unlearning under Plausible Deniability|Ayush K. Varshney, Vicenç Torra|2025|arXiv|https://github.com/Ayush-Umu/Federated-Unlearning-under-Plausible-Deniability|https://doi.org/10.48550/arXiv.2410.09947|
|34|DuplexGuard: Safeguarding Deletion Right in Machine Unlearning Via Duplex Watermarking|Xiaoyu Zhang, Chenyang Zhang, Jian Lou, Kai Wu, Zilong Wang, Xiaofeng Chen|2025|IEEE Transactions on Dependable and Secure Computing|https://github.com/123000001212/DuplexGuard|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10670570|
|35|Provably Unlearnable Data Examples|Derui Wang, Minhui Xue, Bo Li, Seyit Camtepe, Liming Zhu|2025|NDSS|https://github.com/NeuralSec/certified-data-learnability|https://www.ndss-symposium.org/ndss-paper/provably-unlearnable-data-examples/|
|36|Identify Backdoored Model in Federated Learning via Individual Unlearning|Jiahao Xu, Zikai Zhang, Rui Hu|2025|arXiv|https://github.com/JiiahaoXU/MASA|https://doi.org/10.48550/arXiv.2411.01040|
|37|Alternate Preference Optimization for Unlearning Factual Knowledge in Large Language Models|Anmol Reddy Mekala, Vineeth Dorna, Shreya Dubey, Abhishek Lalwani, David Koleczek, Mukund Rungta, Sadid A. Hasan, Elita A. Lobo|2025|arXiv|https://github.com/molereddy/Alternate-Preference-Optimization|https://doi.org/10.48550/arXiv.2409.13474|
|38|Towards efficient and effective unlearning of large language models for recommendation|Hangyu Wang, Jianghao Lin, Bo Chen, Yang Yang, Ruiming Tang, Weinan Zhang, Yong Yu|2025|Frontiers Comput. Sci.|https://github.com/justarter/E2URec|https://doi.org/10.1007/s11704-024-40044-2|
|39|LoRA Unlearns More and Retains More (Student Abstract)|Atharv Mittal|2025|AAAI|https://github.com/vlgiitr/LoRA-Unlearn|https://doi.org/10.1609/aaai.v39i28.35277|
|40|An Information Theoretic Approach to Machine Unlearning|Jack Foster, Kyle Fogarty, Stefan Schoepf, Zack Dugue, Cengiz Öztireli, Alexandra Brintrup|2025|Trans. Mach. Learn. Res.|https://github.com/jwf40/Information-Theoretic-Unlearning|https://openreview.net/forum?id=t1utIThKHD|
|41|Vertical Federated Unlearning via Backdoor Certification|Mengde Han, Tianqing Zhu, Lefeng Zhang, Huan Huo, Wanlei Zhou|2025|IEEE Trans. Serv. Comput.|https://github.com/mengde-han/VFL-unlearn|https://doi.org/10.1109/TSC.2025.3536312|
|42|Scalable and Certifiable Graph Unlearning: Overcoming the Approximation Error Barrier|Lu Yi, Zhewei Wei|2025|ICLR|https://github.com/luyi256/ScaleGUN|https://openreview.net/forum?id=pPyJyeLriR|
|43|Recommendation Unlearning via Influence Function|Yang Zhang, Zhiyu Hu, Yimeng Bai, Fuli Feng, Jiancan Wu, Qifan Wang, Xiangnan He|2025|ACM Transactions on Recommender Systems (TORS), Volume 3, Issue 2|https://github.com/baiyimeng/IFRU|https://dl.acm.org/doi/10.1145/3701763|
|44|A Probabilistic Perspective on Unlearning and Alignment for Large Language Models|Yan Scholten, Stephan Günnemann, Leo Schwinn|2025|arXiv|https://github.com/yascho/probabilistic-unlearning|https://doi.org/10.48550/arXiv.2410.03523|
|45|A Closer Look at Machine Unlearning for Large Language Models|Xiaojian Yuan, Tianyu Pang, Chao Du, Kejiang Chen, Weiming Zhang, Min Lin|2025|arXiv|https://github.com/sail-sg/closer-look-LLM-unlearning|https://doi.org/10.48550/arXiv.2410.08109|
|46|Soft Prompting for Unlearning in Large Language Models|Karuna Bhaila, Minh-Hao Van, Xintao Wu|2025|arXiv|https://github.com/karuna-bhaila/llm_unlearning|https://doi.org/10.48550/arXiv.2406.12038|
|47|MU-Bench: A Multitask Multimodal Benchmark for Machine Unlearning|Jiali Cheng, Hadi Amiri|2024-12-24|arXiv|https://clu-uml.github.io/MU-Bench-Project-Page/|https://doi.org/10.48550/arXiv.2406.14796|
|48|Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification|Changchang Sun, Ren Wang, Yihua Zhang, Jinghan Jia, Jiancheng Liu, Gaowen Liu, Sijia Liu, Yan Yan|2024-12-21|arXiv|https://github.com/Changchangsun/Forget-Vector|http://arxiv.org/abs/2412.16780v1|
|49|Boosting Alignment for Post-Unlearning Text-to-Image Generative Models|Myeongseob Ko, Henry Li, Zhun Wang, Jonathan Patsenker, Jiachen T. Wang, Qinbin Li, Ming Jin, Dawn Song, Ruoxi Jia|2024-12-09|arXiv …, 2024|https://github.com/reds-lab/Restricted_gradient_diversity_unlearning|http://arxiv.org/abs/2412.07808v1|
|50|A Cognac shot to forget bad memories: Corrective Unlearning in GNNs|Varshita Kolipaka, Akshit Sinha, Debangan Mishra, Sumit Kumar, Arvindh Arun, Shashwat Goel, Ponnurangam Kumaraguru|2024-12-02|arXiv …, 2024|https://github.com/varshitakolipaka/corrective-unlearning-for-gnns|http://arxiv.org/abs/2412.00789v2|
|51|Delta-Influence: Unlearning Poisons via Influence Functions|Wenjie Li, Jiawei Li, Christian Schroeder de Witt, Ameya Prabhu, Amartya Sanyal|2024-11-21|arXiv|https://github.com/andyisokay/delta-influence|https://doi.org/10.48550/arXiv.2411.13731|
|52|Does Unlearning Truly Unlearn? A Black Box Evaluation of LLM Unlearning Methods|Jai Doshi, Asa Cooper Stickland|2024-11-19|arXiv:2411.12103, 2024|https://github.com/JaiDoshi/Knowledge-Erasure|http://arxiv.org/abs/2411.12103v2|
|53|Evaluating Deep Unlearning in Large Language Models|Ruihan Wu, Chhavi Yadav, Russ Salakhutdinov, Kamalika Chaudhuri|2024-10-20|arXiv|https://github.com/wrh14/deep_unlearning|https://doi.org/10.48550/arXiv.2410.15153|
|54|Meta-Unlearning on Diffusion Models: Preventing Relearning Unlearned Concepts|Hongcheng Gao, Tianyu Pang, Chao Du, Taihang Hu, Zhijie Deng, Min Lin|2024-10-16|arXiv|https://github.com/sail-sg/Meta-Unlearning|https://doi.org/10.48550/arXiv.2410.12777|
|55|Dissecting Fine-Tuning Unlearning in Large Language Models|Yihuai Hong, Yuelin Zou, Lijie Hu, Ziqian Zeng, Di Wang, Haiqin Yang|2024-10-09|EMNLP|https://github.com/yihuaihong/Dissecting-FT-Unlearning|https://aclanthology.org/2024.emnlp-main.228|
|56|Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning|Chongyu Fan, Jiancheng Liu, Licong Lin, Jinghan Jia, Ruiqi Zhang, Song Mei, Sijia Liu|2024-10-09|arXiv|https://github.com/OPTML-Group/Unlearn-Simple|https://doi.org/10.48550/arXiv.2410.07163|
|57|Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need|Xianlong Wang, Minghui Li, Wei Liu, Hangtao Zhang, Shengshan Hu, Yechao Zhang, Ziqi Zhou, Hai Jin|2024-10-04|arXiv|https://github.com/CGCL-codes/UnlearnablePC|https://doi.org/10.48550/arXiv.2410.03644|
|58|Multimodal Unlearnable Examples: Protecting Data against Multimodal Contrastive Learning|Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao|2024-10|MM '24: Proceedings of the 32nd ACM International Conference on Multimedia|https://github.com/thinwayliu/Multimodal-Unlearnable-Examples|https://dl.acm.org/doi/10.1145/3664647.3680708|
|59|Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models|Aakash Sen Sharma, Niladri Sarkar, Vikram S. Chundawat, Ankur A. Mali, Murari Mandal|2024-09-09|arXiv|https://respailab.github.io/unlearning-or-concealment|https://doi.org/10.48550/arXiv.2409.05668|
|60|CURE4Rec: A Benchmark for Recommendation Unlearning with Deeper Influence|Chaochao Chen, Jiaming Zhang, Yizhao Zhang, Li Zhang, Lingjuan Lyu, Yuyuan Li, Biao Gong, Chenggang Yan|2024-08-26|arXiv|https://oktton.github.io|https://doi.org/10.48550/arXiv.2408.14393|
|61|A Unified Framework for Continual Learning and Machine Unlearning|Romit Chatterjee, Vikram S. Chundawat, Ayush K. Tarun, Ankur A. Mali, Murari Mandal|2024-08-21|arXiv|https://respailab.github.io/CLMUL|https://doi.org/10.48550/arXiv.2408.11374|
|62|Machine Unlearning in Generative AI: A Survey|Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang|2024-07-30|arXiv|https://github.com/franciscoliu/GenAI-MU-Reading|https://doi.org/10.48550/arXiv.2407.20516|
|63|Revisiting Who&apos;s Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective|Yujian Liu, Yang Zhang, Tommi S. Jaakkola, Shiyu Chang|2024-07-24|EMNLP|https://github.com/UCSB-NLP-Chang/causal_unlearn|https://aclanthology.org/2024.emnlp-main.495|
|64|Safe Unlearning: A Surprisingly Effective and Generalizable Solution to Defend Against Jailbreak Attacks|Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning Wang, Minlie Huang|2024-07-03|arXiv|https://github.com/thu-coai/SafeUnlearning|https://doi.org/10.48550/arXiv.2407.02855|
|65|To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models|Bozhong Tian, Xiaozhuan Liang, Siyuan Cheng, Qingbin Liu, Mengru Wang, Dianbo Sui, Xi Chen, Huajun Chen, Ningyu Zhang|2024-07-02|EMNLP|https://github.com/zjunlp/KnowUnDo|https://aclanthology.org/2024.findings-emnlp.82|
|66|Enable the Right to be Forgotten with Federated Client Unlearning in Medical Imaging|Zhipeng Deng, Luyang Luo, Hao Chen|2024-07-02|MICCAI|https://github.com/dzp2095/FCU|https://doi.org/10.1007/978-3-031-72117-5_23|
|67|Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces|Yihuai Hong, Lei Yu, Shauli Ravfogel, Haiqin Yang, Mor Geva|2024-06-17|arXiv|https://github.com/yihuaihong/ConceptVectors|https://doi.org/10.48550/arXiv.2406.11614|
|68|RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models|Zhuoran Jin, Pengfei Cao, Chenhao Wang, Zhitao He, Hongbang Yuan, Jiachun Li, Yubo Chen, Kang Liu, Jun Zhao|2024-06-16|arXiv|http://rwku-bench.github.io|https://doi.org/10.48550/arXiv.2406.10890|
|69|Data Attribution for Text-to-Image Models by Unlearning Synthesized Images|Sheng-Yu Wang, Aaron Hertzmann, Alexei A. Efros, Jun-Yan Zhu, Richard Zhang|2024-06-13|arXiv|https://peterwang512.github.io/AttributeByUnlearning|https://doi.org/10.48550/arXiv.2406.09408|
|70|Large Language Model Unlearning via Embedding-Corrupted Prompts|Chris Yuhao Liu, Yaxuan Wang, Jeffrey Flanigan, Yang Liu|2024-06-12|arXiv|https://github.com/chrisliu298/llm-unlearn-eco|https://doi.org/10.48550/arXiv.2406.07933|
|71|Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference|Jiabao Ji, Yujian Liu, Yang Zhang, Gaowen Liu, Ramana Rao Kompella, Sijia Liu, Shiyu Chang|2024-06-12|arXiv|https://github.com/UCSB-NLP-Chang/ULD|https://doi.org/10.48550/arXiv.2406.08607|
|72|Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew Resilience|Thanh Trung Huynh, Trong Bang Nguyen, Phi Le Nguyen, Thanh Tam Nguyen, Matthias Weidlich, Quoc Viet Hung Nguyen, Karl Aberer|2024-05-28|ECML/PKDD|https://github.com/thanhtrunghuynh93/fastFedUL|https://doi.org/10.1007/978-3-031-70362-1_4|
|73|Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models|Yimeng Zhang, Xin Chen, Jinghan Jia, Yihua Zhang, Chongyu Fan, Jiancheng Liu, Mingyi Hong, Ke Ding, Sijia Liu|2024-05-24|arXiv|https://github.com/OPTML-Group/AdvUnlearn|https://doi.org/10.48550/arXiv.2405.15234|
|74|Generative Unlearning for Any Identity|Juwon Seo, Sung-Hoon Lee, Tae-Young Lee, Seungjun Moon, Gyeong-Moon Park|2024-05-16|2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/KHU-AGI/GUIDE|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10655907|
|75|Erasing Concepts from Text-to-Image Diffusion Models with Few-shot Unlearning|Masane Fuchi, Tomohiro Takagi|2024-05-12|arXiv|https://github.com/fmp453/few-shot-erasing|https://doi.org/10.48550/arXiv.2405.07288|
|76|Purify Unlearnable Examples via Rate-Constrained Variational Autoencoders|Yi Yu, Yufei Wang, Song Xia, Wenhan Yang, Shijian Lu, Yap-Peng Tan, Alex C. Kot|2024-05-02|ICML|https://github.com/yuyi-sd/D-VAE|https://openreview.net/forum?id=0LBNdbmQCM|
|77|Breaking the Trilemma of Privacy, Utility, and Efficiency via Controllable Machine Unlearning|Zheyuan Liu, Guangyao Dou, Eli Chien, Chunhui Zhang, Yijun Tian, Ziwei Zhu|2024-05|WWW '24: Proceedings of the ACM Web Conference 2024|https://github.com/guangyaodou/ConMU|https://dl.acm.org/doi/10.1145/3589334.3645669|
|78|Machine Unlearning for Document Classification|Lei Kang, Mohamed Ali Souibgui, Fei Yang, Lluís Gómez, Ernest Valveny, Dimosthenis Karatzas|2024-04-29|ICDAR|https://github.com/leitro/MachineUnlearning-DocClassification|https://doi.org/10.1007/978-3-031-70546-5_6|
|79|SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning|Jinghan Jia, Yihua Zhang, Yimeng Zhang, Jiancheng Liu, Bharat Runwal, James Diffenderfer, Bhavya Kailkhura, Sijia Liu|2024-04-28|EMNLP|https://github.com/OPTML-Group/SOUL|https://aclanthology.org/2024.emnlp-main.245|
|80|Machine Unlearning via Null Space Calibration|Huiqiang Chen, Tianqing Zhu, Xin Yu, Wanlei Zhou|2024-04-21|IJCAI|https://github.com/HQC-ML/Machine-Unlearning-via-Null-Space-Calibration|https://www.ijcai.org/proceedings/2024/40|
|81|Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge|Weikai Lu, Ziqian Zeng, Jianwei Wang, Zhengdong Lu, Zelin Chen, Huiping Zhuang, Cen Chen|2024-04-08|arXiv|https://github.com/ZeroNLP/Eraser|https://doi.org/10.48550/arXiv.2404.05880|
|82|Challenging Forgets: Unveiling the Worst-Case Forget Sets in Machine Unlearning|Chongyu Fan, Jiancheng Liu, Alfred Olivier Hero, Sijia Liu|2024-03-12|arXiv|https://github.com/OPTML-Group/Unlearn-WorstCase|https://doi.org/10.48550/arXiv.2403.07362|
|83|Dissecting Language Models: Machine Unlearning via Selective Pruning|Nicholas Pochinkov, Nandi Schoots|2024-03-02|arXiv|https://github.com/nickypro/selective-pruning|https://doi.org/10.48550/arXiv.2403.01267|
|84|Machine Unlearning of Pre-trained Large Language Models|Jin Yao, Eli Chien, Minxin Du, Xinyao Niu, Tianhao Wang, Zezhou Cheng, Xiang Yue|2024-02-23|ACL|https://github.com/yaojin17/Unlearning_LLM|https://doi.org/10.18653/v1/2024.acl-long.457|
|85|Corrective Machine Unlearning|Shashwat Goel, Ameya Prabhu, Philip Torr, Ponnurangam Kumaraguru, Amartya Sanyal|2024-02-21|arXiv|https://github.com/drimpossible/corrective-unlearning-bench|https://doi.org/10.48550/arXiv.2402.14015|
|86|Machine Unlearning for Image-to-Image Generative Models|Guihong Li, Hsiang Hsu, Chun-Fu Chen, Radu Marculescu|2024-02-01|ICLR|https://github.com/jpmorganchase/l2l-generator-unlearning|https://openreview.net/forum?id=9hjVoPWPnh|
|87|Dataset Condensation Driven Machine Unlearning|Junaid Iqbal Khan|2024-01-31|arXiv|https://github.com/algebraicdianuj/DC_U|https://doi.org/10.48550/arXiv.2402.00195|
|88|Game-Theoretic Unlearnable Example Generator|Shuang Liu, Yihan Wang, Xiao-Shan Gao|2024-01-31|AAAI|https://github.com/hong-xian/gue|https://doi.org/10.1609/aaai.v38i19.30130|
|89|TOFU: A Task of Fictitious Unlearning for LLMs|Pratyush Maini, Zhili Feng, Avi Schwarzschild, Zachary C. Lipton, J. Zico Kolter|2024-01-11|arXiv|https://locuslab.github.io/tofu/|https://doi.org/10.48550/arXiv.2401.06121|
|90|A Dataset and Benchmark for Copyright Infringement Unlearning from Text-to-Image Diffusion Models|Rui Ma, Qiang Zhou, Yizhu Jin, Daquan Zhou, Bangjun Xiao, Xiuyu Li, Yi Qu, Aishani Singh, Kurt Keutzer, Jingtong Hu, Xiaodong Xie, Zhen Dong, Shanghang Zhang, Shiji Zhou|2024-01-04|arXiv|https://rmpku.github.io/CPDM-page/|http://arxiv.org/abs/2403.12052v3|
|91|Towards Efficient Machine Unlearning with Data Augmentation: Guided Loss-Increasing (GLI) to Prevent the Catastrophic Model Utility Drop|Dasol Choi, Soora Choi, Eunsun Lee, Jinwoo Seo, Dongbin Na|2024|2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)|https://github.com/Dasol-Choi/Guided_Loss_Increasing|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10678506|
|92|To Generate or Not? Safety-Driven Unlearned Diffusion Models Are Still Easy to Generate Unsafe Images ... For Now|Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yihua Zhang, Jiancheng Liu, Ke Ding, Sijia Liu|2024|ECCV|https://github.com/OPTML-Group/Diffusion-MU-Attack|https://doi.org/10.1007/978-3-031-72998-0_22|
|93|Task-Aware Machine Unlearning and Its Application in Load Forecasting|Wangkun Xu, Fei Teng|2024|IEEE Transactions on Power Systems|https://github.com/xuwkk/task_aware_machine_unlearning|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472091|
|94|Stable Unlearnable Example: Enhancing the Robustness of Unlearnable Examples via Stable Error-Minimizing Noise|Yixin Liu, Kaidi Xu, Xun Chen, Lichao Sun|2024|AAAI|https://github.com/liuyixin-louis/Stable-Unlearnable-Example|https://doi.org/10.1609/aaai.v38i4.28169|
|95|Learn to Unlearn for Deep Neural Networks: Minimizing Unlearning Interference with Gradient Projection|Tuan Hoang, Santu Rana, Sunil Gupta, Svetha Venkatesh|2024|2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)|https://github.com/hnanhtuan/projected_gradient_unlearning|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10483632|
|96|Machine Unlearning via Representation Forgetting With Parameter Self-Sharing|Weiqi Wang, Chenhan Zhang, Zhiyi Tian, Shui Yu|2024|IEEE Transactions on Information Forensics and Security|https://github.com/wwq5-code/RFU-SS|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10312776|
|97|SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation|Chongyu Fan, Jiancheng Liu, Yihua Zhang, Dennis Wei, Eric Wong, Sijia Liu|2024|arXiv|https://github.com/OPTML-Group/Unlearn-Saliency|https://doi.org/10.48550/arXiv.2310.12508|
|98|Fast Yet Effective Machine Unlearning|Ayush K. Tarun, Vikram S. Chundawat, Murari Mandal, Mohan S. Kankanhalli|2024|IEEE Transactions on Neural Networks and Learning Systems|https://github.com/vikram2000b/Fast-Machine-Unlearning|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10113700|
|99|Fair Machine Unlearning: Data Removal while Mitigating Disparities|Alex Oesterling, Jiaqi Ma, Flávio P. Calmon, Himabindu Lakkaraju|2024|arXiv|https://github.com/AI4LIFE-GROUP/fair-unlearning|https://doi.org/10.48550/arXiv.2307.14754|
|100|Deep Unlearning: Fast and Efficient Gradient-free Class Forgetting|Sangamesh Kodge, Gobinda Saha, Kaushik Roy|2024|Trans. Mach. Learn. Res.|https://github.com/sangamesh-kodge/class_forgetting|https://openreview.net/forum?id=BmI5p6wBi0|
|101|Continual Forgetting for Pre-Trained Vision Models|H. Zhao, B. Ni, J. Fan, Y. Wang, Y. Chen, G. Meng, Z. Zhang|2024|2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/bjzhb666/GS-LoRA|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10655987|
|102|BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning|S. Liang, M. Zhu, A. Liu, B. Wu, X. Cao, E. -C. Chang|2024|2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/LiangSiyuan21/BadCLIP|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10658003|
|103|A Study Regarding Machine Unlearning on Facial Attribute Data|Emircan Gündogdu, Altay Unal, Gozde Unal|2024|2024 IEEE 18th International Conference on Automatic Face and Gesture Recognition (FG)|https://github.com/ituvisionlab/face-attribute-unlearning|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10581972|
|104|Towards Machine Unlearning Benchmarks: Forgetting the Personal Identities in Facial Recognition Systems|Dasol Choi, Dongbin Na|2023-11-03|arXiv|https://github.com/ndb796/MachineUnlearning|https://doi.org/10.48550/arXiv.2311.02240|
|105|A Survey of Federated Unlearning: A Taxonomy, Challenges and Future Directions|Yang Zhao, Jiaxi Yang, Yiling Tao, Lixu Wang, Xiaoxiao Li, Dusit Niyato|2023-10-30|arXiv|https://github.com/abbottyanginchina/Awesome-Federated-Unlearning|https://doi.org/10.48550/arXiv.2310.19218|
|106|Unlearnable Examples Give a False Sense of Security: Piercing through Unexploitable Data with Learnable Examples|Wan Jiang, Yunfeng Diao, He Wang, Jianxin Sun, Meng Wang, Richang Hong|2023-10|MM '23: Proceedings of the 31st ACM International Conference on Multimedia|https://github.com/jiangw-0/LE_JCDP|https://dl.acm.org/doi/10.1145/3581783.3611833|
|107|What Can We Learn from Unlearnable Datasets?|Pedro Sandoval Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein|2023-05-30|NeurIPS|https://github.com/psandovalsegura/learn-from-unlearnable|http://papers.nips.cc/paper_files/paper/2023/hash/ee5bb72130c332c3d4bf8d231e617506-Abstract-Conference.html|
|108|Model Sparsification Can Simplify Machine Unlearning|Jinghan Jia, Jiancheng Liu, Parikshit Ram, Yuguang Yao, Gaowen Liu, Yang Liu, Pranay Sharma, Sijia Liu|2023-04-11|arXiv|https://github.com/OPTML-Group/Unlearn-Sparse|https://doi.org/10.48550/arXiv.2304.04934|
|109|GIF: A General Graph Unlearning Strategy via Influence Function|Jiancan Wu, Yi Yang, Yuchun Qian, Yongduo Sui, Xiang Wang, Xiangnan He|2023-04-06|WWW '23: Proceedings of the ACM Web Conference 2023|https://github.com/wujcan/GIF-torch/|https://dl.acm.org/doi/10.1145/3543507.3583521|
|110|Inductive Graph Unlearning|Cheng-Long Wang, Mengdi Huai, Di Wang|2023-04-06|USENIX Security Symposium|https://github.com/Happy2Git/GUIDE|https://www.usenix.org/conference/usenixsecurity23/presentation/wang-cheng-long|
|111|Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks|Tianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu|2023-03-27|arXiv|https://github.com/lafeat/ueraser|https://doi.org/10.48550/arXiv.2303.15127|
|112|Unlearnable Clusters: Towards Label-Agnostic Unlearnable Examples|Jiaming Zhang, Xingjun Ma, Qi Yi, Jitao Sang, Yu-Gang Jiang, Yaowei Wang, Changsheng Xu|2023|CVPR|https://github.com/jiamingzhang94/Unlearnable-Clusters|https://doi.org/10.1109/CVPR52729.2023.00388|
|113|Toward Highly-Efficient and Accurate Services QoS Prediction via Machine Unlearning|Yuxiang Zeng, Jianlong Xu, Yuhui Li, Caiyi Chen, Qingcao Dai, Zibo Du|2023|IEEE Access|https://github.com/ZengYuXiang7/CADDEraser|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10171348|
|114|Tangent Model Composition for Ensembling and Continual Fine-tuning|T. Y. Liu, S. Soatto|2023|2023 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/tianyu139/tangent-model-composition|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10378156|
|115|Machine Unlearning of Federated Clusters|Chao Pan, Jin Sima, Saurav Prakash, Vishal Rana, Olgica Milenkovic|2023|ICLR|https://github.com/thupchnsky/mufc|https://openreview.net/forum?id=VzwfoFyYDga|
|116|QoSEraser: A Data Erasable Framework for Web Service QoS Prediction|Y. Zeng, Y. Li, Z. Xia, Z. Du, J. Wang, R. Lian, J. Xu|2023|2023 IEEE International Conference on Software Services Engineering (SSE)|https://github.com/ZengYuXiang7/QoSEraser|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10234360|
|117|ModelGiF: Gradient Fields for Model Functional Distance|J. Song, Z. Xu, S. Wu, G. Chen, M. Song|2023|2023 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/zju-vipa/modelgif|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10377295|
|118|ERM-KTP: Knowledge-Level Machine Unlearning via Knowledge Transfer|Shen Lin, Xiaoyu Zhang, Chenyang Chen, Xiaofeng Chen, Willy Susilo|2023|2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/RUIYUN-ML/ERM-KTP|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10203043|
|119|Knowledge Unlearning for Mitigating Privacy Risks in Language Models|Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, Minjoon Seo|2023|ACL|https://github.com/joeljang/knowledge-unlearning|https://doi.org/10.18653/v1/2023.acl-long.805|
|120|Generalizability and Application of the Skin Reflectance Estimate Based on Dichromatic Separation (SREDS)|J. Drahos, R. Plesh, K. Bahmani, M. Banavar, S. Schuckers|2023|2023 International Conference of the Biometrics Special Interest Group (BIOSIG)|https://github.com/JosephDrahos/SREDS|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10345973|
|121|FedCSA: Boosting the Convergence Speed of Federated Unlearning under Data Heterogeneity|Zhen Wang, Daniyal M. Alghazzawi, Li Cheng, Gaoyang Liu, Chen Wang, Zeng Cheng, Yang Yang|2023|2023 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)|https://github.com/ZhenWang9/FedCSA|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10491845|
|122|Deep Regression Unlearning|Ayush Kumar Tarun, Vikram Singh Chundawat, Murari Mandal, Mohan S. Kankanhalli|2023|arXiv|https://github.com/ayu987/deep-regression-unlearning|https://doi.org/10.48550/arXiv.2210.08196|
|123|CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning|Hritik Bansal, Nishad Singhi, Yu Yang, Fan Yin, Aditya Grover, Kai-Wei Chang|2023|2023 IEEE/CVF International Conference on Computer Vision (ICCV)|https://github.com/nishadsinghi/CleanCLIP|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10377853|
|124|Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher|Vikram S. Chundawat, Ayush K. Tarun, Murari Mandal, Mohan S. Kankanhalli|2023|AAAI|https://github.com/vikram2000b/bad-teaching-unlearning|https://doi.org/10.1609/aaai.v37i6.25879|
|125|A Survey of Machine Unlearning|Thanh Tam Nguyen, Thanh Trung Huynh, Zhao Ren, Phi Le Nguyen, Alan Wee-Chung Liew, Hongzhi Yin, Quoc Viet Hung Nguyen|2022-09-06|arXiv|https://github.com/tamlhp/awesome-machine-unlearning|https://doi.org/10.48550/arXiv.2209.02299|
|126|Deep Unlearning via Randomized Conditionally Independent Hessians|Ronak Mehta, Sourav Pal, Vikas Singh, Sathya N. Ravi|2022-04-15|2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)|https://github.com/vsingh-group/LCODEC-deep-unlearning|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880362|
|127|Robust Unlearnable Examples: Protecting Data Against Adversarial Learning|Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao|2022-03-28|arXiv|https://github.com/fshp971/robust-unlearnable-examples|https://doi.org/10.48550/arXiv.2203.14533|
|128|Continual Learning and Private Unlearning|Bo Liu, Qiang Liu, Peter Stone|2022-03-24|CoLLAs|https://github.com/Cranial-XIX/Continual-Learning-Private-Unlearning|https://proceedings.mlr.press/v199/liu22a.html|
|129|When Machine Unlearning Jeopardizes Privacy|Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang|2021-11|CCS '21: Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security|https://github.com/MinChen00/UnlearningLeaks|https://dl.acm.org/doi/10.1145/3460120.3484756|
|130|Towards Probabilistic Verification of Machine Unlearning|David Marco Sommer, Liwei Song, Sameer Wagh, Prateek Mittal|2020-03-09|arXiv|https://github.com/inspire-group/unlearning-verification|https://arxiv.org/abs/2003.04247|
|131|Robust Deep Learning-Based Diagnosis of Mixed Faults in Rotating Machinery|S. Chen, Y. Meng, H. Tang, Y. Tian, N. He, C. Shao|2020|IEEE/ASME Transactions on Mechatronics|https://github.com/siyuanc2/machine-fault-diag|https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136730|
|132|Compressed Sensing with Deep Image Prior and Learned Regularization|Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, Alexandros G. Dimakis|nan|OpenReview|https://github.com/anon-iclr/csdip-iclr|https://openreview.net/pdf/960068efdade58de64b1b641bcccfdba53ac168b.pdf|
|133|Effective Backdoor Defense by Exploiting Sensitivity of Poisoned Samples|Weixin Chen, Baoyuan Wu, Haoqian Wang|nan|NeurIPS 2022 Accept|https://github.com/SCLBD/Effective_backdoor_defense|https://openreview.net/pdf/82397e777241ae042276e8493ca8e5d228821582.pdf|
|134|Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models|Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro|nan|NeurIPS 2022 Accept|https://github.com/NVIDIA/Megatron-LM/|https://openreview.net/pdf/cbffa1a0bf2612f146adbc70397e00fc131d2db4.pdf|
|135|Knowledge Removal in Sampling-based Bayesian Inference|Shaopeng Fu, Fengxiang He, Dacheng Tao|nan|ICLR 2022 Poster|https://github.com/fshp971/mcmc-unlearning|https://openreview.net/pdf/a42ad90a502167268f1ba4c67f57150bf59ccbc9.pdf|
|136|Training wide residual networks for deployment using a single bit for each weight|Mark D. McDonnell|nan|OpenReview|https://github.com/McDonnell-Lab/1-bit-per-weight/|https://openreview.net/pdf/861cb006a62eb71925571a5d4979901d047a92ea.pdf|
|137|Trap and Replace: Defending Backdoor Attacks by Trapping Them into an Easy-to-Replace Subnetwork|Haotao Wang, Junyuan Hong, Aston Zhang, Jiayu Zhou, Zhangyang Wang|nan|NeurIPS 2022 Accept|https://github.com/VITA-Group/Trap-and-Replace-Backdoor-Defense|https://openreview.net/pdf/a0b040b733099d83fd30969cd35fa8cc35c367b2.pdf|
